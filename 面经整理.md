**<mark>1.介绍智能指针</mark>**

智能指针的作用是用来管理一个指针，防止程序员申请的空间在函数结束时没有释放，从而造成内存泄漏的发生。

使用智能指针可以很大程度上避免这个问题，因为智能指针是一个类，当超出了类的作用域范围时，会自动调用类的析构函数，从而释放资源。

有四种智能指针，auto_ptr, unique_ptr, shared_ptr, weak_ptr 

**auto_ptr**采用所有权的模式，在c++11中被废弃了，其原因是：

（1）auto_ptr在拷贝和赋值操作时会导致所有权转移。auto_ptr以copy的语义来转移指针资源，转移指针资源的所有权的同时，会将原指针置为NULL，这和我们通常理解上的copy行为是不一致的（通常不会修改原数据）。

（2）使用容器保存auto_ptr后，在进行操作后，可能导致容器中保存的原auto_ptr所管理的对象失效，如sort快排实现中有将元素复制到某个局部临时对象中，但对于auto_ptr，却将原元素置为NULL，这就会导致最后的排序结果中可能会存在大量的NULL。

**unique_ptr**同样采用所有权模式，它实现严格拥有的概念，保证同一时间内只能由一个智能指针指向该对象，即两个unique_ptr不能同时指向一个对象，不能进行复制操作，只能进行移动操作。当它指向其他对象时，之前所指向的对象会被摧毁。因此，unique_ptr 比auto_ptr 更安全。

**shared_ptr**实现共享式拥有的概念，多个智能指针可以同时指向相同的对象，使用引用计数的机制来表明资源被几个指针所共享，对象和相关资源会在最后一个引用被销毁时释放，

可以通过调用use_count()来查看资源的所有者个数，并调用release()，来释放当前指针的资源所有权，使计数减一，当计数减为0时，资源会被释放。

**weak_ptr**叫弱引用指针，是一种不控制对象生命周期的智能指针，他指向一个shared_ptr管理的对象。进行该对象内存管理的是强引用的shared_ptr。weak_ptr只是提供了对管理对象的一个访问手段，他设计的目的是为了协助shared_ptr，它可以解决shared_ptr循环引用的问题，weak_ptr只可以从一个shared_ptr或另一个weak_ptr对象构造，他的构造和析构不会引起引用计数的增加或减少。

**循环引用**：两个对象相互使用shared_ptr指向对方

**<mark>2.final修饰符的作用</mark>**

（1）用来修饰类时，使该类不能被继承

（2）用来修饰类的成员函数时，使该成员函数不能被派生类重写。final关键字可以帮助确保程序的安全性，可以防止有人不小心修改或覆盖定义好的函数从而造成错误。

**<mark>3.HTTP状态码</mark>**

1xx: 100, 101

2xx: 200, 204, 206

3xx: 301, 302, 304

4xx: 400, 403, 404

5xx: 500, 501, 502, 503, 504, 505

**<mark>4.MYSQL索引</mark>**

索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是索引是数据的目录。

innoDB主要使用B+ Tree索引类型，创建表时，innoDB存储引擎会根据不同的场景选择不同的列作为索引：

（1）如果有主键，默认使用主键作为聚簇索引的索引键

（2）如果没有主键，就选择第一个不含NULL值的唯一列作为聚簇索引的索引键

（3）如果俩个都没有，InnoDB将会自动生成一个隐式自增ID列作为聚簇索引的索引键

其他索引都称为辅助索引，或二级索引、非聚簇索引。

B+ Tree是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，且每个节点里的数据是按主键顺序存放的。每一层父节点的索引值都会出现在下层子节点的索引值中，所以叶子节点包含所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。

在二级索引的B+Tree就能查询到结果的过程叫做**覆盖索引**，也就是只需要查一个B+Tree就能找到数据

联合索引，存在最左匹配原则

**<mark>5.MYSQL的buffer pool怎么清空</mark>**

使用FLUSH BUFFER POOL

这个命令可以清空所有的缓存页，使得MYSQL需要重新读取磁盘上的数据，这意味着下一次查询的速度会比较慢，因为需要重新从磁盘中读取数据到内存。

**<mark>6.虚函数</mark>**

主要是用来实现多态，在基类的函数前加上virtual关键字，在派生类中重写该函数，运行时将根据对象的实际类型来调用对应的函数，如果对象类型是派生类，就调用派生类的函数，如果是基类，就调用基类函数。

当一个类中包含虚函数时，编译器会为该类生成一个虚函数表，保存该类中虚函数的地址，同样，派生类继承基类，自然也会有虚函数，所以编译器也会为派生类生成自己的虚函数表，当我们定义一个派生类对象时，编译器检测该类型有虚函数，所以为这个派生类对象生成一个虚函数指针，指向该类型的虚函数表，这个虚函数指针的初始化是在构造函数中完成的。

如果有一个基类类型的指针，指向派生类，那么当调用虚函数时，就会根据所指真正对象的虚函数表指针去寻找虚函数的地址，也就可以调用派生类的虚函数表中的虚函数以此实现多态。

**<mark>7.析构函数写成虚函数原因</mark>**

防止内存泄漏，如果定义了一个基类的指针指向一个派生类对象，在使用完毕准备销毁时，如果基类的析构函数没有定义成虚函数，则编译器根据指针类型就会认为当前对象的类型是基类，调用基类的析构函数，仅执行基类的析构，派生类自身的内容无法被析构，造成内存泄漏。

如果基类的析构函数定义为虚函数，那么编译器就可以根据实际对象，执行派生类的析构函数，再执行基类的析构函数，成功释放内存。

**<mark>8.构造函数为什么不能声明为虚函数</mark>**

（1）因为创建一个对象时需要确定对象的类型，而虚函数是在运行时确定其类型的。而在构造一个对象时，由于对象还未创建成功，编译器无法知道对象的实际类型是类本身还是类的派生类。

（2）虚函数的调用需要虚函数表指针，而该指针存放在对象的内存空间中；若构造函数声明为虚函数，那么由于对象还未创建，还没有内存空间，也就没有虚函数表地址用来调用虚函数即构造函数。

**<mark>9.构造函数或析构函数中调用虚函数会怎样</mark>**

语法上没有问题，但会失去多态性。

如果在构造或析构函数中调用虚函数，会先调用父类中的实现。

因为构造函数没有将虚函数指针和虚函数表初始化完毕，就调用了虚函数，此时必然调用基类中的实现。

析构函数中，则因为子类的那部分已经析构掉了，此时在父类的析构函数中调用虚函数，调用的也只能是父类中的实现。

**<mark>10.c++编译过程</mark>**

主要分为预处理，编译，汇编，链接

预处理阶段：主要处理源代码中#开头的预处理指令，如#include，将文件内容替换到它的位置；删除所有#define，展开所有宏定义等。生成.i文件

编译阶段：将.i文件翻译成文本文件.s ,生成汇编语言程序。每条语句都以标准的文本格式确切描述一条低级机器语言指令。

汇编阶段：汇编器将.s 翻译成机器语言指令。把这些指令打包成可重定位的目标程序，生成.o文件。它是一个二进制文件，它的字节码是机器语言指令，不再是字符。前面俩个阶段都还有字符。

链接阶段：将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接

之所要经过预处理，编译，汇编这么一系列步骤才生成目标文件，是因为在每一个阶段都有相应的优化技术，只有在每个阶段分别优化并生成最为高效的机器指令才能达到最大的优化效果，如果一步到位直接从源程序生成目标文件，可能就会失去很多代码优化的机会。

**<mark>11.静态链接，动态链接</mark>**

静态链接就是把Lib文件中用到的函数代码直接链接进目标程序，程序运行时不再需要调用其它的库文件；

动态链接就是把调用的函数所在文件模块（DLL）和调用函数在文件中的位置等信息链接进目标程序，程序运行时再从DLL中寻找相应函数代码，因此需要相应DLL文件的支持

静态链接：

空间浪费：每个可执行文件对所有需要的目标文件都要有一份副本

更新速度：每当库函数代码修改了，需要重新编译链接形成可执行程序

运行效率：因为在可执行程序中已经具备了所有执行程序所需要的东西，在执行的时候运行速度快。

动态链接：

空间少：多个程序在执行时共享同一份副本。

更新速度快：只需要替换原来的目标文件，不需要重新编译链接。

性能损耗大：因为把链接推迟到了运行时。     

**<mark>12.map和unordered_map区别</mark>**

有序，无序；

红黑树，哈希表；

查询和增删效率：map为O(logn) ，unmap为O（1）。

**<mark>13.inline函数</mark>**

（1）由inline关键字定义，引入inline函数主要是为了替代C中复杂易错不易维护的宏函数

（2）编译器在编译阶段完成对inline函数的处理，即把inline函数的调用替换为函数的本体。inline只是对编译器的一种建议，编译器可以不去做。

**优点**：

（1）省去了参数压栈，栈帧开辟与回收，结果返回等，提高运行速度

（2）与宏定义相比，在代码展开时，会做安全检查或自动类型转换

（3）在类中声明同时定义的成员函数，会自动转化为内联函数，因此可以访问类的成员变量，宏定义则不能

（4）在运行时可调试，宏定义不能。

**缺点**：

（1）代码膨胀，inline函数带来的运行效率是典型的空间换时间的做法，内联是以函数膨胀为代价，消除函数调用带来的开销，如果执行函数体内代码的时间，相比函数调用的开销较大，那么效率的收获会很少。且每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。

（2）inline函数不会随着库函数的升级而升级，必须重新编译。如果是non-inline的，用户只需要重新链接。

（3）是否内联不可控

**<mark>14.webserver项目的作用</mark>**

一个webserver就是一个服务器软件。主要功能是通过HTTP协议与客户端（通常是浏览器）进行通信，来接收，存储，处理来自客户端的HTTP请求，并对其请求做出HTTP响应，返回给客户端其请求的内容或返回一个ERROR信息，可实现上万的并发连接。

**<mark>15.reactor高并发</mark>**

IO多路复用监听事件，收到事件后，根据事件类型分配给某个进程/线程。

reactor模式主要由reactor和处理资源池这两个核心部分组成，其中：

Reactor负责监听和分发事件，事件类型包含连接事件，读写事件；

处理资源池负责处理事件，如read-业务逻辑-send

经典方案有：单reactor单进程/线程；单reacto多进程/线程；多reactor多进程/线程

假设当前进程中有三个对象，分别是Reactor、acceptor、Handler。

其中reactor负责监听和分发事件；acceptor负责获取连接；handler负责处理业务逻辑

**单单**：（1）reactor通过IO多路复用接口监听事件，根据事件的类型决定分发给acceptor还是handler处理

（2）如果是连接建立的事件，则交由Acceptor对象处理，accptor对象会通过accept系统调用来获取连接，并创建一个handler对象来处理后续的响应事件

（3）如果不是连接建立的事件，则交由当前连接对应的Handler对象来进行响应

（4）handler对象通过read-业务处理-send的流程来完成完整的业务流程。

优点：实现简单，不用考虑进程间通信，以及多进程竞争

缺点：无法充分利用多核CPU；Handler在进行业务处理时，整个进程是无法处理其他连接事件的。如果业务处理耗时较长，就会造成响应的延迟。

**单多**：（1）（2）（3）同单单

（4）handler对象不再负责业务逻辑的处理，只负责数据的接收和发送。Handler对象通过read读取到数据后，会将数据发给子线程里的processor对象进行业务处理。

子线程里的Processor对象处理完后，将结果发送给主线程里的handler对象，handler对象再通过send方法将响应结果发给client

优点：能充分利用多核CPU性能

缺点：一个reactor对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能瓶颈的地方。

**多多**：（1）主线程中的MainReactor对象通过IO多路复用接口监听连接建立事件，收到事件后通过acceptor对象中的accept获取连接，将新的连接分配某个子线程

（2）子线程中的SubReactor对象将MainReactor对象分配的连接加入IO多路复用接口继续监听，并创建一个Handler用于处理连接的响应事件。

（3）如果有新的事件发生，Subreactor通知当前连接对应的Handler对象来进行响应

（4）Handler对象通过read-业务处理-send的流程来完成完整的业务流程

优点：实现简单，主线程子线程分工明确，主线程和子线程交互简单。

**<mark>16.半同步/半反应堆模式</mark>**

（1）半同步/半反应堆模式是半同步/半异步模式的变体，将半异步具体化为某种事件处理模式

（2）并发模式中的同步指的是程序完全按照代码的顺序执行

异步指的是程序的执行需要由系统事件驱动。

（3）工作流程：

（a）主线程充当异步线程，负责监听所有socket上的事件

（b）若有新请求到来，主线程接收得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件

（c）如果socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成请求对象插入到请求队列中

（d）所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。

**<mark>17.IO多路复用技术</mark>**

即 使用一个进程来维护多个Socket的方式。

一个进程虽然任一时刻只能处理一个请求，但是如果处理每个请求事件的耗时控制在1毫秒以内，则1秒就可以处理上千个请求，把时间拉长了看，就是多个请求复用了一个进程，这就是多路复用，这种思想很类似与一个CPU并发多个进程，所以也叫时分多路复用。

linux内核提供了select/poll/epoll这三个多路复用的系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。

select/poll/epoll在获取事件时，先把所有的连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求。

**<mark>18.为什么使用EPOLL</mark>**

select：使用固定长度的bitsmap来表示文件描述符集合，他支持的文件描述符个数是有限制的，在Linux系统中，默认最大值为1024。

poll：使用动态数组来存储，以链表形式来组织，突破了select文件描述符个数限制

他们俩并没有太大的本质区别，都是使用线性结构来存储sokcet集合，因此都需要遍历文件描述符集合来找到可读或可写的Socket，时间复杂度为O(n)，而且都需要在用户态和内核态之间拷贝文件描述符集合，这种方式随着并发数的增加，性能的损耗会成指数增长。

epoll通过俩个方面，很好的解决了select和poll的问题

（1）epoll在内核中维护了一棵红黑树，可以保存所有待检测的socket，所以每次只需要传入一个待检测的socket，而不需要传入整个socket集合，减少了内核和用户空间大量的数据拷贝和内存分配。

（2）epoll使用事件驱动的机制，在内核里维护了一个链表来记录就绪事件，当某个socket有事件发生时，通过回调函数内核会将其加入到就绪事件链表中，当用户调用epoll_wait函数时，只返回有事件发生的文件描述符个数，这样就不需要像select/poll那样遍历整个集合，大大提高了检测的效率。

**<mark>19.void*的作用</mark>**

void*定义一个指针变量，但不说明他指向哪一种类型。即这个指针变量只有地址，没有大小。

（1）可以作为函数模板，链表等参数的通用参数，使用时，只需要强制类型转换就可以。

（2）可以用来表示指向全是0的地址 (void*)0, 相当于NULL

**<mark>20.函数中声明的不是malloc的数组怎么返回</mark>**

（1）声明一个静态数组，并返回一个指针。静态数组在超出范围时不会被释放，但他不安全，因为当下一次调用该函数时，将覆盖该数组，在多线程中使用更加糟糕。

（2）在调用函数时传入数组地址，在主函数中定义一个数组，然后在调用自定义函数时，将该数组的地址当作参数传入，并在自定义函数生命周期结束后将其内容返回。

**<mark>21.常见的内存泄漏情况。如果程序员不犯错，还有哪些情况会造成内存泄漏</mark>**

（1）在类的构造和析构函数中没有匹配的调用new和delete

（2）没有正确的清除嵌套的对象指针。如在一个对象的成员变量为另一个对象的指针。

（3）在释放对象数组时在delete中没有使用方括号

（4）释放指向对象的指针数组时，只释放了对象空间，没有释放指针空间。

指针数组是指：数组中存放的是对象，只需要调用delete[]，即可调用对象数组中每个对象的析构函数释放空间

指向对象的指针数组是指：数组中存放的是指向对象的指针，不仅要释放每个对象的空间，还要释放每个指针的空间。

（5）缺少拷贝构造函数和重载赋值运算符。默认的是浅拷贝，如果有成员变量是指针，会造成俩个指针指向同一块空间，在释放空间时就会俩次释放同一块空间。所以要么重写拷贝构造函数和重载赋值运算符，要么将他们禁用。

（6）没有将基类的析构函数定义为虚函数。

除了编程错误：

（1）操作系统或硬件的限制

（2）程序使用的某些软件库或者插件

（3）使用效率低下的算法，消耗超过必要的内存

（4）在高负载和压力测试下。

内存泄漏分为：

（1）堆内存泄漏，我们经常说的内存泄漏就是堆内存泄漏，在堆上申请了资源，用完后却没有释放，从而导致该块内存永远不可用。

（2）资源泄漏，通常指的是系统资源，如socket，文件描述符等，因为这些在操作系统中都是有限制的，如果创建了而不归还，久而久之就会耗尽资源。

**<mark>22.匿名函数和函数指针的区别</mark>**

Lambda函数的引入主要就是为了消除使用函数指针的复杂性。要使用函数指针，需要创建一个单独的函数，之后创建指向该函数的函数指针，并将其作为参数传递给所需的函数。

而使用函数指针执行的任务很小，一般不值得写那么多行代码。Lambda函数可以更轻松地完成相同的任务。

匿名函数是动态创建的，不与特定的内存位置相关联，而函数指针被显式定义为保存特定函数在内存中的地址的变量。匿名函数通常用于高阶函数，而函数指针更常用于回调。

**<mark>23.vector, list, map, unordered_map各自的特点和原理</mark>**

vector和list：

（1）vector底层通过数组实现，存储空间上一段连续的内存空间；list通过双向链表实现，把不连续的内存空间通过链表的方式连接在一起。

（2）vector插入删除操作需要移动元素，时间复杂度为ON，而list为O(1)

（3）vector支持随机访问，时间复杂度O(1)， list不支持，需要遍历整个链表来查询，为O(N)

（4）vector空间不足时需要另开辟一个俩倍于当前空间大小的空间，然后将原有的元素复制过去，再析构原空间，会造成原有的迭代器失效。list在每次插入和删除的时候分配和释放空间，所以不会引起迭代器失效。

map和unordered_map：

（1）map的底层是红黑树，unordered_map 是哈希表。

（2）所以map的增删、查找时间复杂度为Ologn，unordered_map为O1。

（3）map的key有序，unordered_map无序。

**<mark>24.vector怎么实现扩容</mark>**

若空间不足，会申请一块2倍于当前大小的新内存，然后把旧内存的元素拷贝至新内存空间，并释放旧内存空间，此时原有的迭代器都指向原空间，因此会失效。

**<mark>25.怎么降低vector扩容次数</mark>**

（1）使用reserve预分配足够大的空间

（2）选择合理的初始容量

**<mark>26.reserve和resize区别</mark>**

resize是用来改变容器里的元素个数，如果参数大于当前元素个数，则新增默认0元素直到元素个数等于参数，如果小于则截断

reserve则用来改变当前容器的最大容量，他不会生成新元素，只是确定这个容器允许放入多少对象，如果参数len大于当前的capacity，那么会开辟一个新的len大小的空间，将之前的对象复制过来，并销毁旧空间。

**<mark>27.map为什么采用红黑树，不采用AVL树</mark>**

因为红黑树在效率和简单性之间提供了良好的平衡。

红黑树确保没有一条路径会比其他路径长出两倍，因此红黑树是一种弱平衡树，相对于要求严格的AVL树来说，旋转次数更少。AVL树比红黑树更加平衡，意味着他需要更加频繁的旋转来维护。

因此AVL树一般适用于读取查找密集型任务。而红黑树适用于插入修改密集型任务。

**<mark>28.TCP三次握手</mark>**

（1）一开始，客户端和服务端都处于closed状态。先是服务端主动监听某个端口，处于LISTEN状态。

（2）客户端随机初始化一个序列号（client_isn)，将此序号置于TCP首部的序列号字段中，同时把SYN标志位置为1，表示SYN报文。接着把第一个SYN报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于SYN-SENT状态。

（3）服务端收到客户端的SYN报文后，首先服务端也随机初始化自己的序列号（server_isn），将此序号填入TCP首部的序列号字段中，其次把TCP首部的确认应答号字段填入client_isn+ 1，接着把SYN和ACK标志位置为1，最后把该报文发给客户端，该报文不包含应用层数据。之后服务端处于SYN-RCVD状态。

（4）客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文TCP首部ACK标志位置为1，其次确认应答号字段填入server_isn + 1，最后把报文发送给服务端，这次报文可以携带客户端到服务端的数据，之后客户端处于ESTABLISHED状态。

（5）服务端收到客户端的应答报文后，也进入ESTABLISHED状态。

**<mark>29.TCP四次挥手</mark>**

（1）客户端打算关闭连接，此时会发送一个TCP首部FIN标志位被置为1的报文，也即FIN报文，之后客户端进入FIN_WAIT_1状态。

（2）服务端收到FIN报文后，就向客户端发送ACK应答报文，接着服务端进入CLOSE_WAIT状态。

（3）客户端收到服务端的ACK应答报文后，进入FIN_WAIT_2状态。

（4）等待服务端处理完数据后，也向客户端发送FIN报文，之后服务端进入LAST_ACK状态。

（5）客户端收到服务端的FIN报文后，回一个ACK报文，之后进入TIME_WAIT状态

（6）服务端收到了ACK应答报文，就进入了CLOSE状态，至此服务端已经完成连接的关闭。

（7）客户端在经过2MSL时间后，自动进入CLOSE状态，至此客户端也完成连接的关闭。

**<mark>30.三个门，两个门后面是羊，一个门后面是车，现在你选择一个门</mark>**

**<mark>主持人会给你打开一个不是车的门，你有一次换门的机会</mark>**

**<mark>请问，是否要换？(是否会提升你的中奖概率)</mark>**

换。只有第一次选对了，不换才能中奖，而第一次选对的概率为1/3，所以换比不换合适

**<mark>31.c++的static和const的区别</mark>**

（1）修饰局部变量：

const修饰的局部变量为只读，其值不可以修改。

static修饰局部变量则改变了它的生命周期，让静态局部变量在出了作用域后仍然存在，到程序结束，生命周期才结束。

（2）修饰全局变量：

如果修饰的全局变量只在一个文件中使用，那么const的作用和局部变量处的作用一样。

一个全局变量被static修饰，则使得这个全局变量只能在本源文件中使用，不能在其他源文件使用

（3）修饰类成员变量

const修饰类成员变量与修饰全局和局部变量类似，其在使用时不能被修改，因此必须使用构造函数初始化列表进行初始化。

static修饰的类成员变量，必须在类外定义，定义时不添加static关键字，但需要添加作用域限定符声明。静态成员变量不属于某个单独的对象，而属于类所有。所有对象共享静态成员变量。

（4）修饰类成员函数

const修饰类的成员函数，实际修饰该成员函数隐含的this指针，表明在该成员函数中不能对类的任何成员变量进行修改，但也可以在某些变量前加上mutable关键字，使其可以被修改。

static修饰的类成员函数，也被所有的类对象所共享，不属于某个具体的实例。没有this指针，不能访问任何非静态成员。

（5）修饰类对象和类

const修饰类对象，对象中的变量均不可被修改，其只能调用const成员函数，非const对象既可以调用普通成员函数，也可以调用const成员函数。

static不能修饰一个普通类，但是可以修饰内部类，被修饰的内部类可以被当成一个普通类来使用，不需要先实例化一个外部类。

**<mark>32.进程和线程的区别</mark>**

调度：线程是程序执行的基本单位。进程是拥有资源的基本单位。

并发性：不同进程之间切换实现并发，各自占有CPU实现并行；一个进程内部的多个线程并发。

拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享属于进程的资源；进程是拥有资源的独立单位。

系统开销：线程切换时只需保存和设置少量寄存器内容，因此开销很小；进程需要切换虚拟地址空间，切换内核栈和硬件上下文等，开销很大。

**<mark>33.Linux中为什么设计了内核态和用户态</mark>**

出于保护机制，防止用户进程误操作或者是恶意破坏系统。内核态类似于c++的私有成员，只能在类内访问，用户态类似于公有成员，可以随意访问。

在CPU的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。如果允许所有的程序使用这些指令，那么系统的崩溃概率将大大增加，所以CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成危险的指令。

**<mark>34.有什么方式进行内核态和用户态的切换</mark>**

（1）系统调用。

由于用户态无法完成某些任务，所以会请求切换到内核态，内核态将通过为用户专门开放的中断完成切换。

（2）出现异常

在执行用户程序时出现某些不可知的异常时，会从用户程序切换到内核中处理该异常的程序，也就是切换到了内核态。

（3）外围设备中断。

外围设备发出中断信号，当中断发生后，当前运行的进程暂停运行，并由操作系统内核对中断进程处理，如果中断之前CPU执行的是用户态程序，就相当于从用户态切换到了内核态。

**<mark>35.4亿数据中找出几个数</mark>**

1.分治法。

对这4亿个数进行哈希运算，按照某个特征划分为多个小文件，然后将小文件直接读取到内存中进行遍历。

2.外排序+归并

也是将大文件分成多个内存足够容纳的小文件，然后对这些分片文件分别内部排序，最后通过归并算法将这些片段文件合并后通过二分搜索来寻找目标数。

**<mark>36.设计一个strcpy函数。dest长度不够怎么办。拷贝用memcpy，释放空指针，结尾补'\0'</mark>**

```
函数原型：char * strcpy(char* dest, const char* src) 
//将src复制到dest字符数组中
头文件：#include <string.h>
返回值：返回的是第一个参数的值，即目的数组的首地址

注意点：
1、strcpy只用于字符串复制，遇到‘\0’时停止，还会复制字符串的结束符‘\0’.
所以源字符串必须以‘\0’结束。
2、目标空间必须可变。
3、如果参数dest所指的内存空间不够大，可能会造成缓冲溢出的错误情况，在编写程序时
需特别留意，或者用strncpy（）来代替。


strncpy不会向dest追加结束标记'\0'


函数实现1：
char * mystr(char* dest, const char* src) {
    char* ret = dest;
    while(*src != '\0') {
        *dest = *src;
        dest++;
        src++;
    }
    *dest = *src; //复制'\0'
    return ret;
}


函数实现2：
char * mystr(char* dest, const char* src) {
    assert(dest != NULL && src != NULL)；
    if(dest == NULL || src == NULL) return NULL;
    if(dest == src) return dest;

    char* ret = dest;
    while(*dest++ = *src++) {
        ;
    }
    *dest = *src;
    return ret;
}
```

**<mark>37.strlen和sizeof的区别</mark>**

（1）sizeof是运算符，不是函数，结果是在编译时得到而非运行中获得，strlen是字符处理的库函数

（2）sizeof参数可以是任何数据的类型或者数据；strlen的参数只能是字符指针且结尾是‘\\0’

的字符串

（3）因为sizeof是在编译时确定，所以不能用来得到动态分配（运行时分配）的存储空间的大小。

**<mark>38.内存管理中堆和栈的区别</mark>**

（1）申请方式不同：

栈由系统自动分配，堆是由我们自己申请和释放的

（2）申请大小限制不同：

栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，ulimit -s修改。

堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。

（3）申请效率不同：

栈由系统分配，速度快，不会有碎片。

堆由程序员分配，速度慢，会有内存碎片。

**<mark>39.栈与队列的区别</mark>**

（1）队列先进先出，栈先进后出。

（2）对插入和删除操作的限制不同：

栈是只能在表的一端进行插入和删除操作的线性表。

队列是只能在表的一端进行插入和在另一端进行删除操作的线性表。

（3）遍历数据速度不同：

栈只能从头部取数据，也就是最先放入的需要遍历整个栈最后才能取出来，而且在遍历数据的时候还得数据开辟临时空间，保持数据在遍历前的一致性。

队列则不同，队列可以通过从头部取出数据再放入尾部的方式来遍历数据，不需要额外的空间。

**<mark>40.static是全局变量吗？</mark>**

不一定

**<mark>41.封装、继承、多态</mark>**

**封装**：

就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让自己信任的类或对象操作，对不信任的进行信息隐藏。一个类就是封装了数据以及操作这些数据的代码的逻辑实体。

**继承**：

是指可以让某个类型的对象获得另一个类型的对象的属性的方法。派生类可以使用其父类的所有功能，并在无需重新编写父类的情况下对这些功能进行扩展。继承的过程，就是从一般到特殊的过程。

实现继承：子类直接使用父类的属性和方法，而无需额外编码

接口继承：子类只继承属性和方法的名称，并提供自己的实现方式

**多态**：

即一个接口，可以实现多个方法。就是向不同的对象发同一个消息，不同对象在接收时会产生不同的行为（即方法）。

多态与非多态的实质区别就是函数地址是早绑定还是晚绑定的，如果函数的调用，在编译期间就可以确定函数的调用地址，并产生代码，则是静态的，即地址早绑定。而如果函数的调用地址需要在运行时才能确定，则是晚绑定。

**<mark>42.你项目中哪一种指针用的比较多。</mark>**

shared_ptr

**<mark>43.socket如何建立</mark>**

**TCP**：

（1）服务端和客户端初始化socket，得到文件描述符。

（2）服务端调用bind，绑定IP地址和端口。

（3）服务端调用listen，进行监听。

（4）服务端调用accept，等待客户端连接。

（5）客户端调用connect，向服务端的地址和端口发起连接请求。

（6）服务端accept返回用于传输的socket的文件描述符。

（7）客户端调用write写入数据，服务端调用read读取数据。

（8）客户端断开连接时，会调用close，那么服务端read读取数据时，会读取到EOF，待处理完数据后，服务端调用close，表示连接关闭。

**bind函数**的作用主要是socket函数并没有为套接字绑定本地地址和端口号，服务端必须显式绑定地址和端口号。

**listen函数**的主要作用就是将套接字（sockfd）变成被动的连接监听套接字（被动等待客户端的连接），参数backlog用于设置内核中连接队列的长度。

**accept函数**的功能是，从处于established状态的连接队列头部中取出一个已经完成的连接，如果没有则阻塞。

**connect**与三次握手直接相关。

**UDP**：

由于没有三次握手，所以不需要调用listen和connect。但是UDP交互仍需要IP地址和端口号，因此需要bind。

对于UDP来说，不需要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念。因此每一个UDP的socket都需要bind。

socket               socket

bind                   bind

sendto               sendto

recvfrom           recvfrom

**<mark>44.全连接队列，半连接队列</mark>**

![半连接队列与全连接队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg)

服务端收到客户端的SYN请求后，内核会把该连接存储到半连接队列，并向客户端响应SYN+ACK，接着客户端返回ACK，服务端收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的连接，并将其添加到全连接队列，等待进程调用accept函数时把连接取出来。

**<mark>45.TCP/IP模型</mark>**

应用层：主要为应用程序提供服务，工作在用户态，以下几层都工作在内核态。

传输层：包含TCP和UDP协议，负责建立、管理和维护端到端的连接。

网络层：负责IP选址和路由选择

网络接口层：也可分为数据链路层和物理层，主要为网络层提供链路级别的传输服务，负责在以太网、WiFi这样的底层网络上发送原始数据包。

**<mark>46.linux命令：chmod，scp，chattr，pgrep，awk</mark>**

**chmod**：改变文件或目录权限

**scp**：远程拷贝文件

scp root@www.runoob.com:/home/root/others/music /home/space/music/1.mp3

scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music

**chattr**：更改文件属性

用chattr命令防止系统中某个关键文件被修改：

chattr +i /etc/resolv.conf

**pgrep**：用于检索当前正在运行的进程

pgrep 命令中使用 `-l` 和 `-a` 选项可以列出与用户相关联的进程 id 和进程名。`-l` 选项将只列出进程名，而 `-a` 将列出进程名的完整路径。

```text
[root@linuxtechi ~]# pgrep -u apache -l
4353 httpd
4354 httpd
4355 httpd
4356 httpd
4357 httpd
4358 httpd
4359 httpd
4360 httpd
[root@linuxtechi ~]#

[root@linuxtechi ~]# pgrep -u apache -a
4353 /usr/sbin/httpd -DFOREGROUND
4354 /usr/sbin/httpd -DFOREGROUND
4355 /usr/sbin/httpd -DFOREGROUND
4356 /usr/sbin/httpd -DFOREGROUND
4357 /usr/sbin/httpd -DFOREGROUND
4358 /usr/sbin/httpd -DFOREGROUND
4359 /usr/sbin/httpd -DFOREGROUND
4360 /usr/sbin/httpd -DFOREGROUND
```

**awk**：文本和数据进行处理的编程语言

```
[root@dev01 yeyz_shell]# cat awk_test.txt 
this is a test file 
this is a test file 
this is a test file 
this is a test file 
this is a test file 
[root@dev01 yeyz_shell]# cat awk_test.txt | awk '{print $1,$2}'
this is
this is
this is
this is
this is
```

其中 awk '{print 1,2}'是指打印出这个文件的第一列和第二列。当我们不指定分隔符的时候，awk会默认按照空格来进行分割，当字符中间的空格有多个的时候，awk会将连续的空格理解为一个分隔符。

**<mark>47.如何后台运行程序</mark>**

（1）在命令的最后加上&，可以把这个命令放到后台执行

（2）ctrl+z可以挂起进程，进程处于暂停状态。使用**jobs**查看后台运行进程的序号，再使用**bg%序号** 在后台运行进程。

（3）nohup+&，将标准输出和标准错误缺省的话，会被重定向到nohup.out文件中，忽略所有SIGHUP信号。

**<mark>48.nohup和&区别</mark>**

在命令的末尾加&后，程序可以在后台运行，但一旦当前终端关闭，该程序就会停止运行。

那么假如我们想要退出当前终端，但又想让程序在后台运行，就需要用nohup。

比如想远程到服务器编译程序，但网络不稳定，一旦掉线就编译中止，就需要重新开始编译，很浪费时间。

nohup就是不挂起的意思（no hang up）。一般形式为：

```
nohup ./test &
```

这样使用则程序的输出默认重定向到一个nohup.out文件下。

```
nohup ./test > myout.txt 2>&1 &
```

2>&1 是指将标准错误重定向到标准输出，于是标准错误和标准输出都重定向到指定的myout.txt文件中。

使用nohup之后，需要使用exit正常退出当前账户，这样才能保证命令一直在后台运行。

**<mark>49.vector和list遍历哪个快</mark>**

vector为随机访问容器，数据在内存连续分布，cache miss概率小，而list通过头尾指针遍历，遍历时需要跳转，内存分布不连续，cache miss概率大，所以理论上vector更快。

**<mark>50.指针和引用的区别</mark>**

（1）指针是一个变量，存储一个地址，引用是原变量的别名

（2）指针可以有多级，引用只有一级

（3）指针可以为空，且可以先声明而不初始化，引用不能为NULL且在定义时必须初始化

（4）指针在初始化后可以改变其指向，引用在初始化之后不可以再改变

（5）sizeof指针得到的是这个指针的大小，sizeof引用得到的是引用所指向变量的大小

（6）当把指针作为参数进行传递时，也就是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，改变形参的指向对实参没有影响。而引用却可以。

**<mark>51.说一下缺页中断</mark>**

（1）概念：缺页中断就是当软件试图访问一个已经映射在虚拟地址空间中，但并未加载到物理内存中的分页时，由中央处理器的内存管理单元所发出的中断。

（2）分类：

**软性页缺失**：指页缺失发生时，相关的页已经被加载进内存，但是没有向MMU注册的情况，操作系统只需要在MMU中注册相关页对应的物理地址即可。（MMU：内存管理单元，负责将虚拟内存地址转换成物理地址）。

**硬性页缺失**：相关的页在页缺失发生时未被加载进内存的情况。

**无效页缺失**：当程序访问的虚拟地址是不存在于虚拟地址空间内的时候，则发生无效页缺失。

（3）中断：指计算机在执行程序的过程中，当出现异常情况或特殊请求时，计算机停止现在运行的程序，转向对这些异常情况或特殊请求的处理，处理结束后再返回程序暂停前的位置，继续运行程序。

具体的缺页中断处理也分为两类：

第一类是内存中还有空闲块，则直接将缺页从外存中调入内存；

第二类是内存已满，需要采用页面置换算法淘汰某页再进行调入。（最佳页面置换算法，FIFO，最近最久未使用，时钟，最不常用）

**<mark>52.TCP在哪一层</mark>**

传输层

**<mark>53.HTTP基于什么</mark>**

http协议是基于TCP/IP协议之上的应用层协议

基于请求-响应模型

**<mark>54.输入域名到页面渲染经历了什么</mark>**

（1）解析URL，生成发送给WEB服务器的HTTP请求信息。

（2）查询服务器域名对应的IP地址，如果缓存中有对应域名的缓存，就直接返回，没有就需要通过DNS服务器来解析

（3）通过DNS获取到IP后，就可以把HTTP的传输工作交给操作系统中的协议栈。

（4）协议栈上半部分是TCP/UDP协议，执行收发数据的操作，下半部分是IP协议，控制网络包的收发。

（5）首先通过三次握手建立TCP连接，将请求报文加上TCP、IP、MAC头部。

（6）然后浏览器向WEB服务器发送HTTP请求

（7）服务器收到请求后，进行对应的处理，把数据传给浏览器，也就是返回网络响应。

（8）完成以上过程后，数据已经到达浏览器端，接下来浏览器解析并渲染数据。

**<mark>55.B+ Tree</mark>**

B+树是一棵自平衡的多叉树。

（1）它只有叶子节点才存放数据（索引+记录），非叶子节点只存放索引。

（2）父节点的所有索引都包含在子节点中

（3）叶子节点保存所有的索引信息，并且叶子节点构成一个单向的有序链表。在INNODB存储引擎中有俩个指针，分别指向下一个和上一个叶子节点，形成双向链表。可以提高范围搜索的效率。

查询方式：

（1）单点查询：由于B+树的非叶子节点不存放实际的记录数据，仅存放索引，这样每个节点可容纳的元素个数多，所以它的深度很低，查询到底层节点的磁盘IO次数很少。

（2）插入和删除效率：B+树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，删除效率高。插入可能存在节点的分裂，但是最多只涉及树的一条路径。

（3）范围查询：双向链表，范围查询速度快

**<mark>56.红黑树原理</mark>**

红黑树在效率和简单性之间提供了良好的平衡。

红黑树是一种特殊的二叉查找树，每个节点都要存储节点的颜色，或红或黑。

它具有5个特性：

（1）每个节点或红或黑

（2）根节点是黑色

（3）空叶子节点是黑色

（4）如果一个节点是红色，那么它的子节点是黑色。

（5）从任意一个节点出发到空的叶子节点经过的黑节点个数相同

红黑树的任何一个节点的左右子树的高度差不会超过俩倍。

通过左旋右旋以及重新着色的操作来维持上述特性。

**<mark>57.O(logn)复杂度查询的数据结构</mark>**

（1）二叉搜索树。

和二分查找一样，插入和查询为O(logn)，但由于插入和删除操作时不保证平衡，所以最坏为O(n)。

（2）二叉平衡树

总是保持平衡，查找、插入、删除在最坏情况下都是O(logn)

（3）二叉伸展树

在每次查找后对树进行重构，把被查找的条目搬到离树根近的地方，但不保证最坏情况下O（logn）复杂度。

（4）跳表

跳表是一个多级索引的链表结构，从顶层链表开始搜索，直到找到一个大于等于目标的元素，或到达尾部。如果等于，则目标已经被找到，如果大于，则退回当前层的前一个元素，然后转入下一层搜索。![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430132656662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MDc4NQ==,size_16,color_FFFFFF,t_70)

（5）数组

二分查找

**<mark>58.4种隔离级别</mark>**

多个事务并发执行时可能会遇到【脏读，不可重复读，幻读】的现象。

脏读：读到其他事务未提交的数据；

不可重复读：前后读取的数据不一致；

幻读：前后读取的记录数量不一致。

SQL标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能越低

（1）读未提交：指一个事务还没提交时，他做的变更就能被其他事务看到

（2）读提交：指一个事务提交之后，他做的变更才能被其他事务看到

（3）可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的。MySQL InnoDB默认隔离级别

（4）串行化：对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突，后访问的事务必须等前一个事务执行完成，才能继续执行

在【读未提交】隔离级别下，可能发生脏读、不可重复读和幻读。

【读提交】：不可重复读，幻读

【可重复读】：幻读

【串行化】：都不会发生

**<mark>59.讲一下协程</mark>**

协程是用户态的轻量级线程，是线程内部调度的基本单位。

同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理。

它直接操作栈，基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快，可以通过共享内存和消息队列来通信。

**<mark>60.条件变量怎么用，说一个使用情况</mark>**

条件变量（cond）和锁（mutex）是紧密相关的。

锁的使用场景是：一件事同时只有一个人能做，我抢到锁我就进去操作，操作完毕后再给下一个人做。

而使用条件变量的场景是：

（1）首先，这件事还是同时只能一个人做，所以还要用到锁，但线程抢到锁之后，发现还要等待一些条件满足，才能做。

（2）这时如果让抢到锁的线程一直循环不停检查这个条件，不仅消耗高，而且每次检查完为了不让CPU一直空跑，需要sleep一下，而sleep的时间如果定少了，则消耗高，定的太大，则有延迟，无法即时发现条件满足了。而且抢到锁后一直检查，别的线程就拿不到锁了。

（3）所以引入了条件变量，抢到锁的线程发现条件未满足时，释放锁，使用pthread_cond_wait()挂起自己。这时别的线程也能获取锁进来，发现条件不满足同样挂起。直到条件满足后，由其他地方调用pthread_cond_broadcast()来唤醒全部挂起的线程，或调用pthread_cond_signal()来唤醒指定线程.

**使用情况**：消费者生产者模型

（1）生产者和消费者都需要操作同一个队列，同一时间只能由一个人操作

（2）消费者需要等待生产者生产完毕后，才能进行消费，所以消费者是pthread_cond_wait等待的那一方，生产者是pthread_cond_broadcast通知的那一方。

**<mark>61.构造函数能不能声明为虚函数</mark>**

同8

**<mark>62.动态链接库</mark>**

动态链接库（DLL）是一个包含函数和数据的模块，它可以被其他模块使用

在DLL中可以定义俩种函数：导出函数和内部函数。

导出函数可以被其他模块调用，内部函数一般而言用于DLL内部。DLL中定义的数据一般只在DLL内使用。

DLL提供了一种模块化应用程序的方法，在多个程序中同时使用相同的函数时，使用DLL有助于减少内存占用。

**<mark>63.c++中一个子类最多可以继承多少个父类</mark>**

c++中一个子类可以继承多个父类，对可以继承的父类数量没有具体限制。但是通常建议限制父类的数量，以避免复杂性和可维护性问题。

**<mark>64.工厂模式</mark>**

用一个简单的类来创建实例的过程就称为工厂，用工厂方式代替外部new操作的一种设计模式称为工厂模式。它是一种创建型的模式，提供了一个创建对象的最佳方法。在工厂模式中，我们创建对象时不会对上层暴露创建逻辑，

分类：简单工厂模式，工厂方法模式，抽象工厂模式

**简单工厂模式**：

简单工厂模式由一个工厂类根据传入的参数，动态决定应该创建哪一种产品类实例。

```
#include <iostream>
#include <vector>
#include <algorithm>
#include <queue>
#include <string>
#include <cmath>
#include <assert.h>
using namespace std;

class operation {
public:
    operation(){}
    virtual int getResult(int num1, int num2) = 0; //设置为纯虚函数，不可以生成该类的对象，但可以声明该类的指针
};

class operationAdd: public operation{
    int getResult(int num1, int num2) {
        return num1 + num2;
    }
};

class operationSub : public operation {
    int getResult(int num1, int num2) {
        return num1 - num2;
    }
};

class operationMult : public operation {
    int getResult(int num1, int num2) {
        return num1 * num2;
    }
};

class operationDiv : public operation {
    int getResult(int num1, int num2) {
        assert(num2 != 0);
        return num1 / num2;
    }
};

class OperationFactory { //工厂
public:
    operation* createOperate(char operate) {
        operation* oper = NULL;
        switch (operate) 
        {
            case '+': {
                oper = new operationAdd();
                return oper;
            }
            case '-': {
                oper = new operationSub();
                return oper;
            }
            case '*': {
                oper = new operationMult();
                return oper;
            }
            case '/': {
                oper = new operationDiv();
                return oper;
            }
        }
    }
};

int main() {
    int num1 = 0;
    int num2 = 0;
    char operate;
    cin >> num1 >> operate >> num2;
    operation* oper;
    OperationFactory fac;
    oper = fac.createOperate(operate);
    int res = oper->getResult(num1, num2);

    cout << res << endl;
}
```

[工厂模式（C++编码） - HOracle - 博客园](https://www.cnblogs.com/horacle/p/15494358.html)

**<mark>65.单例模式</mark>**

是为了保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。

**懒汉版**：单例实例在第一次被使用时才初始化。

```
class A{
private: 
    A() {} //私有构造函数，无法直接创建对象
    static A* instance;
public:
    static A* Getinstance() {
        if (instance == NULL) {
            instance = new A();
        }
        return instance;

    }
};

A* A::instance = NULL;

int main() {
    A* a1 = A::Getinstance();
    A* a2 = A::Getinstance();
    if (a1 == a2) cout << 1111 << endl;

}
```

线程安全问题：

（1）首先想到可以加锁：

```
static Singleton* getInstance() {
    Lock lock;  // 基于作用域的加锁，超出作用域，自动调用析构函数解锁
    if(instance == NULL) {
        instance = new Singleton();
    }
    return instance;
}
//这种方法锁的代价过高
```

```
static Singleton* getInstance() {
    if(instance == NULL) {
        Lock lock;  // 基于作用域的加锁，超出作用域，自动调用析构函数解锁
        if(instance == NULL) {
            instance = new Singleton();
        }
    }
    return instance;
}
//双检查锁，先检查是否为空，空的话才加锁
/*但由于内存读写reorder不安全，所以不能用
对于instance = new Singleton();这一行代码
我们默认的顺序是，先分配内存，再调用构造函数进行初始化，然后将这块内存的首地址返回给
instance。
但在CPU层面，这三个步骤有可能会被reorder。
执行的顺序有可能会变成：（1）先分配内存 （2）然后就将内存返回 （3）最后再调用构造函数
那么此时第二步执行完后instance就不等于NULL了，如果此时另一个线程进来，
判断instance ！= NULL，然后直接返回instance进行使用，就会产生错误。
因为此时的instance还未被构造出来，不可以使用。
*/
```

（2）更好的方式：C++11规定了local static在多线程条件下的初始化行为，要求编译器保证了内部静态变量的线程安全性。static在局部变量使用时初次定义就要初始化，且只能初始化一次，重复调用同一函数，第二次调用时不会执行static局部变量初始化的那句话。

```
// version 1.2
class Singleton
{
private:
    Singleton() { };
    ~Singleton() { };
    Singleton(const Singleton&);
    Singleton& operator=(const Singleton&);
public:
    static Singleton& getInstance() 
    {
        static Singleton instance;
        return instance;
    }
};
```

内存泄漏问题：

注意到第一种基础写法中，类中new出对象之后，没有调用delete释放，因此只有构造函数被调用，析构函数没有被调用，因此会造成内存泄漏。

解决方法：

（1）使用共享指针。

（2）使用局部静态变量，同线程下的（2）

[C++ 单例模式总结与剖析 - 一杯清酒邀明月 - 博客园](https://www.cnblogs.com/ybqjymy/p/14921444.html)

**饿汉版**：

```
//饿汉模式，没有线程安全问题，无需加锁
class singleHungry
{
private:
    int dataA;
    int dataB;
private:
    //构造函数私有化
    singleHungry(int a, int b):dataA(a),dataB(b){} 

    //禁用默认拷贝构造、赋值运算符函数
    singleHungry(const singleHungry& s) = delete;
    singleHungry& operator= (const singleHungry& s) = delete;
public:
    ~singleHungry(){}
    static singleHungry s_instacne;
    static singleHungry& getInstacne();

    //业务逻辑
    int getAddResult()
    {
        int result = dataA + dataB;
        cout<<"add result = "<<result<<endl;
        return result;
    }
};

//静态变量需要在类外进行初始化，由于对象是静态变量，存储在静态存储区，无需人为回收，进程结束自动回收内存
singleHungry singleHungry::s_instacne(1,2);
singleHungry& singleHungry::getInstacne()
{
    return s_instacne;
}
```

潜在问题在于static singleHungry s_instance 和 getAddResult二者初始化顺序不确定，如果在初始化完成之前调用getInstance方法会返回一个未定义的实例。

**<mark>66.malloc之后怎么在里面创建一个指针变量</mark>**

```
int** pptr = (int**)malloc(n * sizeof(int*);//分配一块内存用来存放指针变量

int* ptr = (int*)malloc(sizeof(int));//分配一块内存

*pptr = ptr;

cout << *ptr << endl; //ptr 指向的地址的值
cout << &ptr << endl;//ptr 本身的地址
cout << ptr << endl;//ptr 指向的地址
```

首先分配一块内存用来存放指针变量，pptr指向一块能够存放n个int* 类型的空间。然后将ptr指向的地址作为pptr指向的地址的值，即pptr所指向的空间里面存放的是ptr这个指针变量。

**<mark>67.接口怎么设计</mark>**

（1）需要确保如果客户企图使用某个接口而却没有获得他所预期的行为，这个代码就不应该通过编译；如果代码通过了编译，那它的行为就是客户想要的。

```
class Date
{
public:
    Date(int month, int day, int year);
    …
};
```

这个类做了一个假设---用户都能按月，日，年的顺序来传参。但一定会有不少用户记错这个顺序。

一种好的解决方法是，假定用户输入的数据都是不可靠的，需要对输入进行严格的检查。并提供好的引导方式，让用户知道自己传的是什么参数。

```
class Month
{
private:
    int m_month;
public:
    explicit Month(int month): m_month(month){}
};

class Day
{
private:
    int m_day;
public:
    explicit Day(int day): m_day(day){}
};

class Year
{
private:
    int m_year;
public:
    explicit Year(int year): m_year(year){}
};

class Date
{
private:
    Year m_year;
    Month m_month;
    Day m_day;

public:
    Date(Year year, Month month, Day day): m_year(year), m_month(month), m_day(day){}

};

int main()
{
    Date date(Year(2013), Month(5), Day(28));
}
```

其中Year、Month、Day类中的构造函数前有explicit关键字，也就是不允许隐式构造，如Data data(2013, 5, 28)会报错。

（2）让编译器对不正确的行为进行阻止，常见的方法是加上const。

```
if(a = b * c){…} //应写成==
const Object operator* (const Object& a, const Object& b); //使用const编译器就可以识别出赋值运算符不正确
```

（3）让自定义类型的行为尽量与内置类型行为一致。如不要重载乘号运算符，但里面却做加法。

（4）多使用shared_ptr来代替原始指针

**<mark>68.为什么TCP握手是三次而不是俩次</mark>**

（1）三次握手才可以阻止重复历史连接的初始化（主要原因）：

**三次握手如何避免历史连接**：

如果客户端发送了SYN报文（seq = 90），然后宕机了。而且这个SYN报文被网络阻塞了，服务端没有收到。接着客户端重启后，又重新向服务端建立连接。发送了SYN（seq = 100）报文。简单地说，客户端连续发送了多次建立连接的报文，在网络拥堵的情况下：

（a）一个【旧SYN报文】比【新SYN报文】先抵达服务端，服务端就会回一个SYN+ACK报文给客户端，此报文中的确认号是91（90 + 1）

（b）客户端收到后，发现自己期望的确认号应该是（100 + 1），而不是90 + 1，所以就会回RST报文。

（c）服务端收到RST报文后，就会释放连接。

（d）后续最新的SYN报文抵达服务端后，客户端与服务端就可以完成三次握手了。

如果服务端在收到RST报文之前，先收到了【新SYN报文】，那么就会回challenge ACK报文给客户端，这个ack报文并不是确认收到【新SYN报文】的，而是上一次的ack确认号，也就是90+1. 客户端收到后就会回复RST。

**二次握手为什么不行**：

在二次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。

在俩次握手的情况下，服务端在收到SYN报文后就进入了ESTABLISHED状态，意味着这时可以向对方发送数据，但是客户端此时还没有进入ESTABLISHED状态，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-04-21-15-00-04-image.png)

（2）同步双方初始序列号

当客户端发送携带【初始序列号】的SYN报文的时候，需要服务端回一个ACK应答报文，表示客户端的SYN报文已被服务端成功接收，那当服务端发送【初始序列号】给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步**。

而俩次握手只能确保一方的初始序列号能被对方成功接收。

（3）避免资源浪费

如果只有俩次握手，如果客户端发送的SYN报文在网络中阻塞了，重复发送多次SYN报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-04-21-15-06-50-image.png)

**<mark>69.线程池是什么？核心参数？你的项目什么时候用了线程池？怎么用的？</mark>**

**是什么**：

（1）所谓线程池，就是一个pthread_t类型的普通数组，通过空间换时间的方式，消耗服务器的硬件资源，换取运行效率。

（2）它是一组线程资源的集合，这组资源在服务器启动之前就被完全创建好并初始化。

（3）当服务器进入正式运行阶段，开始处理客户端请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配

（4）当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用释放资源。

**核心参数**：

（1）工作队列大小：

取决于每个工作任务的处理时间和系统资源，需要监控系统性能并进行调整，参考取值10000.

（2）线程池数量：

公式：最佳线程数 = CPU当前可以使用的Cores数 * 当前CPU利用率 * (1 + CPU等待时间/CPU处理时间)，由于等待时间和处理时间不好测量，所以还是采用经验值。设置为8。

**项目中什么时候用了，怎么用的**：

项目中使用线程池并发处理用户请求，主线程负责读写，工作线程（即线程池中的线程）负责处理逻辑。主线程通过epoll_wait发现某个文件描述符上有可读事件后，主线程就将这个HTTP的请求报文读到该连接的读缓存中，然后将该任务对象插入线程池的请求队列中；线程池中的线程通过竞争锁资源来获取任务，完成报文解析。

**<mark>70.平时怎么提升编程能力</mark>**

学习编程语言，应用框架直接看官方文档，写demo通过github找项目，遇到不懂的去查 StackOverflow。

**<mark>71.实现一个string类</mark>**

```
class Mystring {
private:
    char* _str;
    size_t _size;
    size_t _capacity;

    static const size_t npos;
public:
    //当使用初始化列表时，初始成员变量的顺序与列表排列的顺序没有关系，只取决于声明这些成员变量的顺序
    Mystring(const char* str = ""):_size(strlen(str)), _capacity(_size) { 
        //我们要对形参设置缺省值。当我们没有给string对象赋值，我们默认初始化为空，但这里str实际上里还有一个’\0’.
        //我们在给_str 分配空间的时候，要分配_capacity个，
        //因为此时_capacity = _size = strlen(str).strlen()计算字符串长度的时候不包含’\0’, 所以我们实际开空间要多开一个留给’\0’
        _str = new char[_capacity + 1];
        strcpy(_str, str);
    }

    ~Mystring() {
        delete[] _str;
    }

    Mystring(const Mystring& s):_str(NULL) {
        Mystring tmp(s._str); //这里不是拷贝函数,而是调用的构造函数，构造的行参是指针，拷贝的行参是对象
        swap(tmp);
    }

    Mystring& operator=(Mystring s) {
        swap(s);
        return *this;
    }

    char& operator[](size_t pos) {
        assert(pos < _size);
        return _str[pos]; //等价于*(_str + pos)
    }
    const char& operator[](size_t pos) const{ //后加const，说明该函数不能改变成员变量
        assert(pos < _size);
        return _str[pos];
    }

    void reserve(size_t n) {
        if (n > _capacity) {
            char* temp = new char[n + 1];
            strcpy(temp, _str);
            delete[] _str;
            _str = temp;
        }
        _capacity = n;
    }

    void resize(size_t n, char ch = '\0') {
        if (n < _size) {
            _size = n;
            _str[_size] = '\0';
        }
        else {
            if (n > _capacity) {
                reserve(n);
            }
            for (size_t i = _size; i < n; ++i) {
                _str[i] = ch;
            }
            _size = n;
            _str[_size] = '\0';
        }
    }

    void push_back(char ch) {
        if (_size >= _capacity) {
            size_t newcapacity = 0;
            if (_capacity == 0) {
                newcapacity = 4;
            }
            else newcapacity = 2 * _capacity;
            reserve(newcapacity);
        }
        _str[_size] = ch;
        _size++;
        _str[_size] = '\0';
    }

    void append(const char* str) {
        size_t len = strlen(str);
        if (_size + len > _capacity) {
            reserve(_size + len);
        }
        strcpy(_str + _size, str);
        _size += len;
    }

    Mystring& insert(size_t pos, char ch) {
        assert(pos <= _size);

        if (_size == _capacity) {
            size_t newcapacity = 0;
            if (_capacity == 0) {
                newcapacity = 4;
            }
            else newcapacity = 2 * _capacity;
            reserve(newcapacity);
        }
        size_t end = _size + 1;
        while (end >= pos) {
            _str[end] = _str[end - 1];
            end--;
        }
        _str[pos] = ch;
        _size++;
        return *this;
    }

    Mystring& insert(size_t pos, const char* str) {
        assert(pos <= _size);
        size_t len = strlen(str);

        if (len == 0) return *this;
        if (_size + len > _capacity) {
            reserve(_size + len);
        }
        size_t end = _size + len;
        while (end >= pos + len) {
            _str[end] = _str[end - len];
            end--;
        }
        for (size_t i = 0; i < len; ++i) {
            _str[pos + i] = str[i];
        }
        _size += len;
        return *this;
    }

    Mystring& erase(size_t pos, size_t len = npos) {
        assert(pos < _size);
        if (len == npos || pos + len > _size) {
            _str[pos] = '\0';
            _size = pos;
        }
        else {
            strcpy(_str + pos, _str + pos + len);
            _size -= len;
        }
        return *this;
    }

    const char* c_str() const {
        return _str;
    }

    size_t size() const {
        return _size;
    }

    size_t capacity() const {
        return _capacity;
    }

    Mystring& operator += (char ch) {
        push_back(ch);
        return *this;
    }

    Mystring& operator += (const char* str) {
        append(str);
        return *this;
    }

    Mystring& operator += (const Mystring& s) {
        *this += s._str;
        return *this;
    }

    Mystring operator + (char ch) {
        Mystring temp = *this;
        temp += ch;
        return temp;
    }

    Mystring operator + (const char* str) {
        Mystring temp = *this;
        temp += str;
        return temp;
    }

    Mystring operator + (const Mystring& s) {
        Mystring temp = *this;
        temp += s;
        return temp;
    }

    bool operator > (const Mystring& s) {
        return strcmp(_str, s.c_str());
    }

    bool operator == (const Mystring& s) {
        return strcmp(_str, s.c_str()) == 0;
    }

    bool operator != (const Mystring& s) {
        return !(*this == s);
    }

    bool operator >= (const Mystring& s) {
        return *this > s || *this == s;
    }

    bool operator < (const Mystring& s) {
        return !(*this >= s);
    }

    bool operator <=(const Mystring& s) {
        return !(*this > s);
    }
    bool operator == (const Mystring& s) {
        return strcmp(_str, s.c_str()) == 0;
    }

    friend bool operator == (const Mystring& s1, const Mystring& s2) {
        size_t i1 = 0, i2 = 0;
        while (i1 < s1.size() && i2 < s2.size()) {
            if (s1[i1] != s2[i2]) {
                return true;
            }
        }
    }
public:
    typedef char* iterator;
    typedef const char* const_iterator;

    iterator begin() {
        return _str;
    }

    const_iterator begin() const {
        return _str;
    }

    iterator end() {
        return _str + _size;
    }

    const_iterator end() const {
        return _str;
    }

    void swap(Mystring& s) {
        std::swap(_str, s._str);
        std::swap(_size, s._size);
        std::swap(_capacity, s._capacity);
    }

};

const size_t Mystring::npos = -1;

int main() {
    Mystring s("hello");
    Mystring s1("asdfads");
    s = s + s1;
    for (int i = 0; i < s.size(); ++i) {
        cout << s[i] << endl;
    }

}
```

**<mark>72.排序算法</mark>**

快排，冒泡，选择，插入，归并，桶

```
//选择排序
void selection_sort(vector<int>& nums) {
    for(int i = 0; i < nums.size() - 1; ++i) {
        int minindex = i;
        for(int j = i + 1; j < nums.size(); ++j) {
            if(nums[j] < nums[minindex]) {
                minindex = j;
            }
        }
        swap(nums[i], nums[minindex]);
    }
}
```

```
//冒泡排序
void bubble_sort(vector<int>& nums) {
    for (int i = 0; i < nums.size() - 1; ++i) {
        for (int j = 0; j < nums.size() - 1 - i; ++j) {
            if (nums[j] > nums[j + 1]) swap(nums[j], nums[j + 1]);
        }
    }
}
```

```
//插入排序
void insertion_sort(vector<int>& nums) {
    for (int i = 1; i < nums.size(); ++i) {
        for (int j = i; j >= 1; --j) {
            if (nums[j] < nums[j - 1]) swap(nums[j], nums[j - 1]);
        }
    }
}
```

```
//归并排序
void merge(vector<int>& nums, int left, int mid, int right) {
    int s1 = left; //左数组起始位置
    int s2 = mid + 1; //右数组起始位置

    vector<int> temp;
    temp.reserve(right - left + 1);
    while (s1 <= mid && s2 <= right) {
        if (nums[s1] >= nums[s2]) {
            temp.push_back(nums[s2]);
            s2++;
        }
        else {
            temp.push_back(nums[s1]);
            s1++;
        }
    }

    if (s1 <= mid) {
        while (s1 <= mid) {
            temp.push_back(nums[s1]);
            s1++;
        }
    }
    else if(s2 <= right) {
        while (s2 <= right) {
            temp.push_back(nums[s2]);
            s2++;
        }
    }

    for (int i = 0; i < temp.size(); ++i) {
        nums[left] = temp[i];
        left++;
    }
}
void merge_sort(vector<int>& nums, int left, int right) {
    if (left >= right) {
        return;
    }

    int mid = left + ((right - left) >> 1);
    merge_sort(nums, left, mid);
    merge_sort(nums, mid + 1, right);
    merge(nums, left, mid, right);
}
```

```
//快速排序
void quick_sort(vector<int>& nums, int left ,int right) {
    if (left >= right) return;
    srand(time(nullptr));
    int key = rand() % (right - left) + left;
    swap(nums[left], nums[key]);

    int i = left, j = right;
    while (i < j) {
        //必须右先走，否则最后相遇的点不一定比key小
        while (i < j && nums[j] >= nums[left]) j--; 
        while (i < j && nums[i] <= nums[left]) i++;
        if(i != j) swap(nums[i], nums[j]);
    }

    swap(nums[left], nums[j]);

    quick_sort(nums, left, i - 1);
    quick_sort(nums, i + 1, right);

}
```

**<mark>73.虚拟地址空间</mark>**

（1）从程序局部性原理中我们可以得到这样一个结论：进程在运行时，不会一下子就要访问所有的内存，相反进程对于内存的访问会表现出明显的倾向性。进程更倾向于访问最近访问过的数据，以及热点数据附近的数据。

（2）所以无论一个进程实际可以占用的内存资源有多大，根据程序局部性原理，在某一段时间内，进程真正需要的资源只是很少的一部分，我们只需要为每个进程分配很少的内存就可以保证进程的正常运行

（3）而虚拟内存的引入正是为了解决这个问题，虚拟内存引入后，进程的视角就会变得非常开阔，每个进程都拥有属于自己的虚拟地址空间，进程与进程之间的虚拟地址空间是相互隔离，互不干扰的。

（4）每个进程都认为自己独占所有的内存空间，所有内存资源都属于自己，但其实任何一个虚拟内存里存储的数据，本质上还是保存在物理内存里的，只不过内核帮我们做了虚拟内存到物理内存这一层的映射，将不同进程的虚拟地址和不同内存的物理地址映射起来。

（5）当CPU访问进程的虚拟地址时，将虚拟地址转换成不同的物理地址，这样不同的进程运行时，虽然操作的是同一虚拟地址，真正写入的却是不同的物理地址，就不会造成冲突了。

（6）通过将多进程之间协同的相关复杂细节全部交给内核中的内存管理模块来处理，极大降低了编程的复杂性，这一切都是因为虚拟内存能够提供内存地址空间的隔离，极大的扩展了可用空间。

**<mark>74.malloc底层是怎么分配内存的</mark>**

malloc并不是系统调用，而是C库里的函数，用来动态分配内存。

maloc申请内存的时候，会有两种方式向操作系统申请堆内存。

**方式一**：通过brk（）系统调用从堆分配内存：

实现方式：通过brk（）函数将【堆顶】指针向高地址移动，获得新的内存空间。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/brk%E7%94%B3%E8%AF%B7.png)

**方式二**：通过mmap（）系统调用在文件映射区分配内存：

实现方式：通过mmap（）系统调用中【私有匿名映射】的方式，在文件映射区分配一块内存。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/mmap%E7%94%B3%E8%AF%B7.png)

内存映射即在进程的虚拟地址空间中创建一个映射，分为两种：

（1）文件映射：数据源是存储设备上的文件，把文件的一个区间映射到进程的虚拟地址空间

（2）匿名映射：没有数据源，把物理内存映射到进程的虚拟地址空间

根据**修改是否对其他进程可见和是否传递到底层文件**，内存映射分为共享映射和私有映射

（1）共享映射：修改数据时，映射相同区域的其他进程可以看见，如果是文件支持的映射，修改会传递到底层文件。

（2）私有映射：如果有数据源，第一次修改数据时会从数据源复制一个副本，然后修改副本，其他进程不可见，不影响数据源。

malloc源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

**<mark>75.malloc（）分配的是物理内存吗</mark>**

不是，分配的是虚拟内存。

如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。

只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存地址和物理内存之间的映射关系。

**<mark>76.malloc（1）会分配多大的虚拟内存</mark>**

malloc在分配内存的时候，会预分配更大的空间作为内存池。具体预分配多大的空间，和malloc使用的内存管理器有关。默认的内存管理器对于malloc（1）实际上预分配132K字节的内存。

**<mark>77.malloc申请的内存，free释放内存会归还给操作系统吗</mark>**

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
  
  因为brk（）申请的内存较小，与其把这一块内存释放给操作系统，不如先缓存着放进malloc的内存池里，当进程再次申请时就可以直接复用，速度会快很多。当然进程退出后，操作系统会回收进程的所有资源。

- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

**<mark>78.为什么不全部使用mmap来分配内存</mark>**

（1）因为向操作系统申请内存，要进行运行态的切换。如果每次都用mmap来分配内存，等于每次都要切换到内核态。

（2）因为mmap分配的内存每次释放的时候，都直接归还给操作系统，于是每次分配的虚拟地址都是缺页状态，第一次访问时就会触发缺页中断。导致CPU消耗增大。

为了改进这俩个问题，malloc通过brk申请内存时，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放时，就缓存在内存池中。

等下次再申请内存的时候，直接从内存池中取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还在，这样不仅减少系统调用的次数，还减少缺页中断次数。

**<mark>79.为什么不全部使用brk分配内存</mark>**

考虑一个场景：如果我们连续申请了10k，20k，30k这三片内存，如果10k，20k释放了变成了空闲的内存空间，那么如果下次申请的内存小于30k，就可以重用这个空闲内存空间。

但如果大于30k，此时没有可用的空闲空间，必须再次进行申请。

随着频繁调用malloc和free，堆内将产生越来越多不可用的小块内存碎片，导致内存泄漏

**<mark>80.free函数只传入一个内存地址，为什么能知道要释放多大的内存</mark>**

malloc返回给用户态的内存起始地址比进程的堆空间起始地址多了16个字节，这里面保存了该内存块的描述信息

**<mark>81.键入网址过程</mark>**

同54

**<mark>82.伙伴系统</mark>**

伙伴系统是一种内存碎片的解决方法，用来解决内存浪费的问题。他将内存分成若干块，然后尽可能以最适合的方式满足程序内存需求。

定义伙伴的概念的目的是在与释放的过程中，能够动态的维护尽可能长的连续内存。

如果请求的连续内存数量是k，那么伙伴系统将选择满足2^n >= k的最小数字n对应的那个分组，如果伙伴系统中没有对应的分组，那么系统会将更大的分组劈开形成一对伙伴，然后看劈开后的分组是否合适，不合适的话就继续劈开，直到到达合适的大小为止。

当释放内存时，伙伴系统会查看释放分组的伙伴是否空闲，如果空闲的话便会合并两个分组形成一个更大的分组，并递归该操作直到当前分组的伙伴繁忙或已形成最大数量的数组。

**<mark>83.c++的内存结构</mark>**

分为5个区

（1）栈：用来存放局部变量和函数参数，由编译器管理分配和回收。

（2）堆：由程序员管理，需要手动分配和回收，空间较大，但可能会出现内存泄漏和空闲碎片的情况。

（3）全局/静态存储区：分为初始化和未初始化俩个相邻区域，存储初始化和未初始化的全局变量和静态变量。已经初始化的在.data区域，未初始化的在.bss区域

（4）常量存储区：存储常量，一般不允许修改。

（5）代码区：存放程序的二进制代码。

**<mark>84.什么情况使用堆，什么情况使用栈</mark>**

（1）因为与堆相比，栈不会导致内存碎片，且分配效率高。所以函数调用通过栈来完成，以及调用过程中的参数，返回地址，和局部变量等都采用栈的方式存放。如果少量数据需要频繁操作，那么在程序中动态申请少量栈内存（alloca函数），会获得很好的性能提升。

（2）堆可以申请的内存比栈大很多。所以如果需要分配大量的内存空间，最好使用堆内存。

**<mark>85.数组和链表的区别</mark>**

（1）内存分布：

数组占用的是一块连续的内存区

链表在内存中是分散的，通过指针来连接

（2）正是因为他们在内存分布上的差异，导致他们的增删查改时间复杂度不同。

**查改**：数组支持随机访问，O(1)

            链表只能顺序访问，O(n)

**增删**：因为数组在内存中是连续的，要想增加或者删除节点，就会导致其后面的节点都需要进行移动，最坏的情况下需要移动整个数组。

链表只需要改变节点的指向，就可以实现增加或产出的操作。

（3）内存预读：内存管理会将连续的存储空间提前读入缓存（程序局部性原理），所以数组往往都会被读入到缓存中，进一步提高了访问的效率。

链表由于在内存中是分散的，往往都不会读入到缓存中，效率较低。

**<mark>86.i=i+1执行多久</mark>**

i = i + 1, i += 1 , i++。

在实际编译过程中，编译器会自动优化，所以效率一样。

如果没有编译器优化：

（1）i = i + 1效率最低

它需要先读取右i地址；

将值+1；

读取左i地址；

将右值传给左边的i；

（2）i += 1其次；

他首先读取 i 的地址；

将值加一；

传给i；

（3）i++最快

他首先读取 i 的地址；

然后值自增1.

**<mark>87.进程的通信方式有哪些</mark>**

（1）管道：

管道是一种半双工的通信方式，数据只能单向流动。

分为俩类：

**无名管道**（即内存文件）：只能在具有亲缘关系的进程之间使用，通常指父子进程关系。

**有名管道**（即FIFO文件）：可以在不相关的进程之间交换数据。

（2）共享内存：共享内存就是映射一段能被其他进程访问的内存，这段内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式（*Inter-Process Communication，进程间通信*），往往与信号量配合使用来实现进程间的同步和通信。

（3）消息队列：是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

（4）套接字：适用于不同机器间进程通信，在本地也可以作为两个进程通信的方式。

（5）信号：用于通知进程某个事件已经发生，比如按下ctrl + c就是一个信号。

（6）信号量：是一个计数器，用来控制多个进程对共享资源的访问

**<mark>88.了解中断吗</mark>**

（1）**定义**：中断是系统用来响应硬件设备请求的一种机制，如敲击键盘的同时就会产生中断，当硬盘写完数据之后也会产生中断。操作西系统收到硬件的中断请求，就会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

（2）中断请求会打断其他进程的运行，并且中断处理程序在响应中断时，可能还会临时关闭中断，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就是说中断可能丢失，所以**中断处理程序要短且快**。

（3）linux为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分为了两个阶段，分别是上半部和下半部：

**上半部**直接处理硬件请求，也就是硬中断，一般会暂时关闭中断请求，主要负责耗时短的工作，特点是快速执行。

**下半部**是由内核触发，也就是软中断，主要负责上半部未完成的工作，一般以内核线程的方式运行，特点是延迟执行。

**<mark>89.键盘上敲一个字母是什么中断？</mark>**

硬件中断

**<mark>90.查找一个字符串是否在文件中</mark>**

（1）**grep** string filename

（2）nl filename | **sed** -n '/string/p'

（3） **awk** '/string/ {print NR":", $0}' filename

（4）**less** filename 键入/后跟想要查找的字符串，然后按“Enter”

（5）vi同上

**<mark>91.查找一个本机端口号的状态</mark>**

netstat -anp | grep 端口号：查看当前端口的状态

netstat -anp：查看所有

**<mark>92.几十个G的文件中查找一个字符串是否存在</mark>**

使用dd加grep命令

不设置skip，先把count设为一半文件大小的值，采用二分法查找，如果找到，则限定在了一半的范围内。然后继续查找。

**<mark>93.如何判断远程服务的端口有没有开启</mark>**

**方式一**：telnet命令

（1）先查看地址能否ping通

```
ping www.baidu.com
```

（2）然后使用telnet查看端口是否开放

```
telnet www.baidu.com 3306
```

如果命令行不显示任何信息说明端口处于开启状态

如果端口处于关闭状态，命令行窗口显示连接失败。

**方式二**：netcat命令

```
nc -vz www.baidu.com 443
```

**方式三**：nmap命令

```
nmap www.baidu.com
```

会显示已打开的端口

**方式四**：执行/dev/tcp检测

```
echo > /dev/tcp/www.baidu.com/443 && echo "Port is open"
```

如果远程服务器端口是开着的，则会打印“Port is open“，如果没有打开会提示”Connection refused“

**<mark>94.平时使用的Linux命令</mark>**

ls、cd、man、chmod、ps、kill、ping、mkdir、rm、mv、cp、gedit。

**<mark>95.介绍一下OSI七层协议，各层协议都有哪些</mark>**

（1）应用层：负责给应用程序提供统一的接口

常见协议有：HTTP、FTP、DNS

（2）表示层：负责把数据转换成能兼容另一个系统的格式

常见协议：LPP 轻量级会话协议

（3）会话层：负责建立、管理和终止表示层实体之间的通信会话

常见协议：LDAP 轻型目录访问协议

（4）传输层：负责端到端的数据传输

常见协议：TCP,UDP

（5）网络层：负责数据的路由、转发、分片

常见协议：IP、ICMP（用于传输出错报告控制信息）

（6）数据链路层：负责数据的封帧和差错检测，以及MAC寻址

常见协议：ARP协议

（7）物理层：负责在物理网络中传输数据帧

常见协议：Ethernet协议

**<mark>96.baidu.com默认使用什么端口</mark>**

80是http协议的默认端口，是在输入网站的时候浏览器就已经帮我们输入端口号了，所以输入www.baidu.com，其实就是访问www.baidu.com:80。

**<mark>97.三次握手</mark>**

同28

**<mark>98.为什么不是俩次</mark>**

同68

**<mark>99.如果网络情况非常好，百分百不会发生拥塞，不会重传SYN，不会有历史连接问题</mark>**

**<mark>可以两次握手吗</mark>**

还是不可以，因为俩次握手无法同步双方的初始序列号

TCP 协议的通信双方，都必须维护一个【序列号】。序列号是可靠传输的一个关键因素，它的作用：

（1）接收方可以去除重复的数据

（2）接收方可以根据数据包的序列号按序接收

（3）可以标识发送出去的数据包中，哪些是已经被对方接收到的（通过ACK报文中的序列号知道）

所以当客户端发送携带【初始序列号】的SYN报文的时候，需要服务端回一个ACK应答报文，表示客户端的SYN报文已被服务端成功接收，那当服务端发送【初始序列号】给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步**

四次握手也能够可靠的同步双方的初始序列号，但由于第二步和第三步可以优化成一步，所以就成了三次握手。

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接受。

**<mark>100.什么时候用TCP什么时候用UDP</mark>**

由于TCP是面向连接的，能保证数据的可靠性交付，因此经常用于：

（1）FTP文件传输

（2）HTTP/HTTPS

由于UDP面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此常用于：

（1）包总量较少的通信，如DNS

（2）视频，音频等多媒体通信

（3）广播通信

**<mark>101.此时的视频面试用的是UDP还是TCP</mark>**

UDP

（1）为什么使用的是UDP

因为UDP是一个无连接的协议，不用保证可靠性，速度快。

（2）如果UDP不保证可靠性，在视频面试的时候如果你回答问题的视频流丢包了，你的回答我就听不见了，那么视频面试的体验将会非常差，怎么办？

需要结合TCP和UDP的特性，让这个协议既可以保证可靠，又可以保证实时性，也就是使用RUDP，常见的TUDP协议主要有**QUIC**。

**<mark>102.UDP丢包会有什么现象</mark>**

（1）传输的数据无法到达接收端，导致接收端获取不到完整的数据包

（2）接收端可能会发现数据包丢失，从而无法正确处理数据

（3）传输的数据包可能出现乱序，导致接收端无法正确重构数据

（4）传输的数据包可能被重复发送，导致接收端接收到重复的数据

（5）传输的数据包可能出现错误，导致接收端无法正确解码数据

当UDP数据包丢失时，他不会像TCP中那样自动重传，因为UDP没有检测丢失数据包的机制。发送方不会知道数据包丢失，接收方也不会请求重传。

**<mark>103.http和https的区别</mark>**

（1）HTTP协议传输的数据都是未加密的，也就是明文传输，存在安全风险的问题。HTTPS则解决HTTP不安全的缺陷，在TCP和HTTP网络层之间加入了SSL/TLS安全协议，使得报文能够加密传输。

（2）HTTP连接建立相对简单，在TCP三次握手之后就可进行HTTP的报文传输，而HTTPS在三次握手后，还需要进行SLL/TLS握手，才可进行传输

（3）两者默认的端口不一样，HTTP默认端口号是80，HTTPS是443

（4）HTTPS需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的，需要一定费用

**<mark>104.证书绿色是什么意思</mark>**

主流浏览器对没有安装SSL证书的网站提示不安全，安装了SSL证书的网站浏览器会显示绿色安全标志，表示连接安全

**<mark>105.自己随便编一个证书可以吗，需要去什么地方注册</mark>**

不可以，需要去CA注册。

CA（数字证书认证机构），将服务器公钥放在由CA颁发的数字证书中，只要证书是可信的，公钥就是可信的。

**<mark>106.平常查什么网站？</mark>**

github，StackOverflow，cpp reference

**<mark>107.代码、文献、DEBUG习惯</mark>**

（1）习惯写注释，对于接口、类以及复杂的业务逻辑，添加有意义的注释。

对于接口方法的注释，主要会写详细的传入参数和返回结果说明，以及异常抛出的情况。

对于类主要写类的各个成员变量和成员函数的功能说明。

（2）把一个大的项目拆分成多个小的业务结构来写

（3）封装一些方法的形参以及通用的模板函数，还有复杂的逻辑判断条件

（4）习惯选择合适的日志级别来打印日志信息进行DEBUG。

error：错误日志，指比较严重的错误，对正常业务有影响，需要运维配置监控的；
warn：警告日志，一般的错误，对业务影响不大，但是需要开发关注；
info：信息日志，记录排查问题的关键信息，如调用时间、出参入参等等；
debug：用于开发DEBUG的，关键逻辑里面的运行时数据；
trace：最详细的信息，一般这些信息只记录到日志文件中。
**<mark>108.proactor和reactor模式</mark>**

（1）reactor是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生后，比如可读就绪事件，就需要应用程序主动调用read方法来完成数据的读取，也就是要应用程序主动将socket连接接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。

（2）proactor是异步网络模式，感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址等信息，用来存放结果数据，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全部交给操作系统来做，并不需要像Reactor那样还需要应用进程主动发起read/write来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。

**<mark>109.epoll是同步的还是异步的</mark>**

（1）从I/O层面来看，EPOLL一定是同步的

（2）从消息处理层面来看，EPOLL是异步的

**<mark>110.从数据流的角度描述proactor模式</mark>**

同108

**<mark>111.五种IO模型</mark>**

（1）阻塞IO：调用者调用了某个函数，等待这个函数返回，期间不执行任何操作，必须等这个函数返回才能进行下一步动作

（2）非阻塞IO：每隔一段时间就去检测IO事件是否就绪，没有就绪就做其他事情。非阻塞IO执行系统调用总是立即返回，不管事件是否已经发生，若没有发生，则返回-1，此时可以根据errno区分这俩种情况，对于accept、recv和send，事件未发生时，errno通常被设置为EAGAIN

（3）信号驱动IO：用户进程发送一个sigaction系统调用后，立刻返回，并不会阻塞，当IO事件就绪后，进程收到SIGIO信号，然后执行信号处理函数。

（4）IO复用：linux用select/poll/epoll函数实现IO复用模型。这些函数也会使进程阻塞，但是和阻塞IO不同，这几个函数可以同时阻塞多个IO操作，而且可以同时对多个读操作、写操作的IO函数进行检测。

（5）异步IO：Linux中，可以调用aio_read函数让内核进行IO操作，用户进程继续往下执行，当内核将数据拷贝到缓冲区后，再通知应用程序进行数据处理。

**<mark>112.为什么不用异步来做webserver</mark>**

（1）linux下的异步IO并不成熟，比如：他只支持以指定标识（O_DIRECT）打开的文件，不支持socket句柄。

（2）如果CPU的核心数较多，或线程的调度算法优秀的话，即使单核心性能一般，也有可能与异步操作的模式性能差不多

**<mark>113.如何使用同步IO模拟proactor模式</mark>**

原理：主线程执行数据读写操作，读写完成之后，通知工作线程进行处理。从工作线程的角度来看，他们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

工作流程如下：

（1）主线程往epoll内核事件表中注册socket上的读就绪事件

（2）主线程调用epoll_wait等待socket上的读就绪事件

（3）当sokcet上有数据可读时，主线程从socket上循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列

（4）睡眠在请求队列上的某个工作线程被唤醒，来处理请求，然后往epoll内核事件表中注册socket上的写就绪事件

（5）主线程调用epoll_wait等待socket可写后，循环写入数据

**<mark>114.高并发情况下的性能提升方法</mark>**

（1）语言方面：

可以利用引用和指针，来减少类的构造和析构；

在c++11标准里，引入了右值引用，move语义和forward完美转发的新特性，以及移动构造函数和移动赋值运算符。；

可以利用语言提供的原子特性，部分的代替锁来进行互斥。如static在局部变量使用时初次定义就要初始化，且只能初始化一次，重复调用同一函数，第二次调用时不会执行static局部变量初始化的那句话。

（2）IO方面：

使用更优的拥塞控制算法，如谷歌的BBR算法；

修改TCP选项？

（3）减少内存拷贝；

使用条件变量减少频繁的轮询；

尽量减小互斥锁的代码范围，范围越大，竞争条件在时间维度就越激烈

**<mark>115.linux如何切换目录，查看端口绑定情况，查看CPU利用率</mark>**

cd

netstat -tunlp | grep 8089  其中8089为被占用的端口号

vmstat -n 1一秒刷新一次

**<mark>116.什么是qps和tps，如何计算</mark>**

（1）QPS即每秒查询率，指一台服务器每秒能响应的查询次数，用于衡量特定的查询服务器在规定时间内所处理流量的多少，主要针对专门用于查询的服务器的性能指标。

QPS = 1s/单个请求耗时 * 服务器核心数（线程数）

（2）TPS是每秒事务数，一个事务是指客户端向服务器发送请求然后服务器做出反应的过程。

TPS = 事务的数量 / 执行总时间

**<mark>117.线程池和任务队列有没有做分离</mark>**

有。线程池分为了线程集合和任务队列俩部分，把线程和任务分离，提升了线程的重用性。

线程池通过run方法从任务队列提取任务，到一个线程中去执行，有任务就提取执行，没有任务则阻塞线程休眠。

**<mark>118.线程池中怎么利用信号量机制</mark>**

线程池中的线程通过run方法从任务队列中提取任务，初始化时，由于信号量值为0，所以线程池中的线程是阻塞的，当主线程读取完数据后，将数据放到缓冲区，然后调用线程池的append方法，append方法将该任务插入任务队列中，并调用post做一次v操作，使信号量+1。此时线程池中的某个线程就不再阻塞，调用wait做一次P操作，使得信号量-1，然后从任务队列中取出任务执行

**<mark>119.CPU利用率拉满的时候在线程池中增加线程是否能提高qps</mark>**

不能。应该会导致CPU利用率降低。

不断增加线程数，请求就会变多，随之而来的就是大量的上下文切换、锁征用等，这些串行化的因素会大大增加CPU时间。根据阿姆达尔公式：

加速比 = 1 / （F + 1/n(1 - F)）

其中F是系统的串行化比例，n是线程数。由此可见，为了提高系统的速度，仅增加线程的数量并不一定能起到有效的作用，需要从根本上修改程序的串行行为，提高系统内可并行化的模块比重，在此基础上，合理增加线程数，才能获得最大的加速比。

**<mark>120.如何根据CPU利用率动态设计，优化线程池</mark>**

（1）如果线程执行时，CPU已经高于60%，那么需要把线程池大小调小

（2）如果线程执行时，内存占比较满，那么需要把线程池的队列调小

**<mark>121.http解析主从状态机</mark>**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBH2ZO50WrURwTiaNKTH7tCia3AR4WeKu2EEzSgKibXzG4oa4WaPfGutwBqCJtemia3rc5V1wupvOLFjzQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**<mark>122.http状态码</mark>**

同3

**<mark>123.动态链接库静态链接库特点、区别</mark>**

静态链接库：

（1）每一个程序在使用静态库时，都会将静态库文件拷贝一份添加到自身，当有多个源文件时，就会造成大量的内存浪费。

（2）每当库函数代码修改了，需要重新编译链接形成可执行程序。

（3）因为在可执行程序中已经具备了所有执行程序所需要的东西，在执行的时候运行速度快。

动态链接库：

（1）当动态库文件在被使用时，会对所有想使用该动态库的源程序添加一个标记，在程序执行时再链接动态库文件使用

（3）库函数代码修改后，不需要重新编译链接

（3）把链接推迟到了运行时，运行速度慢

**<mark>124.进程线程区别、通信方式</mark>**

区别同32

（1）进程通信同87，进程间的通信需要借助操作系统

（2）线程间可以直接读写进程数据段（如全局变量）来进行通信

**<mark>125.static修饰局部变量</mark>**

static修饰局部变量改变了它的生命周期，让静态局部变量在出了作用域后仍然存在，到程序结束，生命周期才结束。

**<mark>126.static修饰全局变量</mark>**

一个全局变量被static修饰，则使得这个全局变量只能在本源文件中使用，不能在其他源文件使用

**<mark>127.如何使用类中的static成员函数</mark>**

static修饰的类成员函数，也被所有的类对象所共享，不属于某个具体的实例。没有this指针，不能访问任何非静态成员。

**<mark>128.面向对象的三大特性</mark>**

同41

**<mark>129.虚函数表在什么时候创建、存在什么位置</mark>**

虚函数表在编译期间创建。

位于只读数据段（.rodata），即c++内存模型中的常量区。

**<mark>130.虚函数存在于什么位置</mark>**

虚函数存在于代码段（.text），即c++内存模型中的代码区

**<mark>131.虚函数指针在什么时候创建</mark>**

vptr跟着对象走，所以对象什么时候创建，vptr就什么时候创建出来，所以是在程序运行时创建。

当程序在编译期间，编译器会为构造函数中增加为vptr赋值的代码，当程序在运行时，遇到创建对象的代码，执行对象的构造函数，那么这个构造函数里就有为这个对象的vptr赋值的语句。

**<mark>132.虚函数为什么能实现多态</mark>**

（1）编译器发现基类中有虚函数时，会自动为每个含有虚函数的类生成一份虚表，该表是一个一维数组，虚表里保存了虚函数的入口地址

（2）编译器会在每个对象的前四个字节中保存一个虚表指针，即vptr， 指向对象所属类的虚表。在构造时，根据对象的类型去初始化虚表指针vptr，从而让vptr指向正确的虚表，从而在调用虚函数时，能找到正确的函数

（3）在派生类定义对象时，程序运行会自动调用构造函数，在构造函数中创建虚表并对虚表初始化。在构造子类对象时，会先调用父类的构造函数，为父类对象初始化虚表指针，令他指向父类的虚表；然后再调用子类的构造函数，为子类对象初始化虚表指针，令他指向子类的虚表

（4）当派生类对基类的虚函数没有重写时，派生类的虚表指针指向的是基类的虚表；当派生类对基类的虚函数重写时，派生类的虚表指针指向的是自身的虚表；当派生类中有自己的虚函数时，在自己的虚表中将此虚函数地址添加在后面

这样当有一个基类指针指向派生类时，就可以根据派生类对虚函数的重写情况动态的进行调用，从而实现多态。

**<mark>133.函数调用过程中堆栈的变化情况</mark>**

（1）首先是把函数的返回地址、参数从右到左依次压入栈中

（2）然后将当前函数的栈帧压入栈中。栈帧包括临时变量、函数的返回值等信息。

（3）之后跳转到函数的入口点开始执行函数代码

（4）函数执行完毕后，将返回值存放在寄存器中，然后将栈帧弹出，恢复返回地址，跳转回调用点。

**<mark>134.什么是内存泄露、如何防止</mark>**

（1）内存泄漏是指由于疏忽或错误造成程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制。

（2）如何防止：同21. 使用智能指针。

**<mark>135.什么是RAII、为什么智能指针可以防止内存泄漏</mark>**

RAII全称是Resource Acquisition is Initialization ，即“资源获取即初始化”，也就是说在构造函数中申请分配资源，在析构函数中释放资源。

智能指针就是一个类，类在超出作用域范围的时候会自动调用类的析构函数，从而实现自动释放资源的功能

**<mark>136.看过智能指针的源码？讲一下shared_ptr的内部结构</mark>**

shared_ptr和weak_ptr都继承于同一个基类_Ptr_base,基类里面有原始指针*_Ptr和计数类指针*_Rep。

计数类_Ref_count_base是一个虚基类，有两个纯虚函数和强弱指针的引用计数。他有一个派生类_Ref_count, 这才是真正的引用计数器对象，有一个数据成员 _Ptr，就是原始指针。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-05-04-16-04-53-image.png)

![](C:\Users\win\AppData\Roaming\marktext\images\2023-05-04-16-05-07-image.png)

**<mark>137.如果传给shared_ptr一个引用，那么引用计数会不会+1</mark>**

不会

**<mark>138.宏定义，有无类型检查，在什么阶段生效</mark>**

没有类型检查，在预处理阶段会展开宏定义

**<mark>139.讲一下ARP协议的原理和作用？</mark>**

在传输一个IP数据包时，确定了源IP地址和目标IP地址后，就会通过主机【路由表】来确定IP数据包的下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道【下一跳】的MAC地址。

由于主机的路由表可以找到下一跳的IP地址，所以可以通过ARP协议，求得下一跳的MAC地址。

**作用**：根据IP地址获取MAC地址

**原理**：ARP是借助**ARP请求与ARP响应**两种类型的包确定MAC地址的。

![ARP 广播](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/34.jpg)

（1）首先主机会通过广播发送ARP请求，这个包中包含了想要知道的MAC地址的主机IP地址

（2）当同个链路中的所有设备收到ARP请求时，会去拆开ARP请求包里的内容，如果ARP请求包中目标IP地址与自己的IP地址一致，那么这个设备就会将自己的MAC地址塞入**ARP响应包**返回给主机。

操作系统通常会把第一次通过ARP获取的MAC地址缓存起来，以便下次直接从缓存中找到对应IP地址的MAC地址。

不过，MAC地址的缓存是有一定期限的，超过这个期限，缓存的内容就会被清除

**<mark>140.在哪里会用到ARP协议？</mark>**

比如有多台设备连接在同一个交换机上，此时设备1想要和设备3通信，但是设备1只知道设备3的IP地址，不知道对方的MAC地址。

此时设备1就会将自己的IP地址、MAC地址、以及对端的IP地址等信息封装成一个帧。

当交换机收到该帧时，就会在自己的转发表里查看是否存在于该IP对应的MAC地址，这时会有俩种情况：

（1）如果存在，就通过对应的端口发给目标设备，目标设备收到后页组装成一个帧，通过单播的形式传给设备1；

（2）如果不存在，则交换机会通过广播发送ARP请求

**<mark>141.如果获取不到MAC地址会发生什么</mark>**

会再次发送ARP请求，请求的重发次数是由操作系统决定的，通常是3到5次。如果多次发送没有获取到MAC地址，就会返回一个ICMP包用来通知出错原因。

**<mark>142.TCP和UDP区别</mark>**

（1）TCP是面向连接的，UDP是无连接的

（2）TCP提供可靠的服务，UDP则是尽最大努力交付，但不保证可靠

（3）TCP是面向字节流的，UDP是面向报文的

（4）UDP没有拥塞控制，因此网络出现拥塞时不会使源主机的发送速率降低（对实时应用很有用，如视频会议等）

（5）每一条TCP连接只能是点到点的；而UDP支持一对一，一对多，多对一和多对多的交互通信

（6）TCP首部开销较大，需要20个字节；UDP只需要8字节

**<mark>143.对socket的了解</mark>**

socket主要用来实现跨网络与不同主机上的进程之间通信。

socket是在应用层和传输层之间的一个抽象层，他把TCP/IP层复杂的操作抽象为几个简单的·接口供应用层调用已实现进程在网络中通信。

在linux中，可以通过socket函数来打开一个网络文件，返回值就是文件描述符，然后就可以使用普通的文件操作函数来传输数据

**<mark>144.宏定义</mark>**

宏定义是一种预处理指令，有俩种用法，含参或不含参，含参类似于函数，不含参数则主要用于将某个符号或字符串定义为一个宏，以便在程序中使用。用#define来定义。

优点：能简化代码的编写和修改，加快运行的效率

缺点：容易出现未知的错误，因为宏定义没有类型检查和作用域限制。

**<mark>145.宏定义和const的区别</mark>**

（1）编译阶段不同：define是在编译的预处理阶段起作用，const这是在编译和运行的时候起作用

（2）define只做替换，不做类型检查和计算，也不求解，容易产生错误；

const常量有数据类型，编译器可以对其进行类型安全检查

（3）define只是将宏名称进行替换，在内存中会产生多份相同的备份，const在程序运行中只有一份备份

（4）宏定义的数据没有分配内存空间，只是插入替换掉；const定义的变量只是值不能改变，但要分配内存空间

**<mark>146.typedef的作用</mark>**

（1）定义一种类型易于记忆的别名，而不只是简单的宏替换，可以用来声明多个指针对象。

```
char* pa, pb;//只有pa定义为了char指针类型，pb为char类型

typedef char* PCHAR;
PCHAR pa, pb;  //两个都为char指针类型
```

（2）以前的代码，在声明struct新对象时，必须带上struct，使用typedef可以在定义结构体的时候定义一个别名，声明新对象时就不需要再带上struct

```
typedef struct tagPOINT{  
    int x;  
    int y;  
}POINT;  
POINT p1; // 这样就比原来的方式少写了一个struct，比较省事，尤其在大量使用的时候  
```

（3）用来定义与平台无关的类型

```
typedef long double REAL; //在目标平台一上，让它表示最高精度的类型为：
typedef double REAL;      //在不支持 long double 的平台二上，改为：
typedef float REAL;       //在连 double 都不支持的平台三上，改为：
```

（4）可以为复杂的声明定义一个新的简单的别名

```
//原声明：int *(*a[5])(int, char*);
//变量名为a，直接用一个新别名pFun替换a就可以了：
typedef int *(*pFun)(int, char*); 
//原声明的最简化版：
pFun a[5];
```

**<mark>147.在c++中最常用的数据结构</mark>**

vector

**<mark>148.vector的缺点</mark>**

（1）插入删除效率低，在头部进行插入删除时需要移动整个数组

（2）当动态添加的数据超过vector默认分配的大小时，要进行整体的重新分配、拷贝与释放

（3）访问元素时没有边界检查

（4）不支持多维数组，需要通过嵌套vector来表示

**<mark>149.sort排序的底层实现</mark>**

底层是根据传入数组的大小来判断使用的排序方式。

（1）如果长度小于40，直接使用插入排序，否则进入快排

（2）但如果快排的递归层数过多可能会导致栈溢出，因此sort限制递归层数为1.5logN，如果超过了层数限制就使用堆排序

（3）sort快排还对基准值进行了优化，它将每一段排序的数组分成了8段，9个位置，每三个位置进行一次冒泡排序，再对这三组的中间值进行一次冒泡，最后得到一个mid作为基准值

（4）sort快排是一半进入递归，另一半继续for循环，效率更高

**<mark>150.野指针</mark>**

```
int main(void) { 

    int* p;     // 未初始化
    std::cout<< *p << std::endl; // 未初始化就被使用

    return 0;
}
```

指的是没有被初始化过的指针。

为了防止出错，对于指针初始化都是赋值为NULL

**<mark>151.悬空指针</mark>**

```
int main(void) { 
  int * p = nullptr;
  int* p2 = new int;

  p = p2;

  delete p2;
}
```

指针最初指向的内存已经被释放了的一种指针

**<mark>152.如果使用已经被释放的内存是否会出现错误？可能会出现什么错误？</mark>**

会，应该在释放完内存之后将指针设置为NULL，以避免使用已经被释放的内存。

可能出现的错误：

（1）程序崩溃：如果使用已经释放的内存，还进行写操作，会导致程序崩溃

（2）数据损坏：可能会覆盖其他重要内存

（3）安全漏洞

**<mark>153.为什么用reactor</mark>**

（1）高性能：reactor使用了事件驱动，异步非阻塞的特性，可以高效的处理大量的客户端请求，提高系统的并发能力，提供了更高的性能

（2）可扩展性：reactor可以方便的通过增加reactor实例的个数来充分利用CPU资源

（3）灵活性：可以根据应用需求来配置线程数量，可以适应不同的负载，并保证高性能

（4）可维护性：使用reactor模式可以将业务逻辑与IO操作分离，这样有利于对系统进行维护和升级

（5）数据处理简单：数据处理基于事件的方式完成，可以处理大量的数据，避免了阻塞和死锁的问题

**<mark>154.reactor解决了什么实际问题</mark>**

reactor模式的核心是解决了多请求问题，如果有特别多的请求同时发生，不会因为线程池被短时间占满而拒绝服务。一般实现多请求的模块，会使用线程池的实现方案，但如果瞬间有大量并发，则会一下子消耗所有线程，整个服务就陷入阻塞，后续请求将无法接入。

reactor模式则会有一个分发者对象先接收事件，然后再快速的分发给对应连接的处理对象进行处理，这样就不会阻塞请求的接收

**<mark>155.假设线程池有100个线程，但有1000个用户同时使用，reactor的具体表现</mark>**

通过对子线程循环调用来实现高并发问题。

首先在创建线程的时候就调用了pthread_detach将线程分离，不用单独对线程进行回收。

通过子线程的run方法调用函数进行while循环，让每一个线程池中的线程都不会停止，访问请求被封装到请求队列**List**中，如果没有任务线程就一直阻塞等待，有任务线程就抢占式进行处理，直到请求队列为空。

**<mark>156.IO多路复用的流程和原理</mark>**

流程：

（1）创建socket文件描述符，并将需要监听的IO事件添加到事件集合中（如select集合）

（2）调用IO多路复用函数，将所有待处理事件的集合传递给函数

（3）IO多路复用函数会等待并监听所有传递的事件集合中的IO事件，并自动挂起当前进程，直到有事件发生或超时

（4）当某个IO事件触发时，IO多路复用函数会返回该事件的文件描述符，并从事件集合中删除该事件

（5）处理完该事件后，将该事件重新加入到事件集合中

（6）循环上面的2到5步，直到IO操作都完成

原理：

利用操作系统提供的事件通知机制，将多个IO事件添加到一个事件集合中进行监听。当事件发生时，操作系统会通知正在等待的进程，进程就可以及时处理该事件。

**<mark>157.有没有考虑程序崩溃场景，项目程序崩溃了怎么办</mark>**

（1）加入了异常捕获机制，以防止出现程序崩溃的情况

（2）可以加入日志，来监控系统运行情况，以便于追踪问题的根源

（3）开发完成后，使用webbench进行了测试和验证，以确保程序的稳定性和安全性

**<mark>158.项目具体应用场景，为什么做这个项目</mark>**

**应用场景**：

（1）目前实现的主要是提供web服务，将静态的页面通过http协议呈现给用户，可以同时处理上万个客户端的请求

（2）后续完善可以实现文件的传输和下载，以及在线视频和音频等内容的传播。

**为什么做这个项目**：

实验室的项目偏向于机器视觉，感觉自身对于后台开发的知识有点薄弱，而Webserver项目涉及到很多基础的网络知识和编程技术，通过做这个项目能够提高自己的技术水平和理论水平。并且可以通过实践搭建Web服务器，能够深入了解Web服务器的工作原理和机制。

**<mark>159.为什么裸写socket编程而不是使用一些成熟的协议</mark>**

成熟协议：ISAPI, CGI，WinInet，Winsock

（1）主要是因为裸写socket编程可以更好地理解和掌握网络通信原理，从而更好的应对一些特殊的需求或问题。

（2）利用成熟的协议可以简化开发和部署的工作量，并且减少出现问题的可能性，但是有些时候我们会需要更加细节的控制，例如需要进行网络延迟测试，此时裸写socket编程就可以实现更好的优化。

补充：裸写socket可以实现网络延迟测试是因为它可以直接控制底层的网络数据传输过程，包括对数据包的发送时间、延迟、丢失等进行细粒度的控制。而成熟的协议涉及到许多层次的网络协议，其控制的粒度更为宏观，无法对底层数据进行如此细节的控制

<mark>**160.项目中遇到的印象深刻的问题**</mark>

（1）使用优先级队列来优化定时器的时候，最先想到的就是直接使用STL库自带的priority_queue来实现就可以了。但写到调整定时器adjust_timer操作的时候，发现需要修改priority_queue中保存的定时器指针内部的expire_time的值。然后当时就有个疑问，想到直接修改priority_queue内部的值后，是否会进行自动排序。后来写了个测试程序试了一下，发现修改后并不会重新排序，所以不能直接对其保存的指针内部的值进行修改。后来参考了别人的写法，发现是要自己用vector数组来重新实现一个小顶堆，通过unordered_map来保存定时器的下标。当需要调整指定的定时器的时候，先通过哈希表找到定时器在vector中的位置，然后修改内部的值后，再通过下沉的操作把它移动到合适的位置。

（2）线程池初始化时，通过pthread_create生成线程的时候，工作线程运行的函数一定要声明为static。因为pthread_create函数的第三个参数为函数指针，指向工作线程运行的函数，他要求线程处理函数的参数类型为void*，如果线程函数为类成员函数，那么this指针会作为默认的参数传进函数中，this指针的类型为线程池类的类型，从而和void*不匹配，不能通过编译。改成static成员函数，就不会有this指针

**<mark>161.TCP如何保证可靠传输</mark>**

（1）确认和重传：接收方收到报文就会进行确认，并返回一个确定应答消息，发送方发送一段时间后没有收到确认应答消息就会进行重传

（2）数据校验：TCP报文头有校验和，用于校验报文是否损坏

（3）数据合理分片和排序：TCP会按最大传输单元（MTU）合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层

（4）流量控制：当接收方来不及处理发送方的数据时，能通过滑动窗口，提示发送方降低发送的的速率，防止包丢失

（5）拥塞控制：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失

**<mark>162.使用TCP编程时，如果服务端程序崩溃了，那么客户端会出现什么情况</mark>**

（1）如果是服务端的进程崩溃了，那么内核会发送FIN报文，与服务端进行四次挥手断开连接

（2）如果服务端主机宕机，那么就不会发生四次挥手：

    （a）此时如果没有开启TCP keepalive， 且双方一直没有数据交互，那么客户端的TCP连接会一直处于ESTABLISHED状态；

    （b）如果客户端会发送数据：

由于服务端已经不存在了，所以客户端会进行超时重传，超过一定时间后，会断开TCP连接；

              如果客户端一直不会发送数据：

如果开启了TCP Keepalive机制，则在一段时间没有进行数据交互后，客户端会发送探测报文，达到一定次数没收到响应后，就会断开连接；

如果没有开启，则TCP连接会一直存在

<mark>**163.服务器关机时，一定要等到客户端触发TCP的keepalive后客户端才会关闭吗，有什**么</mark>**<mark>优化方法吗</mark>**

可以在客户端实现心跳机制，自己设定一个时间来发送心跳包，当服务器关机后，心跳包无法收到响应，就可以选择关闭连接

**<mark>164.线程之间共享全局变量如何协调</mark>**

（1）锁机制：通过互斥锁、信号量等线程同步机制来保证共享变量在同一时间只能被一个线程访问，避免多个线程同时读写同一块内存

（2）原子操作：使用atomic关键字，让多个线程对共享变量的读写操作都是原子性的

（3）使用条件变量，让线程在一定条件下等待或唤醒，从而实现线程之间的同步

**<mark>165.为什么使用条件变量时总会使用互斥锁</mark>**

为了保证wait操作的原子性。如果一个线程调用了pthread_cond_wait()函数，但此时还没进入wait状态，另一个线程就调用了pthread_cond_singal()，就会导致此次唤醒丢失。而加了锁的情况下，第二个线程必须等到第一个线程的pthread_cond_wait()释放锁进入wait状态后，才能调用pthread_cond_singal()

**<mark>166.对于大一点的项目如何快速找出C++内存泄漏的代码</mark>**

（1）可以利用valgrind的memcheck工具，来检测程序运行短时间内出现的内存泄漏

（2）利用valgrind的massif工具，来检测程序运行长时间内的内存泄漏

（3）用cppcheck来检测一些我们可能忽略的代码错误

**<mark>167.c++和python有什么区别</mark>**

（1）c++是一种编译型语言，需要将代码编译成可执行文件才能运行；

python是一种解释型语言，可以直接运行脚本

（2）c++是一种静态类型语言，需要在编译时指定变量的数据类型；

python是一种动态类型的语言，可以在运行时解析变量类型

（3）c++可以直接操作内存，效率高；python具有很高的开发效率，但性能较低

**<mark>168.调用new之后底层会做什么</mark>**

new会调用自定义类型的构造函数来初始化对象，并调用一个全局函数operator new。

operator new是对malloc的封装，实际还是通过malloc来申请空间，申请成功则直接返回，失败则会执行用户设置的应对措施，如果没有设置则抛出异常

**<mark>169.操作系统如何分配内存，在哪里分配内存</mark>**

（1）当一个进程启动时，操作系统会为该进程分配一部分内存。这部分内存被分为更小的单元，称为页面

（2）操作系统会在页表中维护所有的可用页面

（3）当进程请求内存时，操作系统会检查页表以查看是否有可用的页面：

如果有，就把该页面分配给进程；如果没有，就使用页面置换算法来淘汰某页面腾出空间

在哪里分配内存：操作系统从RAM或虚拟内存中分配内存，当物理RAM不足以容纳所有正在运行的程序和数据时，则通过虚拟内存来模拟额外的内存

**<mark>170.归还内存时操作系统会做什么</mark>**

操作系统会将该内存区域的页面标记为空闲，移入空闲页面列表，以便其他程序可以使用这些页面

**<mark>171.内存碎片怎么处理</mark>**

内存碎片分为：

（1）内部碎片：就是已经分配出去，却不能被利用的内存空间

（2）外部碎片：指的是还没有被分配出去，但由于太小了无法分配给申请内存空间的新进程的内存空闲区域

通常内部碎片无法完全避免。

对于外部碎片通过紧凑技术消除，就是操作系统不时的对进程进行移动和整理

比如有1G的物理内存，用户执行了多个程序，分别占用512MB，128MB, 256MB，这时候如果关闭128MB的程序，则此时空闲内存还有256MB，如果这个256MB不是连续的，被分成了俩段128MB内存，就会导致没有空间再打开一个200MB的程序。

可以把256MB程序占用的内存写到硬盘上，然后再从硬盘上读回来到内存里。不过在读回来的时候，我们不能装载回原来的位置，而是要紧跟再那已经被占用的512MB内存后面，这样就能空出连续的256MB内存。

且回收内存的时候要尽可能地将相邻的空间合并

**<mark>172.c++有什么情况会导致宕机</mark>**

（1）内存泄漏

（2）内存越界访问

（3）野指针

（4）访问空指针

（5）栈溢出

（6）返回指向临时变量的指针、内存分配释放不配对

**<mark>173.数组越界为什么会导致宕机</mark>**

因为数组在内存中是连续存储的，当访问一个数组元素时，会根据数组的起始地址和下标计算出该元素的内存地址，如果下标越界了，就会访问无效的内存地址，破坏了内存的安全性

**<mark>174.迷宫寻路算法，如果迷宫有环怎么办</mark>**

BFS,DFS, Dijkstra，A*

如果有环：不能只是简单地将走过的路径标记为2，然后通过判断当前点是不是2来决定能不能落脚，可以将入口点标记为2，每走一步加一，然后通过上一个点pre和当前点cur的值来判断能不能落脚

[(157条消息) 数据结构---复杂迷宫求解（多路径带环）_数据结构图求多个路径的方法_y6_xiamo的博客-CSDN博客](https://blog.csdn.net/y6_xiamo/article/details/80102163)

**<mark>175.客户端输入名字的前部分，如有玩家ABC，当客户端输入A时，会有下拉框提示ABC</mark>**，**<mark>问数据结构和算法设计</mark>**

数据结构：字典树

算法设计：

（**1**）初始化：一棵空的字典树仅包含一个根节点，该节点的字符指针为空

（**2**）插入：当需要插入一个字符串S时，首先让一个指针P指向根节点，然后依次扫描字符串S中的每个字符c：

（a）如果P的子节点中没有c这个节点，则创建一个c节点，然后将P移动到节点c

（b）如果有c这个节点，则直接让P节点移动到c

重复上述操作，直到字符串S扫描完毕，在当前节点P上标记一下字符串末尾

（**3**）检索：检索和插入类似，假设我们需要检索一个字符串s，首先让一个指针P指向根节点，然后依次扫描S中的每个字符c：

（a）如果P的子节点中没有c这个节点，则字符串不存在，结束检索

（b）如果有c这个节点，则直接让P节点移动到c，继续检索

重复上述操作，当S中的字符扫描完毕时，若当前p有被标记为字符串末尾，则说明S存在，否则不存在

**<mark>176.文件读写流程（问磁盘到内存的那些步骤）</mark>**

**读文件**：

（1）进程调用库函数向内核发起读文件请求

（2）内核通过检查进程的文件描述符定位到虚拟文件系统的已打开文件列表表项

（3）调用系统调用函数read（）

（4）read()函数通过文件表项链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的inode

（5）在inode模块中，通过文件内容偏移量计算出要读取的页，并可以找到文件对应的address_space

（6）在 address_space中访问该文件的页缓存树，查找对应的页缓存节点：

如果页缓存命中，那么直接返回文件内容；

如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页，然后重新查找页缓存，返回文件内容

**写文件**：

前5步和读文件一致

（6）如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去

（7）如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过 inode找到文件该页的磁盘地址，读取相应的页填充该缓存页，此时缓存页命中，执行第6步

（8）一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块，有两种方式可以把脏页写回磁盘：

（a）手动调用sync() 或fsync()系统调用把脏页写回

（b）pdflush进程会定时把脏页写回到磁盘

同时需要注意的是，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放
