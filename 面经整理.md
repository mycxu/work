**<mark>1.介绍智能指针</mark>**

智能指针的作用是用来管理一个指针，防止程序员申请的空间在函数结束时没有释放，从而造成内存泄漏的发生。

使用智能指针可以很大程度上避免这个问题，因为智能指针是一个类，当超出了类的作用域范围时，会自动调用类的析构函数，从而释放资源。

有四种智能指针，auto_ptr, unique_ptr, shared_ptr, weak_ptr 

**auto_ptr**采用所有权的模式，在c++11中被废弃了，其原因是：

（1）auto_ptr在拷贝和赋值操作时会导致所有权转移。auto_ptr以copy的语义来转移指针资源，转移指针资源的所有权的同时，会将原指针置为NULL，这和我们通常理解上的copy行为是不一致的（通常不会修改原数据）。

（2）使用容器保存auto_ptr后，在进行操作后，可能导致容器中保存的原auto_ptr所管理的对象失效，如sort快排实现中有将元素复制到某个局部临时对象中，但对于auto_ptr，却将原元素置为NULL，这就会导致最后的排序结果中可能会存在大量的NULL。

**unique_ptr**同样采用所有权模式，它实现严格拥有的概念，保证同一时间内只能由一个智能指针指向该对象，即两个unique_ptr不能同时指向一个对象，不能进行复制操作，只能进行移动操作。当它指向其他对象时，之前所指向的对象会被摧毁。因此，unique_ptr 比auto_ptr 更安全。

**shared_ptr**实现共享式拥有的概念，多个智能指针可以同时指向相同的对象，使用引用计数的机制来表明资源被几个指针所共享，对象和相关资源会在最后一个引用被销毁时释放，

可以通过调用use_count()来查看资源的所有者个数，并调用release()，来释放当前指针的资源所有权，使计数减一，当计数减为0时，资源会被释放。

**weak_ptr**叫弱引用指针，是一种不控制对象生命周期的智能指针，他指向一个shared_ptr管理的对象。进行该对象内存管理的是强引用的shared_ptr。weak_ptr只是提供了对管理对象的一个访问手段，他设计的目的是为了协助shared_ptr，它可以解决shared_ptr循环引用的问题，weak_ptr只可以从一个shared_ptr或另一个weak_ptr对象构造，他的构造和析构不会引起引用计数的增加或减少。

**循环引用**：两个对象相互使用shared_ptr指向对方

**<mark>2.final修饰符的作用</mark>**

（1）用来修饰类时，使该类不能被继承

（2）用来修饰类的成员函数时，使该成员函数不能被派生类重写。final关键字可以帮助确保程序的安全性，可以防止有人不小心修改或覆盖定义好的函数从而造成错误。

**<mark>3.HTTP状态码</mark>**

100： 继续。客户端应继续其请求

101： 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议

1xx: 100, 101

2xx: 200, 204, 206

3xx: 301, 302, 304

4xx: 400, 403, 404

5xx: 500, 501, 502, 503, 504, 505

504： 充当网关或代理的服务器，未及时从远端服务器获取请求

505 ：服务器不支持请求的HTTP协议的版本，无法完成处理

**<mark>4.MYSQL索引</mark>**

索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是索引是数据的目录。

innoDB主要使用B+ Tree索引类型，创建表时，innoDB存储引擎会根据不同的场景选择不同的列作为索引：

（1）如果有主键，默认使用主键作为聚簇索引的索引键

（2）如果没有主键，就选择第一个不含NULL值的唯一列作为聚簇索引的索引键

（3）如果俩个都没有，InnoDB将会自动生成一个隐式自增ID列作为聚簇索引的索引键

其他索引都称为辅助索引，或二级索引、非聚簇索引。

B+ Tree是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，且每个节点里的数据是按主键顺序存放的。每一层父节点的索引值都会出现在下层子节点的索引值中，所以叶子节点包含所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表，从而有利于进行范围搜索。

在二级索引的B+Tree就能查询到结果的过程叫做**覆盖索引**，也就是只需要查一个B+Tree就能找到数据

联合索引，存在最左匹配原则

**<mark>5.MYSQL的buffer pool怎么清空</mark>**

使用FLUSH BUFFER POOL

这个命令可以清空所有的缓存页，使得MYSQL需要重新读取磁盘上的数据，这意味着下一次查询的速度会比较慢，因为需要重新从磁盘中读取数据到内存。

**<mark>6.虚函数</mark>**

主要是用来实现多态，在基类的函数前加上virtual关键字，在派生类中重写该函数，运行时将根据对象的实际类型来调用对应的函数。

当一个类中包含虚函数时，编译器会为该类生成一个虚函数表，保存该类中虚函数的地址，同样，派生类继承基类，自然也会有虚函数，所以编译器也会为派生类生成自己的虚函数表，当我们定义一个派生类对象时，编译器检测该类型有虚函数，所以为这个派生类对象生成一个虚函数指针，指向该类型的虚函数表，这个虚函数指针的初始化是在构造函数中完成的。

如果有一个基类类型的指针，指向派生类，那么当调用虚函数时，就会根据所指真正对象的虚函数表指针去寻找虚函数的地址，也就可以调用派生类的虚函数表中的虚函数以此实现多态。

**<mark>7.析构函数写成虚函数原因</mark>**

防止内存泄漏，如果定义了一个基类的指针指向一个派生类对象，在使用完毕准备销毁时，如果基类的析构函数没有定义成虚函数，则编译器根据指针类型就会认为当前对象的类型是基类，调用基类的析构函数，仅执行基类的析构，派生类自身的内容无法被析构，造成内存泄漏。

如果基类的析构函数定义为虚函数，那么编译器就可以根据实际对象，执行派生类的析构函数，再执行基类的析构函数，成功释放内存。

**<mark>8.构造函数为什么不能声明为虚函数</mark>**

（1）因为创建一个对象时需要确定对象的类型，而虚函数是在运行时确定其类型的。而在构造一个对象时，由于对象还未创建成功，编译器无法知道对象的实际类型是类本身还是类的派生类。

（2）虚函数的调用需要虚函数表指针，而该指针存放在对象的内存空间中；若构造函数声明为虚函数，那么由于对象还未创建，还没有内存空间，也就没有虚函数表地址用来调用虚函数即构造函数。

**<mark>9.构造函数或析构函数中调用虚函数会怎样</mark>**

语法上没有问题，但会失去多态性。

如果在构造或析构函数中调用虚函数，会先调用父类中的实现。

因为构造函数没有将虚函数指针和虚函数表初始化完毕，就调用了虚函数，此时必然调用基类中的实现。

析构函数中，则因为子类的那部分已经析构掉了，此时在父类的析构函数中调用虚函数，调用的也只能是父类中的实现。

**<mark>10.c++编译过程</mark>**

主要分为预处理，编译，汇编，链接

预处理阶段：主要处理源代码中#开头的预处理指令，如#include，将文件内容替换到它的位置；删除所有#define，展开所有宏定义等。生成.i文件

编译阶段：将.i文件翻译成文本文件.s ,生成汇编语言程序。每条语句都以标准的文本格式确切描述一条低级机器语言指令。

汇编阶段：汇编器将.s 翻译成机器语言指令。把这些指令打包成可重定位的目标程序，生成.o文件。它是一个二进制文件，它的字节码是机器语言指令，不再是字符。前面俩个阶段都还有字符。

链接阶段：将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接

之所要经过预处理，编译，汇编这么一系列步骤才生成目标文件，是因为在每一个阶段都有相应的优化技术，只有在每个阶段分别优化并生成最为高效的机器指令才能达到最大的优化效果，如果一步到位直接从源程序生成目标文件，可能就会失去很多代码优化的机会。

**<mark>11.静态链接，动态链接</mark>**

静态链接就是把Lib文件中用到的函数代码直接链接进目标程序，程序运行时不再需要调用其它的库文件；

动态链接就是把调用的函数所在文件模块（DLL）和调用函数在文件中的位置等信息链接进目标程序，程序运行时再从DLL中寻找相应函数代码，因此需要相应DLL文件的支持

静态链接：

空间浪费：每个可执行文件对所有需要的目标文件都要有一份副本

更新速度：每当库函数代码修改了，需要重新编译链接形成可执行程序

运行效率：因为在可执行程序中已经具备了所有执行程序所需要的东西，在执行的时候运行速度快。

动态链接：

空间少：多个程序在执行时共享同一份副本。

更新速度快：只需要替换原来的目标文件，不需要重新编译链接。

性能损耗大：因为把链接推迟到了运行时。     

**<mark>12.map和unordered_map区别</mark>**

有序，无序；

红黑树，哈希表；

查询和增删效率：map为O(logn) ，unmap为O（1）。

**<mark>13.inline函数</mark>**

（1）由inline关键字定义，引入inline函数主要是为了替代C中复杂易错不易维护的宏函数

（2）编译器在编译阶段完成对inline函数的处理，即把inline函数的调用替换为函数的本体。inline只是对编译器的一种建议，编译器可以不去做。

**优点**：

（1）省去函数调用带来的参数压栈，栈帧开辟与回收，结果返回等，从而提高运行速度

（2）与宏定义相比，在代码展开时，会做安全检查或自动类型转换

（3）在类中声明同时定义的成员函数，会自动转化为内联函数，因此可以访问类的成员变量，宏定义则不能

（4）在运行时可调试，宏定义不能。

**缺点**：

（1）代码膨胀，inline函数带来的运行效率是典型的空间换时间的做法，内联是以函数膨胀为代价，消除函数调用带来的开销，如果执行函数体内代码的时间，相比函数调用的开销较大，那么效率的收获会很少。且每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。

（2）inline函数不会随着库函数的升级而升级，必须重新编译。如果是non-inline的，用户只需要重新链接。

（3）是否内联不可控

**<mark>14.webserver项目的作用</mark>**

一个webserver就是一个服务器软件。主要功能是通过HTTP协议与客户端（通常是浏览器）进行通信，来接收，存储，处理来自客户端的HTTP请求，并对其请求做出HTTP响应，返回给客户端其请求的内容或返回一个ERROR信息，可实现上万的并发连接。

**<mark>15.reactor高并发</mark>**

IO多路复用监听事件，收到事件后，根据事件类型分配给某个进程/线程。

reactor模式主要由reactor和处理资源池这两个核心部分组成，其中：

Reactor负责监听和分发事件，事件类型包含连接事件，读写事件；

处理资源池负责处理事件，如read-业务逻辑-send

经典方案有：单reactor单进程/线程；单reacto多进程/线程；多reactor多进程/线程

假设当前进程中有三个对象，分别是Reactor、acceptor、Handler。

其中reactor负责监听和分发事件；acceptor负责获取连接；handler负责处理业务逻辑

**单单**：（1）reactor通过IO多路复用接口监听事件，根据事件的类型决定分发给acceptor还是handler处理

（2）如果是连接建立的事件，则交由Acceptor对象处理，accptor对象会通过accept系统调用来获取连接，并创建一个handler对象来处理后续的响应事件

（3）如果不是连接建立的事件，则交由当前连接对应的Handler对象来进行响应

（4）handler对象通过read-业务处理-send的流程来完成完整的业务流程。

优点：实现简单，不用考虑进程间通信，以及多进程竞争

缺点：无法充分利用多核CPU；Handler在进行业务处理时，整个进程是无法处理其他连接事件的。如果业务处理耗时较长，就会造成响应的延迟。

**单多**：（1）（2）（3）同单单

（4）handler对象不再负责业务逻辑的处理，只负责数据的接收和发送。Handler对象通过read读取到数据后，会将数据发给子线程里的processor对象进行业务处理。

子线程里的Processor对象处理完后，将结果发送给主线程里的handler对象，handler对象再通过send方法将响应结果发给client

优点：能充分利用多核CPU性能

缺点：一个reactor对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能瓶颈的地方。

**多多**：（1）主线程中的MainReactor对象通过IO多路复用接口监听连接建立事件，收到事件后通过acceptor对象中的accept获取连接，将新的连接分配某个子线程

（2）子线程中的SubReactor对象将MainReactor对象分配的连接加入IO多路复用接口继续监听，并创建一个Handler用于处理连接的响应事件。

（3）如果有新的事件发生，Subreactor通知当前连接对应的Handler对象来进行响应

（4）Handler对象通过read-业务处理-send的流程来完成完整的业务流程

优点：实现简单，主线程子线程分工明确，主线程和子线程交互简单。

**<mark>16.半同步/半反应堆模式</mark>**

（1）半同步/半反应堆模式是半同步/半异步模式的变体，将半异步具体化为某种事件处理模式

（2）并发模式中的同步指的是程序完全按照代码的顺序执行

异步指的是程序的执行需要由系统事件驱动。

（3）工作流程：

（a）主线程充当异步线程，负责监听所有socket上的事件

（b）若有新请求到来，主线程接收得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件

（c）如果socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成任务对象插入到任务队列中

（d）所有工作线程睡眠在任务队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。

**<mark>17.IO多路复用技术</mark>**

即 使用一个进程来维护多个Socket的方式。

一个进程虽然任一时刻只能处理一个请求，但是如果处理每个请求事件的耗时控制在1毫秒以内，则1秒就可以处理上千个请求，把时间拉长了看，就是多个请求复用了一个进程，这就是多路复用，这种思想很类似与一个CPU并发多个进程，所以也叫时分多路复用。

linux内核提供了select/poll/epoll这三个多路复用的系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。

select/poll/epoll在获取事件时，先把所有的连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求。

**<mark>18.为什么使用EPOLL</mark>**

select：使用固定长度的bitsmap来表示文件描述符集合，他支持的文件描述符个数是有限制的，在Linux系统中，默认最大值为1024。

poll：使用动态数组来存储，以链表形式来组织，突破了select文件描述符个数限制

他们俩并没有太大的本质区别，都是使用线性结构来存储sokcet集合，因此都需要遍历文件描述符集合来找到可读或可写的Socket，时间复杂度为O(n)，而且都需要在用户态和内核态之间拷贝文件描述符集合，这种方式随着并发数的增加，性能的损耗会成指数增长。

epoll通过俩个方面，很好的解决了select和poll的问题

（1）epoll在内核中维护了一棵红黑树，可以保存所有待检测的socket，所以每次只需要传入一个待检测的socket，而不需要传入整个socket集合，减少了内核和用户空间大量的数据拷贝和内存分配。

（2）epoll使用事件驱动的机制，在内核里维护了一个链表来记录就绪事件，当某个socket有事件发生时，通过回调函数内核会将其加入到就绪事件链表中，当用户调用epoll_wait函数时，只返回有事件发生的文件描述符个数，这样就不需要像select/poll那样遍历整个集合，大大提高了检测的效率。

**<mark>19.void*的作用</mark>**

void*定义一个指针变量，但不说明他指向哪一种类型。即这个指针变量只有地址，没有大小。

（1）可以作为函数模板，链表等的通用参数，使用时，只需要强制类型转换就可以。

（2）可以用来表示指向全是0的地址 (void*)0, 相当于NULL

（3）内存分配：`void*` 可以用作动态内存分配函数（如 `malloc`、`calloc`）的返回类型。这样可以分配任意类型的内存块，并将其指针存储在 `void*` 类型的指针中

**<mark>20.函数中声明的不是malloc的数组怎么返回</mark>**

（1）声明一个静态数组，并返回一个指针。静态数组在超出范围时不会被释放，但他不安全，因为当下一次调用该函数时，将覆盖该数组，在多线程中使用更加糟糕。

（2）在调用函数时传入数组地址，在主函数中定义一个数组，然后在调用自定义函数时，将该数组的地址当作参数传入，并在自定义函数生命周期结束后将其内容返回。

**<mark>21.常见的内存泄漏情况。如果程序员不犯错，还有哪些情况会造成内存泄漏</mark>**

（1）在类的构造和析构函数中没有匹配的调用new和delete

（2）没有正确的清除嵌套的对象指针。如在一个对象的成员变量为另一个对象的指针。

（3）在释放对象数组时在delete中没有使用方括号

（4）释放指向对象的指针数组时，只释放了对象空间，没有释放指针空间。

指针数组是指：数组中存放的是对象，只需要调用delete[]，即可调用对象数组中每个对象的析构函数释放空间

指向对象的指针数组是指：数组中存放的是指向对象的指针，不仅要释放每个对象的空间，还要释放每个指针的空间。

（5）缺少拷贝构造函数和重载赋值运算符。默认的是浅拷贝，如果有成员变量是指针，会造成俩个指针指向同一块空间，在释放空间时就会俩次释放同一块空间。所以要么重写拷贝构造函数和重载赋值运算符，要么将他们禁用。

（6）没有将基类的析构函数定义为虚函数。

除了编程错误：

（1）操作系统或硬件的限制

（2）程序使用的某些软件库或者插件

（3）使用效率低下的算法，消耗超过必要的内存

（4）在高负载和压力测试下。

内存泄漏分为：

（1）堆内存泄漏，我们经常说的内存泄漏就是堆内存泄漏，在堆上申请了资源，用完后却没有释放，从而导致该块内存永远不可用。

（2）资源泄漏，通常指的是系统资源，如socket，文件描述符等，因为这些在操作系统中都是有限制的，如果创建了而不归还，久而久之就会耗尽资源。

**<mark>22.匿名函数和函数指针的区别</mark>**

（1）定义方式：匿名函数（也称为 Lambda 函数）可以在代码中直接定义，不需要为其命名。函数指针则是一个指向函数的指针变量，需要提前声明和赋值。

（2）声明与调用：匿名函数的声明和调用通常在同一处完成，可以直接在需要的地方使用。函数指针的声明和调用分开进行，需要先声明函数指针变量，然后将其指向具体的函数，最后通过指针变量进行调用。

（3）存储方式：匿名函数动态创建，不与特定的内存位置相关联。函数指针是一个变量，需要分配内存来存储指针地址。

（4）上下文：匿名函数可以直接访问其定义所在的作用域中的变量，包括外部函数的局部变量。这种特性称为闭包，可以方便地共享上下文。函数指针没有直接的上下文，它只是一个指向函数的指针，无法自动访问其他变量。

（5）灵活性：匿名函数通常更灵活，可以根据需要来定义和使用，适用于一次性或简单的函数需求。函数指针则更适合于需要在不同上下文中重复使用相同的函数的情况。

**<mark>23.vector, list, map, unordered_map各自的特点和原理</mark>**

vector和list：

（1）vector底层通过数组实现，存储空间上一段连续的内存空间；list通过双向链表实现，把不连续的内存空间通过链表的方式连接在一起。

（2）vector插入删除操作需要移动元素，时间复杂度为ON，而list为O(1)

（3）vector支持随机访问，时间复杂度O(1)， list不支持，需要遍历整个链表来查询，为O(N)

（4）vector空间不足时需要另开辟一个俩倍于当前空间大小的空间，然后将原有的元素复制过去，再析构原空间，会造成原有的迭代器失效。list在每次插入和删除的时候分配和释放空间，所以不会引起迭代器失效。

map和unordered_map：

（1）map的底层是红黑树，unordered_map 是哈希表。

（2）所以map的增删、查找时间复杂度为Ologn，unordered_map为O1。

（3）map的key有序，unordered_map无序。

**<mark>24.vector怎么实现扩容</mark>**

若空间不足，会申请一块2倍于当前大小的新内存，然后把旧内存的元素拷贝至新内存空间，并释放旧内存空间，此时原有的迭代器都指向原空间，因此会失效。

**<mark>25.怎么降低vector扩容次数</mark>**

（1）使用reserve预分配足够大的空间

（2）选择合理的初始容量

**<mark>26.reserve和resize区别</mark>**

resize是用来改变容器里的元素个数，如果参数大于当前元素个数，则新增默认0元素直到元素个数等于参数，如果小于则截断

reserve则用来改变当前容器的最大容量，他不会生成新元素，只是确定这个容器允许放入多少对象，如果参数len大于当前的capacity，那么会开辟一个新的len大小的空间，将之前的对象复制过来，并销毁旧空间。

如果需要的内存空间小于或者等于当前容量，reserve什么也不做

所以调用reserve永远也不会减少容器占用内存空间的大小

**<mark>27.map为什么采用红黑树，不采用AVL树</mark>**

因为红黑树在效率和简单性之间提供了良好的平衡。

红黑树确保没有一条路径会比其他路径长出两倍，因此红黑树是一种弱平衡树，相对于要求严格的AVL树来说，旋转次数更少。AVL树比红黑树更加平衡，意味着他需要更加频繁的旋转来维护。

因此AVL树一般适用于读取查找密集型任务。而红黑树适用于插入修改密集型任务。

**<mark>28.TCP三次握手</mark>**

（1）一开始，客户端和服务端都处于closed状态。先是服务端主动监听某个端口，处于LISTEN状态。

（2）客户端随机初始化一个序列号（client_isn)，将此序号置于TCP首部的序列号字段中，同时把SYN标志位置为1，表示SYN报文。接着把第一个SYN报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于SYN-SENT状态。

（3）服务端收到客户端的SYN报文后，首先服务端也随机初始化自己的序列号（server_isn），将此序号填入首部的序列号字段中，其次把TCP首部的确认应答号字段填入client_isn+ 1，接着把SYN和ACK标志位置为1，最后把该报文发给客户端，该报文不包含应用层数据。之后服务端处于SYN-RCVD状态。

（4）客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文TCP首部ACK标志位置为1，其次确认应答号字段填入server_isn + 1，最后把报文发送给服务端，这次报文可以携带客户端到服务端的数据，之后客户端处于ESTABLISHED状态。

（5）服务端收到客户端的应答报文后，也进入ESTABLISHED状态。

**<mark>29.TCP四次挥手</mark>**

（1）客户端打算关闭连接，此时会发送一个TCP首部FIN标志位被置为1的报文，也即FIN报文，之后客户端进入FIN_WAIT_1状态。

（2）服务端收到FIN报文后，就向客户端发送ACK应答报文，接着服务端进入CLOSE_WAIT状态。

（3）客户端收到服务端的ACK应答报文后，进入FIN_WAIT_2状态。

（4）等待服务端处理完数据后，也向客户端发送FIN报文，之后服务端进入LAST_ACK状态。

（5）客户端收到服务端的FIN报文后，回一个ACK报文，之后进入TIME_WAIT状态

（6）服务端收到了ACK应答报文，就进入了CLOSE状态，至此服务端已经完成连接的关闭。

（7）客户端在经过2MSL时间后，自动进入CLOSE状态，至此客户端也完成连接的关闭。

**<mark>30.三个门，两个门后面是羊，一个门后面是车，现在你选择一个门</mark>**

**<mark>主持人会给你打开一个不是车的门，你有一次换门的机会</mark>**

**<mark>请问，是否要换？(是否会提升你的中奖概率)</mark>**

换。只有第一次选对了，不换才能中奖，而第一次选对的概率为1/3，所以换比不换合适

**<mark>31.c++的static和const的区别</mark>**

（1）修饰局部变量：

const修饰的局部变量为只读，其值不可以修改。

static修饰局部变量则改变了它的生命周期，让静态局部变量在出了作用域后仍然存在，到程序结束，生命周期才结束。

（2）修饰全局变量：

如果修饰的全局变量只在一个文件中使用，那么const的作用和局部变量处的作用一样。

一个全局变量被static修饰，则使得这个全局变量只能在本源文件中使用，不能在其他源文件使用

（3）修饰类成员变量

const修饰类成员变量与修饰全局和局部变量类似，其在使用时不能被修改，因此必须使用构造函数初始化列表进行初始化。

static修饰的类成员变量，必须在类外定义，定义时不添加static关键字，但需要添加作用域限定符声明。静态成员变量不属于某个单独的对象，而属于类所有。所有对象共享静态成员变量。

（4）修饰类成员函数

const修饰类的成员函数，实际修饰该成员函数隐含的this指针，表明在该成员函数中不能对类的任何成员变量进行修改，但也可以在某些变量前加上mutable关键字，使其可以被修改。

static修饰的类成员函数，也被所有的类对象所共享，不属于某个具体的实例。没有this指针，不能访问任何非静态成员。

（5）修饰类对象和类

const修饰类对象，对象中的变量均不可被修改，其只能调用const成员函数，非const对象既可以调用普通成员函数，也可以调用const成员函数。

static不能修饰一个普通类，但是可以修饰内部类，被修饰的内部类可以被当成一个普通类来使用，不需要先实例化一个外部类。

**<mark>32.进程和线程的区别</mark>**

调度：线程是程序执行的基本单位。进程是拥有资源的基本单位。

并发性：不同进程之间切换实现并发，各自占有CPU实现并行；一个进程内部的多个线程并发。

拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享属于进程的资源；进程是拥有资源的独立单位。

系统开销：线程切换时只需保存和设置少量寄存器内容，因此开销很小；进程需要切换虚拟地址空间，切换内核栈和硬件上下文等，开销很大。

**<mark>33.Linux中为什么设计了内核态和用户态</mark>**

出于保护机制，防止用户进程误操作或者是恶意破坏系统。内核态类似于c++的私有成员，只能在类内访问，用户态类似于公有成员，可以随意访问。

在CPU的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。如果允许所有的程序使用这些指令，那么系统的崩溃概率将大大增加，所以CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成危险的指令。

**<mark>34.有什么方式进行内核态和用户态的切换</mark>**

（1）系统调用。

由于用户态无法完成某些任务，所以会请求切换到内核态，内核态将通过为用户专门开放的中断完成切换。

（2）出现异常

在执行用户程序时出现某些不可知的异常时，会从用户程序切换到内核中处理该异常的程序，也就是切换到了内核态。

（3）外围设备中断。

外围设备发出中断信号，当中断发生后，当前运行的进程暂停运行，并由操作系统内核对中断进程处理，如果中断之前CPU执行的是用户态程序，就相当于从用户态切换到了内核态。

**<mark>35.4亿数据中找出几个数</mark>**

(1) 分治法。

对这4亿个数进行哈希运算，按照某个特征划分为多个小文件，然后将小文件直接读取到内存中进行遍历。

(2) 外排序+归并

a.将4亿个数据分割成多个较小的块（例如1万个数据为一块），每个块都能在内存中进行排序。

b.对每个块进行排序，可以使用常见的排序算法，如快速排序或归并排序。

c.将排序后的块写回磁盘，并逐个读取它们。

d.使用归并操作将这些块合并成更大的有序块。可以使用归并排序的思想，逐个从每个块中选择最小的元素，并将其写入输出文件。

e.重复上一步骤，直到所有块都被合并成一个排序好的文件。

f.在合并后的有序块上执行二分搜索算法来查找特定数。二分搜索可以快速定位到目标数的位置

外排序和归并的方式可以有效地处理大规模数据集，因为它避免了将整个数据集加载到内存中进行排序的问题。它允许在有限的内存空间下对大量数据进行排序和处理。

**<mark>36.设计一个strcpy函数。dest长度不够怎么办。拷贝用memcpy，释放空指针，结尾补'\0'</mark>**

```
函数原型：char * strcpy(char* dest, const char* src) 
//将src复制到dest字符数组中
头文件：#include <string.h>
返回值：返回的是第一个参数的值，即目的数组的首地址

注意点：
1、strcpy只用于字符串复制，遇到‘\0’时停止，还会复制字符串的结束符‘\0’.
所以源字符串必须以‘\0’结束。
2、目标空间必须可变。
3、如果参数dest所指的内存空间不够大，可能会造成缓冲溢出的错误情况，在编写程序时
需特别留意，或者用strncpy（）来代替。


strncpy不会向dest追加结束标记'\0'


函数实现1：
char * mystr(char* dest, const char* src) {
    char* ret = dest;
    while(*src != '\0') {
        *dest = *src;
        dest++;
        src++;
    }
    *dest = *src; //复制'\0'
    return ret;
}


函数实现2：
char * mystr(char* dest, const char* src) {
    assert(dest != NULL && src != NULL)；
    if(dest == NULL || src == NULL) return NULL;
    if(dest == src) return dest;

    char* ret = dest;
    while(*dest++ = *src++) {
        ;
    }
    *dest = *src;
    return ret;
}

int main() {
    char* str = new char[5];
    mystr(str, "aaaaa");
    cout<<str<<endl;
}
```

在C++中，使用 `new char[1]` 分配的内存空间确实只能容纳一个字符。然而，C++并没有对内存访问进行边界检查，因此你可以复制一个长度为10的字符串到这个分配的内存空间中。

这种情况下，虽然你可以复制较长的字符串进去，但这是一种不安全的行为，可能导致内存越界访问和未定义行为。在复制长度超过分配内存空间的字符串时，会覆盖分配的内存之外的位置，可能会影响到其他变量或导致程序崩溃。

为了确保安全性，你应该在分配内存时分配足够的空间以容纳要存储的字符串，例如 `new char[10]`。这样可以确保你有足够的内存来存储字符串，并避免了越界访问的问题。

总之，尽量避免在分配的内存空间之外进行写入操作，以确保程序的正确性和安全性。

**<mark>37.strlen和sizeof的区别</mark>**

（1）sizeof是运算符，不是函数，结果是在编译时得到而非运行中获得，strlen是字符处理的库函数

（2）sizeof参数可以是任何数据的类型或者数据；strlen的参数只能是字符指针且结尾是‘\\0’

的字符串

（3）因为sizeof是在编译时确定，所以不能用来得到动态分配（运行时分配）的存储空间的大小。

**<mark>38.内存管理中堆和栈的区别</mark>**

（1）申请方式不同：

栈由系统自动分配，堆是由我们自己申请和释放的

（2）申请大小限制不同：

栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，ulimit -s修改。

堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。

（3）申请效率不同：

栈由系统分配，速度快，不会有碎片。

堆由程序员分配，速度慢，会有内存碎片。

**<mark>39.栈与队列的区别</mark>**

（1）队列先进先出，栈先进后出。

（2）对插入和删除操作的限制不同：

栈是只能在表的一端进行插入和删除操作的线性表。

队列是只能在表的一端进行插入和在另一端进行删除操作的线性表。

（3）遍历数据速度不同：

栈只能从头部取数据，也就是最先放入的需要遍历整个栈最后才能取出来，而且在遍历数据的时候还得数据开辟临时空间，保持数据在遍历前的一致性。

队列则不同，队列可以通过从头部取出数据再放入尾部的方式来遍历数据，不需要额外的空间。

**<mark>40.static是全局变量吗？</mark>**

不一定

**<mark>41.封装、继承、多态</mark>**

**封装**：

就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让自己信任的类或对象操作，对不信任的进行信息隐藏。一个类就是封装了数据以及操作这些数据的代码的逻辑实体。

**继承**：

是指可以让某个类型的对象获得另一个类型的对象的属性的方法。派生类可以使用其父类的所有功能，并在无需重新编写父类的情况下对这些功能进行扩展。继承的过程，就是从一般到特殊的过程。

实现继承：子类直接使用父类的属性和方法，而无需额外编码

接口继承：子类只继承属性和方法的名称，并提供自己的实现方式

**多态**：

即一个接口，可以实现多个方法。就是向不同的对象发同一个消息，不同对象在接收时会产生不同的行为（即方法）。

多态与非多态的实质区别就是函数地址是早绑定还是晚绑定的，如果函数的调用，在编译期间就可以确定函数的调用地址，并产生代码，则是静态的，即地址早绑定。而如果函数的调用地址需要在运行时才能确定，则是晚绑定。

**<mark>42.你项目中哪一种指针用的比较多。</mark>**

unique_ptr

**<mark>43.socket如何建立</mark>**

**TCP**：

（1）服务端和客户端初始化socket，得到文件描述符。

（2）服务端调用bind，绑定IP地址和端口。

（3）服务端调用listen，进行监听。

（4）服务端调用accept，等待客户端连接。

（5）客户端调用connect，向服务端的地址和端口发起连接请求。

（6）服务端accept返回用于传输的socket的文件描述符。

（7）客户端调用write写入数据，服务端调用read读取数据。

（8）客户端断开连接时，会调用close，那么服务端read读取数据时，会读取到EOF，待处理完数据后，服务端调用close，表示连接关闭。

**bind函数**的作用主要是socket函数并没有为套接字绑定本地地址和端口号，服务端必须显式绑定地址和端口号。

**listen函数**的主要作用就是将套接字（sock）变成被动的连接监听套接字（被动等待客户端的连接），参数backlog用于设置内核中连接队列的长度。

**accept函数**的功能是，从处于established状态的连接队列头部中取出一个已经完成的连接，如果没有则阻塞。

**connect**与三次握手直接相关。

**UDP**：

由于没有三次握手，所以不需要调用listen和connect。但是UDP交互仍需要IP地址和端口号，因此需要bind。

对于UDP来说，不需要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念。因此每一个UDP的socket都需要bind。

socket               socket

bind                   bind

sendto               sendto

recvfrom           recvfrom

**<mark>44.全连接队列，半连接队列</mark>**

![半连接队列与全连接队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg)

服务端收到客户端的SYN请求后，内核会把该连接存储到半连接队列，并向客户端响应SYN+ACK，接着客户端返回ACK，服务端收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的连接，并将其添加到全连接队列，等待进程调用accept函数时把连接取出来。

**<mark>45.TCP/IP模型</mark>**

应用层：主要为应用程序提供服务，工作在用户态，以下几层都工作在内核态。

传输层：包含TCP和UDP协议，负责建立、管理和维护端到端的连接。

网络层：负责IP选址和路由选择

网络接口层：也可分为数据链路层和物理层，主要为网络层提供链路级别的传输服务，负责在以太网、WiFi这样的底层网络上发送原始数据包。

**<mark>46.linux命令：chmod，scp，chattr，pgrep，awk</mark>**

**chmod**：改变文件或目录权限

**scp**：远程拷贝文件

scp root@www.runoob.com:/home/root/others/music /home/space/music/1.mp3

scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music

**chattr**：更改文件属性

用chattr命令防止系统中某个关键文件被修改：

chattr +i /etc/resolv.conf

**pgrep**：用于检索当前正在运行的进程

pgrep 命令中使用 `-l` 和 `-a` 选项可以列出与用户相关联的进程 id 和进程名。`-l` 选项将只列出进程名，而 `-a` 将列出进程名的完整路径。

```text
[root@linuxtechi ~]# pgrep -u apache -l
4353 httpd
4354 httpd
4355 httpd
4356 httpd
4357 httpd
4358 httpd
4359 httpd
4360 httpd
[root@linuxtechi ~]#

[root@linuxtechi ~]# pgrep -u apache -a
4353 /usr/sbin/httpd -DFOREGROUND
4354 /usr/sbin/httpd -DFOREGROUND
4355 /usr/sbin/httpd -DFOREGROUND
4356 /usr/sbin/httpd -DFOREGROUND
4357 /usr/sbin/httpd -DFOREGROUND
4358 /usr/sbin/httpd -DFOREGROUND
4359 /usr/sbin/httpd -DFOREGROUND
4360 /usr/sbin/httpd -DFOREGROUND
```

**awk**：文本和数据进行处理的编程语言

```
[root@dev01 yeyz_shell]# cat awk_test.txt 
this is a test file 
this is a test file 
this is a test file 
this is a test file 
this is a test file 
[root@dev01 yeyz_shell]# cat awk_test.txt | awk '{print $1,$2}'
this is
this is
this is
this is
this is
```

其中 awk '{print 1,2}'是指打印出这个文件的第一列和第二列。当我们不指定分隔符的时候，awk会默认按照空格来进行分割，当字符中间的空格有多个的时候，awk会将连续的空格理解为一个分隔符。

**<mark>47.如何后台运行程序</mark>**

（1）在命令的最后加上&，可以把这个命令放到后台执行

（2）ctrl+z可以挂起进程，进程处于暂停状态。使用**jobs**查看后台运行进程的序号，再使用**bg%序号** 在后台运行进程。

（3）nohup+&，将标准输出和标准错误缺省的话，会被重定向到nohup.out文件中，忽略所有SIGHUP信号。

**<mark>48.nohup和&区别</mark>**

在命令的末尾加&后，程序可以在后台运行，但一旦当前终端关闭，该程序就会停止运行。

那么假如我们想要退出当前终端，但又想让程序在后台运行，就需要用nohup。

比如想远程到服务器编译程序，但网络不稳定，一旦掉线就编译中止，就需要重新开始编译，很浪费时间。

nohup就是不挂起的意思（no hang up）。一般形式为：

```
nohup ./test &
```

这样使用则程序的输出默认重定向到一个nohup.out文件下。

```
nohup ./test > myout.txt 2>&1 &
```

2>&1 是指将标准错误重定向到标准输出，于是标准错误和标准输出都重定向到指定的myout.txt文件中。

使用nohup之后，需要使用exit正常退出当前账户，这样才能保证命令一直在后台运行。

**<mark>49.vector和list遍历哪个快</mark>**

vector为随机访问容器，数据在内存连续分布，cache miss概率小，而list通过头尾指针遍历，遍历时需要跳转，内存分布不连续，cache miss概率大，所以理论上vector更快。

**<mark>50.指针和引用的区别</mark>**

（1）指针是一个变量，存储一个地址，引用是原变量的别名

（2）指针可以有多级，引用只有一级

（3）指针可以为空，且可以先声明而不初始化，引用不能为NULL且在定义时必须初始化

（4）指针在初始化后可以改变其指向，引用在初始化之后不可以再改变

（5）sizeof指针得到的是这个指针的大小，sizeof引用得到的是引用所指向变量的大小

（6）当把指针作为参数进行传递时，也就是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，改变形参的指向对实参没有影响。而引用却可以。

**<mark>51.说一下缺页中断</mark>**

（1）概念：缺页中断就是当软件试图访问一个已经映射在虚拟地址空间中，但并未加载到物理内存中的分页时，由中央处理器的内存管理单元所发出的中断。

（2）分类：

**软性页缺失**：指页缺失发生时，相关的页已经被加载进内存，但是没有向MMU注册的情况，操作系统只需要在MMU中注册相关页对应的物理地址即可。（MMU：内存管理单元，负责将虚拟内存地址转换成物理地址）。

**硬性页缺失**：相关的页在页缺失发生时未被加载进内存的情况。

**无效页缺失**：当程序访问的虚拟地址是不存在于虚拟地址空间内的时候，则发生无效页缺失。

（3）中断：指计算机在执行程序的过程中，当出现异常情况或特殊请求时，计算机停止现在运行的程序，转向对这些异常情况或特殊请求的处理，处理结束后再返回程序暂停前的位置，继续运行程序。

具体的缺页中断处理也分为两类：

第一类是内存中还有空闲块，则直接将缺页从外存中调入内存；

第二类是内存已满，需要采用页面置换算法淘汰某页再进行调入。（最佳页面置换算法，FIFO，最近最久未使用，时钟，最不常用）

**<mark>52.TCP在哪一层</mark>**

传输层

**<mark>53.HTTP基于什么</mark>**

http协议是基于TCP/IP协议之上的应用层协议

基于请求-响应模型

**<mark>54.输入域名到页面渲染经历了什么</mark>**

（1）解析URL，生成发送给WEB服务器的HTTP请求信息。

（2）查询服务器域名对应的IP地址，如果缓存中有对应域名的缓存，就直接返回，没有就需要通过DNS服务器来解析

（3）获取到IP后，就可以把HTTP的传输工作交给操作系统中的协议栈。

（4）协议栈上半部分是TCP/UDP协议，执行收发数据的操作，下半部分是IP协议，控制网络包的收发。

（5）通过三次握手建立TCP连接。

（6）建立连接后，浏览器向WEB服务器发送HTTP请求

（7）服务器收到请求后，进行对应的处理，把数据传给浏览器，也就是返回网络响应。

（8）完成以上过程后，数据已经到达浏览器端，接下来浏览器解析并渲染数据。

**<mark>55.B+ Tree</mark>**

B+树是一棵自平衡的多叉树。

（1）它只有叶子节点才存放数据（索引+记录），非叶子节点只存放索引。

（2）父节点的所有索引都包含在子节点中

（3）叶子节点保存所有的索引信息，并且叶子节点构成一个单向的有序链表。在INNODB存储引擎中有俩个指针，分别指向下一个和上一个叶子节点，形成双向链表。可以提高范围搜索的效率。

查询方式：

（1）单点查询：由于B+树的非叶子节点不存放实际的记录数据，仅存放索引，这样每个节点可容纳的元素个数多，所以它的深度很低，查询到底层节点的磁盘IO次数很少。

（2）插入和删除效率：B+树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，删除效率高。插入可能存在节点的分裂，但是最多只涉及树的一条路径。

（3）范围查询：双向链表，范围查询速度快

**<mark>56.红黑树原理</mark>**

红黑树在效率和简单性之间提供了良好的平衡。

红黑树是一种特殊的二叉搜索树，每个节点都要存储节点的颜色，或红或黑。

它具有5个特性：

（1）每个节点或红或黑

（2）根节点是黑色

（3）空叶子节点是黑色

（4）如果一个节点是红色，那么它的子节点是黑色。

（5）从任意一个节点出发到空的叶子节点经过的黑节点个数相同

红黑树的任何一个节点的左右子树的高度差不会超过俩倍。

通过左旋右旋以及重新着色的操作来维持上述特性。

**<mark>57.O(logn)复杂度查询的数据结构</mark>**

（1）二叉搜索树。

和二分查找一样，插入和查询为O(logn)，但由于插入和删除操作时不保证平衡，所以最坏为O(n)。

（2）二叉平衡树

总是保持平衡，查找、插入、删除在最坏情况下都是O(logn)

（3）二叉伸展树

在每次查找后对树进行重构，把被查找的条目搬到离树根近的地方，但不保证最坏情况下O（logn）复杂度。

（4）跳表

跳表是一个多级索引的链表结构，从顶层链表开始搜索，直到找到一个大于等于目标的元素，或到达尾部。如果等于，则目标已经被找到，如果大于，则退回当前层的前一个元素，然后转入下一层搜索。![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430132656662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MDc4NQ==,size_16,color_FFFFFF,t_70)

（5）数组

二分查找

**<mark>58.4种隔离级别</mark>**

多个事务并发执行时可能会遇到【脏读，不可重复读，幻读】的现象。

脏读：读到其他事务未提交的数据；

不可重复读：前后读取的数据不一致；

幻读：前后读取的记录数量不一致。

SQL标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能越低

（1）读未提交：指一个事务还没提交时，他做的变更就能被其他事务看到

（2）读提交：指一个事务提交之后，他做的变更才能被其他事务看到

（3）可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的。MySQL InnoDB默认隔离级别

（4）串行化：对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突，后访问的事务必须等前一个事务执行完成，才能继续执行

在【读未提交】隔离级别下，可能发生脏读、不可重复读和幻读。

【读提交】：不可重复读，幻读

【可重复读】：幻读

【串行化】：都不会发生

**<mark>59.讲一下协程</mark>**

协程是用户态的轻量级线程，是线程内部调度的基本单位。

同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理。

（1）协程是由用户代码控制的，而不是由操作系统内核调度。它不依赖于操作系统提供的线程管理机制，因此可以在用户空间实现，并避免了线程切换的开销。

（2）可以在一个线程内执行多个协程，并且可以通过协程之间的切换来实现多任务并发。这种切换是协作式的，也就是说一个协程在执行过程中可以主动让出执行权给其他协程。

**<mark>60.条件变量怎么用，说一个使用情况</mark>**

条件变量（cond）和锁（mutex）是紧密相关的。

锁的使用场景是：一件事同时只有一个人能做，我抢到锁我就进去操作，操作完毕后再给下一个人做。

而使用条件变量的场景是：

（1）首先，这件事还是同时只能一个人做，所以还要用到锁，但线程抢到锁之后，发现还要等待一些条件满足，才能做。

（2）这时如果让抢到锁的线程一直循环不停检查这个条件，不仅消耗高，而且每次检查完为了不让CPU一直空跑，需要sleep一下，而sleep的时间如果定少了，则消耗高，如果定的太大，则有延迟，无法即时发现条件满足了。而且抢到锁后一直检查，别的线程就拿不到锁了。

（3）所以引入了条件变量，抢到锁的线程发现条件未满足时，释放锁，使用pthread_cond_wait()挂起自己。这时别的线程也能获取锁进来，发现条件不满足同样挂起。直到条件满足后，由其他地方调用pthread_cond_broadcast()来唤醒全部挂起的线程，或调用pthread_cond_signal()来唤醒指定线程.

**使用情况**：消费者生产者模型

（1）生产者和消费者都需要操作同一个队列，同一时间只能由一个人操作

（2）消费者需要等待生产者生产完毕后，才能进行消费，所以消费者是pthread_cond_wait等待的那一方，生产者是pthread_cond_broadcast通知的那一方。

**<mark>61.构造函数能不能声明为虚函数</mark>**

同8

**<mark>62.动态链接库</mark>**

动态链接库（DLL）是一个包含函数和数据的模块，它可以被其他模块使用

在DLL中可以定义俩种函数：导出函数和内部函数。

导出函数可以被其他模块调用，内部函数一般而言用于DLL内部。DLL中定义的数据一般只在DLL内使用。

DLL提供了一种模块化应用程序的方法，在多个程序中同时使用相同的函数时，使用DLL有助于减少内存占用。

**<mark>63.c++中一个子类最多可以继承多少个父类</mark>**

c++中一个子类可以继承多个父类，对可以继承的父类数量没有具体限制。但是通常建议限制父类的数量，以避免复杂性和可维护性问题。

**<mark>64.工厂模式</mark>**

用一个简单的类来创建实例的过程就称为工厂，用工厂方式代替外部new操作的这种设计模式称为工厂模式。它是一种创建型的模式，提供了一个创建对象的最佳方法。在工厂模式中，我们创建对象时不会对上层暴露创建逻辑。

分类：简单工厂模式，工厂方法模式，抽象工厂模式

**简单工厂模式**：

简单工厂模式由一个工厂类根据传入的参数，动态决定应该创建哪一种产品类实例。

```
#include <iostream>
#include <vector>
#include <algorithm>
#include <queue>
#include <string>
#include <cmath>
#include <assert.h>
using namespace std;

class operation {
public:
    operation(){}
    virtual int getResult(int num1, int num2) = 0; //设置为纯虚函数，不可以生成该类的对象，但可以声明该类的指针
};

class operationAdd: public operation{
    int getResult(int num1, int num2) {
        return num1 + num2;
    }
};

class operationSub : public operation {
    int getResult(int num1, int num2) {
        return num1 - num2;
    }
};

class operationMult : public operation {
    int getResult(int num1, int num2) {
        return num1 * num2;
    }
};

class operationDiv : public operation {
    int getResult(int num1, int num2) {
        assert(num2 != 0);
        return num1 / num2;
    }
};

class OperationFactory { //工厂
public:
    operation* createOperate(char operate) {
        operation* oper = NULL;
        switch (operate) 
        {
            case '+': {
                oper = new operationAdd();
                return oper;
            }
            case '-': {
                oper = new operationSub();
                return oper;
            }
            case '*': {
                oper = new operationMult();
                return oper;
            }
            case '/': {
                oper = new operationDiv();
                return oper;
            }
        }
    }
};

int main() {
    int num1 = 0;
    int num2 = 0;
    char operate;
    cin >> num1 >> operate >> num2;
    operation* oper;
    OperationFactory fac;
    oper = fac.createOperate(operate);
    int res = oper->getResult(num1, num2);

    cout << res << endl;
}
```

[工厂模式（C++编码） - HOracle - 博客园](https://www.cnblogs.com/horacle/p/15494358.html)

**<mark>65.单例模式</mark>**

是为了保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。

**懒汉版**：单例实例在第一次被使用时才初始化。

```
class A{
private: 
    A() {} //私有构造函数，无法直接创建对象
    static A* instance;
public:
    static A* Getinstance() {
        if (instance == NULL) {
            instance = new A();
        }
        return instance;

    }
};

A* A::instance = NULL;

int main() {
    A* a1 = A::Getinstance();
    A* a2 = A::Getinstance();
    if (a1 == a2) cout << 1111 << endl;

}
```

线程安全问题：

（1）首先想到可以加锁：

```
static Singleton* getInstance() {
    Lock lock;  // 基于作用域的加锁，超出作用域，自动调用析构函数解锁
    if(instance == NULL) {
        instance = new Singleton();
    }
    return instance;
}
//这种方法锁的代价过高
```

```
static Singleton* getInstance() {
    if(instance == NULL) {
        Lock lock;  // 基于作用域的加锁，超出作用域，自动调用析构函数解锁
        if(instance == NULL) {
            instance = new Singleton();
        }
    }
    return instance;
}
//双检查锁，先检查是否为空，空的话才加锁
/*但由于内存读写reorder不安全，所以不能用
对于instance = new Singleton();这一行代码
我们默认的顺序是，先分配内存，再调用构造函数进行初始化，然后将这块内存的首地址返回给
instance。
但在CPU层面，这三个步骤有可能会被reorder。
执行的顺序有可能会变成：（1）先分配内存 （2）然后就将内存返回 （3）最后再调用构造函数
那么此时第二步执行完后instance就不等于NULL了，如果此时另一个线程进来，
判断instance ！= NULL，然后直接返回instance进行使用，就会产生错误。
因为此时的instance还未被构造出来，不可以使用。
*/
```

（2）更好的方式：C++11规定了local static在多线程条件下的初始化行为，要求编译器保证了内部静态变量的线程安全性。static在局部变量使用时初次定义就要初始化，且只能初始化一次，重复调用同一函数，第二次调用时不会执行static局部变量初始化的那句话。

```
// version 1.2
class Singleton
{
private:
    Singleton() { }
    ~Singleton() { }
    Singleton(const Singleton&);
    Singleton& operator=(const Singleton&);
public:
    static Singleton& getInstance() 
    {
        static Singleton instance;
        return instance;
    }
};
```

内存泄漏问题：

注意到第一种基础写法中，类中new出对象之后，没有调用delete释放，因此只有构造函数被调用，析构函数没有被调用，因此会造成内存泄漏。

解决方法：

（1）使用共享指针。

（2）使用局部静态变量，同线程下的（2）

[C++ 单例模式总结与剖析 - 一杯清酒邀明月 - 博客园](https://www.cnblogs.com/ybqjymy/p/14921444.html)

**饿汉版**：

```
//饿汉模式，没有线程安全问题，无需加锁
class singleHungry
{
private:
    int dataA;
    int dataB;
private:
    //构造函数私有化
    singleHungry(int a, int b):dataA(a),dataB(b){} 

    //禁用默认拷贝构造、赋值运算符函数
    singleHungry(const singleHungry& s) = delete;
    singleHungry& operator= (const singleHungry& s) = delete;
public:
    ~singleHungry(){}
    static singleHungry s_instacne;
    static singleHungry& getInstacne();

    //业务逻辑
    int getAddResult()
    {
        int result = dataA + dataB;
        cout<<"add result = "<<result<<endl;
        return result;
    }
};

//静态变量需要在类外进行初始化，由于对象是静态变量，存储在静态存储区，无需人为回收，进程结束自动回收内存
singleHungry singleHungry::s_instacne(1,2);
singleHungry& singleHungry::getInstacne()
{
    return s_instacne;
}
```

潜在问题在于static singleHungry s_instance 和 getAddResult二者初始化顺序不确定，如果在初始化完成之前调用getInstance方法会返回一个未定义的实例。

**<mark>66.malloc之后怎么在里面创建一个指针变量</mark>**

```
int* ptr = static_cast<int*>(malloc(sizeof(int)));
//可以通过类型转换将分配的内存视为指针变量的存储空间，然后如下所示
```

```
int** pptr = (int**)malloc(n * sizeof(int*);//分配一块内存用来存放指针变量

int* ptr = (int*)malloc(sizeof(int));//分配一块内存

*pptr = ptr;

cout << *ptr << endl; //ptr 指向的地址的值
cout << &ptr << endl;//ptr 本身的地址
cout << ptr << endl;//ptr 指向的地址
首先分配一块内存用来存放指针变量，pptr指向一块能够存放n个int* 类型的空间。
然后将ptr指向的地址作为pptr指向的地址的值，
即pptr所指向的空间里面存放的是ptr这个指针变量。
```

**<mark>67.接口怎么设计</mark>**

（1）需要确保如果客户企图使用某个接口而却没有获得他所预期的行为，这个代码就不应该通过编译；如果代码通过了编译，那它的行为就是客户想要的。

```
class Date
{
public:
    Date(int month, int day, int year);
    …
};
```

这个类做了一个假设---用户都能按月，日，年的顺序来传参。但一定会有不少用户记错这个顺序。

一种好的解决方法是，假定用户输入的数据都是不可靠的，需要对输入进行严格的检查。并提供好的引导方式，让用户知道自己传的是什么参数。

```
class Month
{
private:
    int m_month;
public:
    explicit Month(int month): m_month(month){}
};

class Day
{
private:
    int m_day;
public:
    explicit Day(int day): m_day(day){}
};

class Year
{
private:
    int m_year;
public:
    explicit Year(int year): m_year(year){}
};

class Date
{
private:
    Year m_year;
    Month m_month;
    Day m_day;

public:
    Date(Year year, Month month, Day day): m_year(year), m_month(month), m_day(day){}

};

int main()
{
    Date date(Year(2013), Month(5), Day(28));
}
```

其中Year、Month、Day类中的构造函数前有explicit关键字，也就是不允许隐式构造，如Data data(2013, 5, 28)会报错。

（2）让编译器对不正确的行为进行阻止，常见的方法是加上const。

```
if(a = b * c){…} //应写成==
const Object operator* (const Object& a, const Object& b); 
//使用const编译器就可以识别出赋值运算符不正确
```

（3）让自定义类型的行为尽量与内置类型行为一致。如不要重载乘号运算符，但里面却做加法。

（4）多使用shared_ptr来代替原始指针

**<mark>68.为什么TCP握手是三次而不是俩次</mark>**

（1）三次握手才可以阻止重复历史连接的初始化（主要原因）：

**三次握手如何避免历史连接**：

如果客户端发送了SYN报文（seq = 90），然后宕机了。而且这个SYN报文被网络阻塞了，服务端没有收到。接着客户端重启后，又重新向服务端建立连接。发送了SYN（seq = 100）报文。简单地说，客户端连续发送了多次建立连接的报文，在网络拥堵的情况下：

（a）一个【旧SYN报文】比【新SYN报文】先抵达服务端，服务端就会回一个SYN+ACK报文给客户端，此报文中的确认号是91（90 + 1）

（b）客户端收到后，发现自己期望的确认号应该是（100 + 1），而不是90 + 1，所以就会回RST报文。

（c）服务端收到RST报文后，就会释放连接。

（d）后续最新的SYN报文抵达服务端后，客户端与服务端就可以完成三次握手了。

如果服务端在收到RST报文之前，先收到了【新SYN报文】，那么就会回challenge ACK报文给客户端，这个ack报文并不是确认收到【新SYN报文】的，而是上一次的ack确认号，也就是90+1. 客户端收到后就会回复RST。

**二次握手为什么不行**：

在二次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。

在俩次握手的情况下，服务端在收到SYN报文后就进入了ESTABLISHED状态，意味着这时可以向对方发送数据，但是客户端此时还没有进入ESTABLISHED状态，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-04-21-15-00-04-image.png)

（2）同步双方初始序列号

当客户端发送携带【初始序列号】的SYN报文的时候，需要服务端回一个ACK应答报文，表示客户端的SYN报文已被服务端成功接收，那当服务端发送【初始序列号】给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步**。

而俩次握手只能确保一方的初始序列号能被对方成功接收。

（3）避免资源浪费

如果只有俩次握手，如果客户端发送的SYN报文在网络中阻塞了，重复发送多次SYN报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-04-21-15-06-50-image.png)

**<mark>69.线程池是什么？核心参数？你的项目什么时候用了线程池？怎么用的？</mark>**

**是什么**：

（1）所谓线程池，就是一个pthread_t类型的普通数组，通过空间换时间的方式，消耗服务器的硬件资源，换取运行效率。

（2）它是一组线程资源的集合，这组资源在服务器启动之前就被完全创建好并初始化。

（3）当服务器进入正式运行阶段，开始处理客户端请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配

（4）当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用释放资源。

**核心参数**：

（1）任务队列大小：

取决于每个工作任务的处理时间和系统资源，需要监控系统性能并进行调整，参考取值10000.

（2）线程池数量：

（a）**CPU核心数**：一般情况下线程池的内核数应该与CPU核心数相同或略多一些。对于CPU密 集型的任务，可以选择与CPU核心数相同，避免线程之间的竞争和影响CPU的性能；对于 
I/O密集型任务，可以适当多开一些线程，利用多线程并发机制降低I/O等待时间。  

（b）**系统资源**：考虑线程池所需的内存、CPU等系统资源，对线程池的内核数做出权衡。 
过多的线程会带来内存占用、CPU切换等开销，而过少的线程会导致任务排队等待，  浪费系统资源。  

因此，选择线程池的内核数应该综合考虑各种因素和特性，并根据实际情况进行调整和优化。我设置为8

**项目中什么时候用了，怎么用的**：

项目中使用线程池并发处理用户请求，主线程负责读写，线程池中的线程负责处理逻辑。主线程通过epoll_wait发现某个文件描述符上有可读事件后，主线程就将这个HTTP的请求报文读到该连接的读缓存中，然后将该任务对象插入线程池的任务队列中；线程池中的线程通过竞争锁资源来获取任务，完成报文解析。

**<mark>70.平时怎么提升编程能力</mark>**

学习编程语言，应用框架直接看官方文档，写demo通过github找项目，遇到不懂的去查 StackOverflow。

**<mark>71.实现一个string类</mark>**

```
class Mystring {
private:
    char* _str;
    size_t _size;
    size_t _capacity;

    static const size_t npos;
public:
    //当使用初始化列表时，初始成员变量的顺序与列表排列的顺序没有关系，只取决于声明这些成员变量的顺序
    Mystring(const char* str = ""):_size(strlen(str)), _capacity(_size) { 
        //我们要对形参设置缺省值。当我们没有给string对象赋值，我们默认初始化为空，但这里str实际上里还有一个’\0’.
        //我们在给_str 分配空间的时候，要分配_capacity个，
        //因为此时_capacity = _size = strlen(str).strlen()计算字符串长度的时候不包含’\0’, 所以我们实际开空间要多开一个留给’\0’
        _str = new char[_capacity + 1];
        strcpy(_str, str);
    }

    ~Mystring() {
        delete[] _str;
    }

    Mystring(const Mystring& s):_str(NULL) {
        Mystring tmp(s._str); //这里不是拷贝函数,而是调用的构造函数，构造的行参是指针，拷贝的行参是对象
        swap(tmp);
    }

    Mystring& operator=(Mystring s) { //去掉了引用，把申请临时变量的任务交给形参来做
        swap(s);
        return *this;
    }

    char& operator[](size_t pos) {
        assert(pos < _size);
        return _str[pos]; //等价于*(_str + pos)
    }
    const char& operator[](size_t pos) const{ //后加const，说明该函数不能改变成员变量
        assert(pos < _size);
        return _str[pos];
    }

    void reserve(size_t n) {
        if (n > _capacity) {
            char* temp = new char[n + 1];
            strcpy(temp, _str);
            delete[] _str;
            _str = temp;
        }
        _capacity = n;
    }

    void resize(size_t n, char ch = '\0') {
        if (n < _size) {
            _size = n;
            _str[_size] = '\0';
        }
        else {
            if (n > _capacity) {
                reserve(n);
            }
            for (size_t i = _size; i < n; ++i) {
                _str[i] = ch;
            }
            _size = n;
            _str[_size] = '\0';
        }
    }

    void push_back(char ch) {
        if (_size >= _capacity) {
            size_t newcapacity = 0;
            if (_capacity == 0) {
                newcapacity = 4;
            }
            else newcapacity = 2 * _capacity;
            reserve(newcapacity);
        }
        _str[_size] = ch;
        _size++;
        _str[_size] = '\0';
    }

    void append(const char* str) {
        size_t len = strlen(str);
        if (_size + len > _capacity) {
            reserve(_size + len);
        }
        strcpy(_str + _size, str);
        _size += len;
    }

    Mystring& insert(size_t pos, char ch) {
        assert(pos <= _size);

        if (_size == _capacity) {
            size_t newcapacity = 0;
            if (_capacity == 0) {
                newcapacity = 4;
            }
            else newcapacity = 2 * _capacity;
            reserve(newcapacity);
        }
        size_t end = _size + 1;
        while (end >= pos) {
            _str[end] = _str[end - 1];
            end--;
        }
        _str[pos] = ch;
        _size++;
        return *this;
    }

    Mystring& insert(size_t pos, const char* str) {
        assert(pos <= _size);
        size_t len = strlen(str);

        if (len == 0) return *this;
        if (_size + len > _capacity) {
            reserve(_size + len);
        }
        size_t end = _size + len;
        while (end >= pos + len) {
            _str[end] = _str[end - len];
            end--;
        }
        for (size_t i = 0; i < len; ++i) {
            _str[pos + i] = str[i];
        }
        _size += len;
        return *this;
    }

    Mystring& erase(size_t pos, size_t len = npos) {
        assert(pos < _size);
        if (len == npos || pos + len > _size) {
            _str[pos] = '\0';
            _size = pos;
        }
        else {
            strcpy(_str + pos, _str + pos + len);
            _size -= len;
        }
        return *this;
    }

    const char* c_str() const {
        return _str;
    }

    size_t size() const {
        return _size;
    }

    size_t capacity() const {
        return _capacity;
    }

    Mystring& operator += (char ch) {
        push_back(ch);
        return *this;
    }

    Mystring& operator += (const char* str) {
        append(str);
        return *this;
    }

    Mystring& operator += (const Mystring& s) {
        *this += s._str;
        return *this;
    }

    Mystring operator + (char ch) {
        Mystring temp = *this;
        temp += ch;
        return temp;
    }

    Mystring operator + (const char* str) {
        Mystring temp = *this;
        temp += str;
        return temp;
    }

    Mystring operator + (const Mystring& s) {
        Mystring temp = *this;
        temp += s;
        return temp;
    }

    bool operator > (const Mystring& s) {
        return strcmp(_str, s.c_str());
    }

    bool operator == (const Mystring& s) {
        return strcmp(_str, s.c_str()) == 0;
    }

    bool operator != (const Mystring& s) {
        return !(*this == s);
    }

    bool operator >= (const Mystring& s) {
        return *this > s || *this == s;
    }

    bool operator < (const Mystring& s) {
        return !(*this >= s);
    }

    bool operator <=(const Mystring& s) {
        return !(*this > s);
    }
    bool operator == (const Mystring& s) {
        return strcmp(_str, s.c_str()) == 0;
    }

    friend bool operator == (const Mystring& s1, const Mystring& s2) {
        size_t i1 = 0, i2 = 0;
        while (i1 < s1.size() && i2 < s2.size()) {
            if (s1[i1] != s2[i2]) {
                return true;
            }
        }
    }
public:
    typedef char* iterator;
    typedef const char* const_iterator;

    iterator begin() {
        return _str;
    }

    const_iterator begin() const {
        return _str;
    }

    iterator end() {
        return _str + _size;
    }

    const_iterator end() const {
        return _str;
    }

    void swap(Mystring& s) {
        std::swap(_str, s._str);
        std::swap(_size, s._size);
        std::swap(_capacity, s._capacity);
    }

};

const size_t Mystring::npos = -1;

int main() {
    Mystring s("hello");
    Mystring s1("asdfads");
    s = s + s1;
    for (int i = 0; i < s.size(); ++i) {
        cout << s[i] << endl;
    }

}
```

面试时候写size(), capacity(), c_str()函数

**<mark>72.排序算法</mark>**

快排，冒泡，选择，插入，归并，桶

```
//选择排序
void selection_sort(vector<int>& nums) {
    for(int i = 0; i < nums.size() - 1; ++i) {
        int minindex = i;
        for(int j = i + 1; j < nums.size(); ++j) {
            if(nums[j] < nums[minindex]) {
                minindex = j;
            }
        }
        swap(nums[i], nums[minindex]);
    }
}
```

```
//冒泡排序
void bubble_sort(vector<int>& nums) {
    for (int i = 0; i < nums.size() - 1; ++i) {
        for (int j = 0; j < nums.size() - 1 - i; ++j) {
            if (nums[j] > nums[j + 1]) swap(nums[j], nums[j + 1]);
        }
    }
}
```

```
//插入排序
void insertion_sort(vector<int>& nums) {
    for (int i = 1; i < nums.size(); ++i) {
        for (int j = i; j >= 1; --j) {
            if (nums[j] < nums[j - 1]) swap(nums[j], nums[j - 1]);
        }
    }
}
```

```
//归并排序
void merge(vector<int>& nums, int left, int mid, int right) {
    int s1 = left; //左数组起始位置
    int s2 = mid + 1; //右数组起始位置

    vector<int> temp;
    temp.reserve(right - left + 1);
    while (s1 <= mid && s2 <= right) {
        if (nums[s1] >= nums[s2]) {
            temp.push_back(nums[s2]);
            s2++;
        }
        else {
            temp.push_back(nums[s1]);
            s1++;
        }
    }

    if (s1 <= mid) {
        while (s1 <= mid) {
            temp.push_back(nums[s1]);
            s1++;
        }
    }
    else if(s2 <= right) {
        while (s2 <= right) {
            temp.push_back(nums[s2]);
            s2++;
        }
    }

    for (int i = 0; i < temp.size(); ++i) {
        nums[left] = temp[i];
        left++;
    }
}
void merge_sort(vector<int>& nums, int left, int right) {
    if (left >= right) {
        return;
    }

    int mid = left + ((right - left) >> 1);
    merge_sort(nums, left, mid);
    merge_sort(nums, mid + 1, right);
    merge(nums, left, mid, right);
}
```

```
//快速排序
void quick_sort(vector<int>& nums, int left ,int right) {
    if (left >= right) return;
    srand(time(nullptr));
    int key = rand() % (right - left) + left;
    swap(nums[left], nums[key]);

    int i = left, j = right;
    while (i < j) {
        //必须右先走，否则最后相遇的点不一定比key小
        while (i < j && nums[j] >= nums[left]) j--; //必须是大于等于
        while (i < j && nums[i] <= nums[left]) i++;
        if(i != j) swap(nums[i], nums[j]);
    }

    swap(nums[left], nums[j]);

    quick_sort(nums, left, i - 1);
    quick_sort(nums, i + 1, right);

}
```

**<mark>73.虚拟地址空间</mark>**

（1）从程序局部性原理中我们可以得到这样一个结论：进程在运行时，不会一下子就要访问所有的内存，相反进程对于内存的访问会表现出明显的倾向性。进程更倾向于访问最近访问过的数据，以及热点数据附近的数据。

（2）所以无论一个进程实际可以占用的内存资源有多大，根据程序局部性原理，在某一段时间内，进程真正需要的资源只是很少的一部分，我们只需要为每个进程分配很少的内存就可以保证进程的正常运行

（3）而虚拟内存的引入正是为了解决这个问题，虚拟内存引入后，进程的视角就会变得非常开阔，每个进程都拥有属于自己的虚拟地址空间，进程与进程之间的虚拟地址空间是相互隔离，互不干扰的。

（4）每个进程都认为自己独占所有的内存空间，所有内存资源都属于自己，但其实任何一个虚拟内存里存储的数据，本质上还是保存在物理内存里的，只不过内核帮我们做了虚拟内存到物理内存这一层的映射，将不同进程的虚拟地址和不同内存的物理地址映射起来。

（5）当CPU访问进程的虚拟地址时，将虚拟地址转换成不同的物理地址，这样不同的进程运行时，虽然操作的是同一虚拟地址，真正写入的却是不同的物理地址，就不会造成冲突了。

（6）通过将多进程之间协同的相关复杂细节全部交给内核中的内存管理模块来处理，极大降低了编程的复杂性，这一切都是因为虚拟内存能够提供内存地址空间的隔离，极大的扩展了可用空间。

**<mark>74.malloc底层是怎么分配内存的</mark>**

malloc并不是系统调用，而是C库里的函数，用来动态分配内存。

maloc申请内存的时候，会有两种方式向操作系统申请堆内存。

**方式一**：通过brk（）系统调用从堆分配内存：

实现方式：通过brk（）函数将【堆顶】指针向高地址移动，获得新的内存空间。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/brk%E7%94%B3%E8%AF%B7.png)

**方式二**：通过mmap（）系统调用在文件映射区分配内存：

实现方式：通过mmap（）系统调用中【私有匿名映射】的方式，在文件映射区分配一块内存。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/mmap%E7%94%B3%E8%AF%B7.png)

内存映射即在进程的虚拟地址空间中创建一个映射，分为两种：

（1）文件映射：数据源是存储设备上的文件，把文件的一个区间映射到进程的虚拟地址空间

（2）匿名映射：没有数据源，把物理内存映射到进程的虚拟地址空间

根据**修改是否对其他进程可见和是否传递到底层文件**，内存映射分为共享映射和私有映射

（1）共享映射：修改数据时，映射相同区域的其他进程可以看见，如果是文件支持的映射，修改会传递到底层文件。

（2）私有映射：如果有数据源，第一次修改数据时会从数据源复制一个副本，然后修改副本，其他进程不可见，不影响数据源。

malloc源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

**<mark>75.malloc（）分配的是物理内存吗</mark>**

不是，分配的是虚拟内存。

如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。

只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存地址和物理内存之间的映射关系。

**<mark>76.malloc（1）会分配多大的虚拟内存</mark>**

malloc在分配内存的时候，会预分配更大的空间作为内存池。具体预分配多大的空间，和malloc使用的内存管理器有关。默认的内存管理器对于malloc（1）实际上预分配132K字节的内存。

**<mark>77.malloc申请的内存，free释放内存会归还给操作系统吗</mark>**

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
  
  因为brk（）申请的内存较小，与其把这一块内存释放给操作系统，不如先缓存着放进malloc的内存池里，当进程再次申请时就可以直接复用，速度会快很多。当然进程退出后，操作系统会回收进程的所有资源。

- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

**<mark>78.为什么不全部使用mmap来分配内存</mark>**

（1）因为向操作系统申请内存，要进行运行态的切换。如果每次都用mmap来分配内存，等于每次都要切换到内核态。

（2）因为mmap分配的内存每次释放的时候，都直接归还给操作系统，于是每次分配的虚拟地址都是缺页状态，第一次访问时就会触发缺页中断。导致CPU消耗增大。

为了改进这俩个问题，malloc通过brk申请内存时，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放时，就缓存在内存池中。

等下次再申请内存的时候，直接从内存池中取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还在，这样不仅减少系统调用的次数，还减少缺页中断次数。

**<mark>79.为什么不全部使用brk分配内存</mark>**

考虑一个场景：如果我们连续申请了10k，20k，30k这三片内存，如果10k，20k释放了变成了空闲的内存空间，那么如果下次申请的内存小于30k，就可以重用这个空闲内存空间。

但如果大于30k，此时没有可用的空闲空间，必须再次进行申请。

随着频繁调用malloc和free，堆内将产生越来越多不可用的小块内存碎片，导致内存泄漏

**<mark>80.free函数只传入一个内存地址，为什么能知道要释放多大的内存</mark>**

malloc返回给用户态的内存起始地址比进程的堆空间起始地址多了16个字节，这里面保存了该内存块的描述信息

**<mark>81.键入网址过程</mark>**

同54

**<mark>82.伙伴系统</mark>**

伙伴系统是一种内存碎片的解决方法。他将内存分成若干块，然后尽可能以最适合的方式满足程序内存需求。

定义伙伴这个概念的目的是在分配与释放内存的过程中，能够动态的维护尽可能长的连续内存。

如果请求的连续内存数量是k，那么伙伴系统将选择满足2^n >= k的最小数字n对应的那个分组，如果伙伴系统中没有对应的分组，那么系统会将更大的分组劈开形成一对伙伴，然后看劈开后的分组是否合适，不合适的话就继续劈开，直到到达合适的大小为止。

当释放内存时，伙伴系统会查看释放分组的伙伴是否空闲，如果空闲的话便会合并两个分组形成一个更大的分组，并递归该操作直到当前分组的伙伴繁忙或已形成最大数量的数组。

**<mark>83.c++的内存结构</mark>**

分为5个区

（1）栈：用来存放局部变量和函数参数，由编译器管理分配和回收。

（2）堆：由程序员管理，需要手动分配和回收，空间较大，但可能会出现内存泄漏和空闲碎片的情况。

（3）全局/静态存储区：分为初始化和未初始化俩个相邻区域，存储初始化和未初始化的全局变量和静态变量。已经初始化的在.data区域，未初始化的在.bss区域

（4）常量存储区：存储常量，一般不允许修改。

（5）代码区：存放程序的二进制代码。

**<mark>84.什么情况使用堆，什么情况使用栈</mark>**

（1）因为与堆相比，栈不会导致内存碎片，且分配效率高。所以函数调用通过栈来完成，以及调用过程中的参数，返回地址，和局部变量等都采用栈的方式存放。如果少量数据需要频繁操作，那么在程序中动态申请少量栈内存（alloca函数），会获得很好的性能提升。

（2）堆可以申请的内存比栈大很多。所以如果需要分配大量的内存空间，最好使用堆内存。

**<mark>85.数组和链表的区别</mark>**

（1）内存分布：

数组占用的是一块连续的内存区

链表在内存中是分散的，通过指针来连接

（2）正是因为他们在内存分布上的差异，导致他们的增删查改时间复杂度不同。

**查改**：数组支持随机访问，O(1)

            链表只能顺序访问，O(n)

**增删**：因为数组在内存中是连续的，要想增加或者删除节点，就会导致其后面的节点都需要进行移动，最坏的情况下需要移动整个数组。

链表只需要改变节点的指向，就可以实现增加或删除的操作。

（3）内存预读：内存管理会将连续的存储空间提前读入缓存（程序局部性原理），所以数组往往都会被读入到缓存中，进一步提高了访问的效率。

链表由于在内存中是分散的，往往都不会读入到缓存中，效率较低。

**<mark>86.i=i+1执行多久</mark>**

i = i + 1, i += 1 , i++。

在实际编译过程中，编译器会自动优化，所以效率一样。

如果没有编译器优化：

（1）i = i + 1效率最低

它需要先读取右i地址；

将值+1；

读取左i地址；

将右值传给左边的i；

（2）i += 1其次；

他首先读取 i 的地址；

将值加一；

传给i；

（3）i++最快

他首先读取 i 的地址；

然后值自增1.

**<mark>87.进程的通信方式有哪些</mark>**

（1）管道：

管道是一种半双工的通信方式，数据只能单向流动。

分为俩类：

**无名管道**（即内存文件）：只能在具有亲缘关系的进程之间使用，通常指父子进程关系。

**有名管道**（即FIFO文件）：可以在不相关的进程之间交换数据。

（2）共享内存：共享内存就是映射一段能被其他进程访问的内存，这段内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式（*Inter-Process Communication，进程间通信*），往往与信号量配合使用来实现进程间的同步和通信。

（3）消息队列：是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

（4）套接字：适用于不同机器间进程通信，在本地也可以作为两个进程通信的方式。

（5）信号：用于通知进程某个事件已经发生，比如按下ctrl + c就是一个信号。

（6）信号量：是一个计数器，用来控制多个进程对共享资源的访问

**<mark>88.了解中断吗</mark>**

（1）**定义**：中断是系统用来响应硬件设备请求的一种机制，如敲击键盘的同时就会产生中断，当硬盘写完数据之后也会产生中断。操作系统收到硬件的中断请求，就会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

（2）中断请求会打断其他进程的运行，并且中断处理程序在响应中断时，可能还会临时关闭中断，这意味着，如果在当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就是说中断可能丢失，所以**中断处理程序要短且快**。

（3）linux为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分为了两个阶段，分别是上半部和下半部：

**上半部**直接处理硬件请求，也就是硬中断，一般会暂时关闭中断请求，主要负责耗时短的工作，特点是快速执行。

**下半部**是由内核触发，也就是软中断，主要负责上半部未完成的工作，一般以内核线程的方式运行，特点是延迟执行。

**<mark>89.键盘上敲一个字母是什么中断？</mark>**

硬件中断

**<mark>90.查找一个字符串是否在文件中</mark>**

（1）**grep** string filename

（2）nl filename | **sed** -n '/string/p'

（3） **awk** '/string/ {print NR":", $0}' filename

（4）**less** filename 键入/后跟想要查找的字符串，然后按“Enter”

（5）vi同上

**<mark>91.查找一个本机端口号的状态</mark>**

netstat -anp | grep 端口号：查看当前端口的状态

netstat -anp：查看所有

**<mark>92.几十个G的文件中查找一个字符串是否存在</mark>**

使用dd加grep命令

dd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。默认从标准输入拷贝到标准输出。

 if=文件名：输入文件名，缺省为标准输入。即指定源文件。

skip=blocks：从输入文件开头跳过blocks个块后再开始复制。

ibs=bytes：一次读入bytes个字节，即指定一个块大小为bytes个字节。

 bs=bytes：同时设置读入/输出的块大小为bytes个字节。

 count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。

不设置skip，先把count设为一半文件大小的值，采用二分法查找，如果找到，则限定在了一半的范围内。然后继续查找。

```
dd if=model_20200423155728 bs=1024 skip=3600000 count=1200 | grep '4222019284714124'
```

**<mark>93.如何判断远程服务的端口有没有开启</mark>**

**方式一**：telnet命令

（1）先查看地址能否ping通

```
ping www.baidu.com
```

（2）然后使用telnet查看端口是否开放

```
telnet www.baidu.com 3306
```

如果命令行不显示任何信息说明端口处于开启状态

如果端口处于关闭状态，命令行窗口显示连接失败。

**方式二**：netcat命令

```
nc -vz www.baidu.com 443
```

**方式三**：nmap命令

```
nmap www.baidu.com
```

会显示已打开的端口

**方式四**：执行/dev/tcp检测

```
echo > /dev/tcp/www.baidu.com/443 && echo "Port is open"
```

如果远程服务器端口是开着的，则会打印“Port is open“，如果没有打开会提示”Connection refused“

**<mark>94.平时使用的Linux命令</mark>**

ls、cd、man、chmod、ps、kill、ping、mkdir、rm、mv、cp、gedit。

**<mark>95.介绍一下OSI七层协议，各层协议都有哪些</mark>**

（1）应用层：负责给应用程序提供统一的接口

常见协议有：HTTP、FTP、DNS

（2）表示层：负责把数据转换成能兼容另一个系统的格式

常见协议：LPP 轻量级会话协议

（3）会话层：负责建立、管理和终止表示层实体之间的通信会话

常见协议：LDAP 轻型目录访问协议

（4）传输层：负责端到端的数据传输

常见协议：TCP,UDP

（5）网络层：负责数据的路由、转发、分片

常见协议：IP、ICMP（用于传输出错报告控制信息）

（6）数据链路层：负责数据的封帧和差错检测，以及MAC寻址

常见协议：ARP协议

（7）物理层：负责在物理网络中传输数据帧

常见协议：Ethernet协议

**<mark>96.baidu.com默认使用什么端口</mark>**

80是http协议的默认端口，是在输入网站的时候浏览器就已经帮我们输入端口号了，所以输入www.baidu.com，其实就是访问www.baidu.com:80。

**<mark>97.三次握手</mark>**

同28

**<mark>98.为什么不是俩次</mark>**

同68

**<mark>99.如果网络情况非常好，百分百不会发生拥塞，不会重传SYN，不会有历史连接问题</mark>**

**<mark>可以两次握手吗</mark>**

在理论上，如果网络情况非常好，不存在拥塞、重传SYN或历史连接问题，那么可以考虑使用两次握手进行连接。然而，实际上，在现代网络通信中，使用两次握手建立连接是不安全的，因为它容易受到各种攻击，如类似SYN攻击，俩次握手的情况下，服务端每收到一个SYN报文，就建立一个连接，这样就会造成大量的资源浪费。

TCP协议通常使用三次握手来建立连接，这是出于安全性和稳定性的考虑。通过三次握手，可以确保双方都能够确认彼此的能力和愿望建立连接，从而减少了一些攻击的可能性。

在实际应用中，为了确保连接的安全性和可靠性，仍然建议使用三次握手来建立TCP连接。尽管网络情况可能非常好，但保持良好的安全实践是很重要的，以防止未来可能出现的网络问题或攻击。

**<mark>100.什么时候用TCP什么时候用UDP</mark>**

由于TCP是面向连接的，能保证数据的可靠性交付，因此经常用于：

（1）FTP文件传输

（2）HTTP/HTTPS

由于UDP面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此常用于：

（1）包总量较少的通信，如DNS

（2）视频，音频等多媒体通信

（3）广播通信

**<mark>101.此时的视频面试用的是UDP还是TCP</mark>**

UDP

（1）为什么使用的是UDP

因为UDP是一个无连接的协议，不用保证可靠性，速度快。

（2）如果UDP不保证可靠性，在视频面试的时候如果你回答问题的视频流丢包了，你的回答我就听不见了，那么视频面试的体验将会非常差，怎么办？

需要结合TCP和UDP的特性，让这个协议既可以保证可靠，又可以保证实时性，也就是使用RUDP，常见的RUDP协议主要有**QUIC**。

**<mark>102.UDP丢包会有什么现象</mark>**

（1）传输的数据无法到达接收端，导致接收端获取不到完整的数据包

（2）传输的数据包可能出现乱序，导致接收端无法正确重构数据

（3）传输的数据包可能被重复发送，导致接收端接收到重复的数据

（4）传输的数据包可能出现错误，导致接收端无法正确解码数据

（5）应用程序性能降低

**<mark>103.http和https的区别</mark>**

（1）HTTP协议传输的数据都是未加密的，也就是明文传输，存在安全风险的问题。HTTPS则解决HTTP不安全的缺陷，在TCP和HTTP网络层之间加入了SSL/TLS安全协议，使得报文能够加密传输。

（2）HTTP连接建立相对简单，在TCP三次握手之后就可进行HTTP的报文传输，而HTTPS在三次握手后，还需要进行SSL/TLS握手，才可进行传输

（3）两者默认的端口不一样，HTTP默认端口号是80，HTTPS是443

（4）HTTPS需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的，需要一定费用

**<mark>104.证书绿色是什么意思</mark>**

当浏览器显示网页的证书绿色时，通常表示该网页使用了SSL/TLS协议进行加密通信，并且获得了有效的数字证书。

**<mark>105.自己随便编一个证书可以吗，需要去什么地方注册</mark>**

不可以，需要去CA注册。

CA（数字证书认证机构），将服务器公钥放在由CA颁发的数字证书中，只要证书是可信的，公钥就是可信的。

**<mark>106.平常查什么网站？</mark>**

github，StackOverflow，cpp reference

**<mark>107.代码、文献、DEBUG习惯</mark>**

（1）习惯写注释，对于接口、类以及复杂的业务逻辑，添加有意义的注释。

对于接口方法的注释，主要会写详细的传入参数和返回结果说明，以及异常抛出的情况。

对于类主要写类的各个成员变量和成员函数的功能说明。

（2）把一个大的项目拆分成多个小的业务结构来写

（3）封装一些通用的模板函数，还有复杂的逻辑判断条件

（4）习惯选择合适的日志级别来打印日志信息进行DEBUG。

error：错误日志，指比较严重的错误，对正常业务有影响，需要运维配置监控的；
warn：警告日志，一般的错误，对业务影响不大，但是需要开发关注；
info：信息日志，记录排查问题的关键信息，如调用时间、出参入参等等；
debug：用于开发DEBUG的，关键逻辑里面的运行时数据；
trace：最详细的信息，一般这些信息只记录到日志文件中。
**<mark>108.proactor和reactor模式</mark>**

（1）reactor是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生后，比如可读就绪事件，就需要应用程序主动调用read方法来完成数据的读取，也就是要应用程序主动将socket连接接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。

（2）proactor是异步网络模式，感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址等信息，用来存放结果数据，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全部交给操作系统来做，并不需要像Reactor那样还需要应用进程主动发起read/write来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。

**<mark>109.epoll是同步的还是异步的</mark>**

（1）从I/O层面来看，EPOLL一定是同步的

（2）从消息处理层面来看，EPOLL是异步的

**<mark>110.从数据流的角度描述proactor模式</mark>**

同108

**<mark>111.五种IO模型</mark>**

（1）阻塞IO：调用者调用了某个函数，等待这个函数返回，期间不执行任何操作，必须等这个函数返回才能进行下一步动作

（2）非阻塞IO：每隔一段时间就去检测IO事件是否就绪，没有就绪就做其他事情。非阻塞IO执行系统调用总是立即返回，不管事件是否已经发生，若没有发生，则返回-1，此时可以根据errno区分这俩种情况，对于accept、recv和send，事件未发生时，errno通常被设置为EAGAIN

（3）信号驱动IO：用户进程发送一个sigaction系统调用后，立刻返回，并不会阻塞，当IO事件就绪后，进程收到SIGIO信号，然后执行信号处理函数。

（4）IO复用：linux用select/poll/epoll函数实现IO复用模型。这些函数也会使进程阻塞，但是和阻塞IO不同，这几个函数可以同时阻塞多个IO操作，而且可以同时对多个读操作、写操作的IO函数进行检测。

（5）异步IO：Linux中，可以调用aio_read函数让内核进行IO操作，用户进程继续往下执行，当内核将数据拷贝到缓冲区后，再通知应用程序进行数据处理。

**<mark>112.为什么不用异步来做webserver</mark>**

（1）linux下的异步IO并不成熟，比如：他只支持以指定标识（O_DIRECT）打开的文件，不支持socket句柄（文件描述符）。

（2）如果CPU的核心数较多，或线程的调度算法优秀的话，即使单核心性能一般，也有可能与异步操作的模式性能差不多

**<mark>113.如何使用同步IO模拟proactor模式</mark>**

原理：主线程执行数据读写操作，读写完成之后，通知工作线程进行处理。从工作线程的角度来看，他们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

工作流程如下：

（1）主线程往epoll内核事件表中注册socket上的读就绪事件

（2）主线程调用epoll_wait等待socket上的读就绪事件

（3）当sokcet上有数据可读时，主线程从socket上循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列

（4）睡眠在请求队列上的某个工作线程被唤醒，来处理请求，然后往epoll内核事件表中注册socket上的写就绪事件

（5）主线程调用epoll_wait等待socket可写后，循环写入数据

**<mark>114.高并发情况下的性能提升方法</mark>**

（1）语言方面：

可以利用引用和指针，来减少类的构造和析构；

在c++11标准里，引入了右值引用，move语义和forward完美转发的新特性，以及移动构造函数和移动赋值运算符。

**（右值引用补充: 左值和右值有了解过吗？**

- **左值是一个内存实体，可以&，可以存在很久**
- **右值没有内存实体，只是临时的，用一次就不用了。**

**可以用std::move将左值转换为右值**

**说下你是怎么使用右值引用的**

- **实现一个类的时候，会提供移动构造函数和移动赋值函数**
- **怎么使用：如果发现某个对象需要赋值给一个新对象而且之前老对象不会不用了，就用std::move将左值转换为右值）**

可以利用语言提供的原子特性，部分的代替锁来进行互斥。如static在局部变量使用时初次定义就要初始化，且只能初始化一次，重复调用同一函数，第二次调用时不会执行static局部变量初始化的那句话。

（2）IO方面：

使用更优的拥塞控制算法，如谷歌的BBR算法；

修改TCP选项？

（3）减少内存拷贝；

使用条件变量减少频繁的轮询；

尽量减小互斥锁的代码范围，范围越大，竞争条件在时间维度就越激烈

（4）使用零拷贝技术

使用场景：

a.网络数据传输：在网络编程中，零拷贝技术可以显著提高数据传输性能。通过避免将数据从应用程序缓冲区复制到内核缓冲区，然后再复制到网络套接字，可以减少数据在内存中的复制次数，降低CPU和内存带宽的开销。这对于高性能网络应用程序、数据中心通信和大规模分布式系统非常有用。

b.文件系统操作：在处理文件系统操作时，零拷贝技术可以提供更高的效率。例如，在读取大文件时，使用内存映射（Memory Mapping）技术可以将文件内容直接映射到应用程序的内存空间，避免了数据从磁盘到内核缓冲区再到应用程序缓冲区的拷贝操作。

c.数据库和存储系统：零拷贝技术对于处理大量数据的数据库和存储系统非常有用。通过避免数据在内存和磁盘之间的复制，可以提高读取和写入操作的性能。此外，零拷贝还可以在数据库之间进行数据传输时减少数据的复制，提高数据迁移和备份的效率。

d.多媒体处理：在处理音视频数据时，零拷贝技术可以提供更好的性能和低延迟。例如，通过使用适当的API和硬件加速功能，可以将音频或视频数据直接传输到音频设备或显示器，而无需额外的数据拷贝操作。

e.并发编程：在多线程或并发编程中，零拷贝技术可以减少线程间的数据共享和同步开销。通过使用共享内存或无锁数据结构，不同的线程可以直接访问数据，而无需复制或传递数据。

**<mark>115.linux如何切换目录，查看端口绑定情况，查看CPU利用率</mark>**

cd

netstat -tunlp | grep 8089  其中8089为被占用的端口号

vmstat -n 1 一秒刷新一次

**<mark>116.什么是qps和tps，如何计算</mark>**

（1）QPS即每秒查询率，指一台服务器每秒能响应的查询次数，用于衡量特定的查询服务器在规定时间内所处理流量的多少，是主要针对专门用于查询的服务器的性能指标。

QPS = 1s/单个请求耗时 * 服务器核心数（线程数）

（2）TPS是每秒事务数，一个事务是指客户端向服务器发送请求然后服务器做出反应的过程。

TPS = 事务的数量 / 执行总时间

**<mark>117.线程池和任务队列有没有做分离</mark>**

有。线程池分为了线程集合和任务队列俩部分，把线程和任务分离，提升了线程的重用性。

线程池从任务队列提取任务，到一个线程中去执行，有任务就提取执行，没有任务则阻塞线程休眠。

**<mark>118.线程池中怎么利用信号量机制</mark>**

线程池中的线程通过run方法从任务队列中提取任务，初始化时，由于信号量值为0，所以线程池中的线程是阻塞的，当主线程读取完数据后，将数据放到缓冲区，然后调用线程池的append方法，append方法将该任务插入任务队列中，并调用post做一次v操作，使信号量+1。此时线程池中的某个线程的wait就不再阻塞，做一次P操作，使得信号量-1，然后从任务队列中取出任务执行

**<mark>119.CPU利用率拉满的时候在线程池中增加线程是否能提高qps</mark>**

不能。应该会导致qps降低。

不断增加线程数，请求就会变多，随之而来的就是大量的上下文切换、锁征用等，这些串行化的因素会大大增加CPU时间。根据阿姆达尔公式：

加速比 = 1 / （F + 1/n(1 - F)）

其中F是系统的串行化比例，n是线程数。由此可见，为了提高系统的速度，仅增加线程的数量并不一定能起到有效的作用，需要从根本上修改程序的串行行为，提高系统内可并行化的模块比重，在此基础上，合理增加线程数，才能获得最大的加速比。

**<mark>120.如何根据CPU利用率动态设计，优化线程池</mark>**

（1）如果CPU利用率过高是因为线程池中的任务过多或任务处理时间过长，那么增大线程池中的线程数量可以解决问题。但是，如果CPU利用率过高是因为线程池中的某些线程在等待IO操作完成或者其他原因导致了线程挂起，那么增大线程池中的线程数量可能并不会解决问题，甚至会加剧问题。在这种情况下，需要进一步分析问题的根本原因，并采取适当的措施来解决问题。

（2）线程池不仅仅包括线程，还有任务队列，因为任务队列可以缩短任务等待执行的时间。如果线程池中的线程数已经足够，我们可以考虑增加任务队列的大小，以便更多的任务可以等待执行。

**<mark>121.http解析主从状态机</mark>**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBH2ZO50WrURwTiaNKTH7tCia3AR4WeKu2EEzSgKibXzG4oa4WaPfGutwBqCJtemia3rc5V1wupvOLFjzQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**<mark>122.http状态码</mark>**

同3

**<mark>123.动态链接库静态链接库特点、区别</mark>**

静态链接：

空间浪费：每个可执行文件对所有需要的目标文件都要有一份副本

更新速度：每当库函数代码修改了，需要重新编译链接形成可执行程序

运行效率：因为在可执行程序中已经具备了所有执行程序所需要的东西，在执行的时候运行速度快。

动态链接：

空间少：多个程序在执行时共享同一份副本。

更新速度快：只需要替换原来的目标文件，不需要重新编译链接。

性能损耗大：因为把链接推迟到了运行时。

**<mark>124.进程线程区别、通信方式</mark>**

区别同32

进程通信同87

线程通信方式：信号、锁、条件变量、信号量

（1）进程间的通信需要借助操作系统

（2）线程间可以直接读写进程数据段（如全局变量）来进行通信

**<mark>125.static修饰局部变量</mark>**

static修饰局部变量改变了它的生命周期，让静态局部变量在出了作用域后仍然存在，到程序结束，生命周期才结束。

**<mark>126.static修饰全局变量</mark>**

一个全局变量被static修饰，则使得这个全局变量只能在本源文件中使用，不能在其他源文件使用

**<mark>127.如何使用类中的static成员函数</mark>**

static修饰的类成员函数，也被所有的类对象所共享，不属于某个具体的实例。没有this指针，不能访问任何非静态成员。使用作用域修饰符来使用, 对象也可以调用

**<mark>128.面向对象的三大特性</mark>**

同41

**<mark>129.虚函数表在什么时候创建、存在什么位置</mark>**

虚函数表在编译期间创建。

位于只读数据段（.rodata），即c++内存模型中的常量区。

**<mark>130.虚函数存在于什么位置</mark>**

虚函数存在于代码段（.text），即c++内存模型中的代码区

**<mark>131.虚函数指针在什么时候创建</mark>**

vptr跟着对象走，所以对象什么时候创建，vptr就什么时候创建出来，所以是在程序运行时创建。

当程序在编译期间，编译器会为构造函数中增加为vptr赋值的代码，当程序在运行时，遇到创建对象的代码，执行对象的构造函数，那么这个构造函数里就有为这个对象的vptr赋值的语句。

**<mark>132.虚函数为什么能实现多态</mark>**

（1）编译器会自动为每个含有虚函数的类生成一份虚表，该表是一个一维数组，虚表里保存了虚函数的入口地址

（2）编译器会在每个对象的前四个字节中保存一个虚表指针，即vptr， 指向对象所属类的虚表。在构造时，根据对象的类型去初始化虚表指针vptr，从而让vptr指向正确的虚表，从而在调用虚函数时，能找到正确的函数

（3）当派生类对基类的虚函数没有重写时，派生类的虚表指针指向的是基类的虚表；当派生类对基类的虚函数重写时，派生类的虚表指针指向的是自身的虚表；当派生类中有自己的虚函数时，在自己的虚表中将此虚函数地址添加在后面

这样当有一个基类指针指向派生类时，就可以根据派生类对虚函数的重写情况动态的进行调用，从而实现多态。

**<mark>133.函数调用过程中堆栈的变化情况</mark>**

（1）首先是把函数的返回地址、参数从右到左依次压入栈中

（2）然后将当前函数的栈帧压入栈中。栈帧包括临时变量、函数的返回值等信息。

（3）之后跳转到函数的入口点开始执行函数代码

（4）函数执行完毕后，将返回值存放在寄存器中，然后将栈帧弹出，恢复返回地址，跳转回调用点。

**<mark>134.什么是内存泄露、如何防止</mark>**

（1）内存泄漏是指由于疏忽或错误造成程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制。

（2）如何防止：同21

（1）使用智能指针

（2）如果类中有指针成员变量，需要手动重写拷贝构造函数以及重载赋值运算符

（3）在拷贝构造函数和析构函数中成对的调用new和delete

（4）如果有派生类，需要把基类的析构函数定义为虚函数

**<mark>135.什么是RAII、为什么智能指针可以防止内存泄漏</mark>**

RAII全称是Resource Acquisition is Initialization ，即“资源获取即初始化”，也就是说在构造函数中申请分配资源，在析构函数中释放资源。

智能指针就是一个类，类在超出作用域范围的时候会自动调用类的析构函数，从而实现自动释放资源的功能

**<mark>136.看过智能指针的源码？讲一下shared_ptr的内部结构</mark>**

shared_ptr和weak_ptr都继承于同一个基类_Ptr_base,基类里面有原始指针*_Ptr和计数类指针*_Rep。

计数类_Ref_count_base是一个虚基类，有两个纯虚函数和强弱指针的引用计数。他有一个派生类_Ref_count, 这才是真正的引用计数器对象，有一个数据成员 _Ptr，就是原始指针。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-05-04-16-04-53-image.png)

![](C:\Users\win\AppData\Roaming\marktext\images\2023-05-04-16-05-07-image.png)

shared_ptr是一个智能指针，它包含两个部分：指向内存的指针和引用计数。指向内存的指针指向被共享的对象，引用计数表示目前共享该对象的智能指针数量。

在shared_ptr内部，还包含一个控制块（_Ref_count），控制块包含了引用计数、删除器和其他管理共享资源的信息。每个shared_ptr对象都共享一个控制块，通过操作控制块，可以对所有指向同一个对象的shared_ptr进行引用计数和资源释放的管理。 

一般情况下，shared_ptr的控制块是在堆上分配的，而指向内存的指针是指向堆上分配的对象的。当最后一个shared_ptr指针被销毁时，控制块会负责释放堆上的资源。

**总结**：shared_ptr多个指针指向相同的对象。shared_ptr使用引用计数，每一个shared_ptr的拷贝都指向相同的内存。每使用他一次，内部的引用计数加1，每析构一次，内部的引用计数减1，减为0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。

shared_ptr的一个最大的陷阱是循环引用，循环引用会导致堆内存无法正确释放，导致内存泄漏，可以通过 weak_ptr 来解决这个问题。

**<mark>137.如果传给shared_ptr一个引用，那么引用计数会不会+1</mark>**

不会

**<mark>138.宏定义，有无类型检查，在什么阶段生效</mark>**

没有类型检查，在预处理阶段会展开宏定义

**<mark>139.讲一下ARP协议的原理和作用？</mark>**

在传输一个IP数据包时，确定了源IP地址和目标IP地址后，就会通过主机【路由表】来确定IP数据包的下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道【下一跳】的MAC地址。

由于主机的路由表可以找到下一跳的IP地址，所以可以通过ARP协议，获得下一跳的MAC地址。

**作用**：根据IP地址获取MAC地址

**原理**：ARP是借助**ARP请求与ARP响应**两种类型的包确定MAC地址的。

![ARP 广播](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/34.jpg)

（1）首先主机会通过广播发送ARP请求，这个包中包含了想要知道的MAC地址的主机IP地址

（2）当同个链路中的所有设备收到ARP请求时，会去拆开ARP请求包里的内容，如果ARP请求包中目标IP地址与自己的IP地址一致，那么这个设备就会将自己的MAC地址塞入**ARP响应包**返回给主机。

操作系统通常会把第一次通过ARP获取的MAC地址缓存起来，以便下次直接从缓存中找到对应IP地址的MAC地址。

不过，MAC地址的缓存是有一定期限的，超过这个期限，缓存的内容就会被清除

**<mark>140.在哪里会用到ARP协议？</mark>**

（1）局域网内的主机通信：当一台主机需要与同一局域网内的另一台主机进行通信时，它需要知道目标主机的MAC地址。ARP协议通过广播一个ARP请求（ARP Request）消息来询问局域网内的其他主机，以获取目标主机的MAC地址。然后，目标主机通过ARP响应（ARP Reply）消息回复包含其MAC地址的响应，从而完成地址解析过程。

（2）路由器的转发决策：当路由器接收到一个IP数据包时，它需要确定数据包的下一跳目标。在这种情况下，路由器可能需要使用ARP协议来解析下一跳目标的MAC地址。它会发送一个ARP请求消息来获取下一跳目标的MAC地址，并将数据包转发到正确的目标地址。

**<mark>141.如果获取不到MAC地址会发生什么</mark>**

会再次发送ARP请求，请求的重发次数是由操作系统决定的，通常是3到5次。如果多次发送没有获取到MAC地址，就会返回一个ICMP包用来通知出错原因。

**<mark>142.TCP和UDP区别</mark>**

（1）TCP是面向连接的，UDP是无连接的

（2）TCP提供可靠的服务，UDP则是尽最大努力交付，但不保证可靠

（3）TCP是面向字节流的，UDP是面向报文的

（4）UDP没有拥塞控制，因此网络出现拥塞时不会使源主机的发送速率降低（对实时应用很有用，如视频会议等）

（5）每一条TCP连接只能是点到点的；而UDP支持一对一，一对多，多对一和多对多的交互通信

（6）TCP首部开销较大，需要20个字节；UDP只需要8字节

**<mark>143.对socket的了解</mark>**

socket主要用来实现跨网络与不同主机上的进程之间通信。

socket是在应用层和传输层之间的一个抽象层，他把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用以实现进程在网络中通信。

在linux中，可以通过socket函数来打开一个网络文件，返回值是一个文件描述符，然后就可以使用普通的文件操作函数来传输数据

**<mark>144.宏定义</mark>**

宏定义是一种预处理指令，有俩种用法，含参或不含参，含参类似于函数，不含参数则主要用于将某个符号或字符串定义为一个宏，以便在程序中使用。用#define来定义。

优点：能简化代码的编写和修改，加快运行的效率

缺点：容易出现未知的错误，因为宏定义没有类型检查和作用域限制。

**<mark>145.宏定义和const的区别</mark>**

（1）编译阶段不同：define是在编译的预处理阶段起作用，const是在编译和运行的时候起作用

（2）define只做替换，不做类型检查和计算，也不求解，容易产生错误；

const常量有数据类型，编译器可以对其进行类型安全检查

（3）在运行的时候，define只是将宏名称进行替换，在内存中会产生多份相同的备份，const在程序运行中只有一份备份

（4）宏定义的数据没有分配内存空间，只是插入替换掉；const定义的变量只是值不能改变，但要分配内存空间

**<mark>146.typedef的作用</mark>**

（1）定义一种类型易于记忆的别名，而不只是简单的宏替换，可以用来声明多个指针对象。

```
char* pa, pb;//只有pa定义为了char指针类型，pb为char类型

typedef char* PCHAR;
PCHAR pa, pb;  //两个都为char指针类型
```

（2）以前的代码，在声明struct新对象时，必须带上struct，使用typedef可以在定义结构体的时候定义一个别名，声明新对象时就不需要再带上struct

```
typedef struct tagPOINT{  
    int x;  
    int y;  
}POINT;  
POINT p1; // 这样就比原来的方式少写了一个struct，比较省事，尤其在大量使用的时候  
```

（3）用来定义与平台无关的类型

```
typedef long double REAL; //在一目标平台上，让它表示最高精度的类型为：
typedef double REAL;      //在不支持 long double 的平台二上，改为：
typedef float REAL;       //在连 double 都不支持的平台三上，改为：
```

（4）可以为复杂的声明定义一个新的简单的别名

```
//原声明：int *(*a[5])(int, char*);
//变量名为a，直接用一个新别名pFun替换a就可以了：
typedef int *(*pFun)(int, char*); 
//原声明的最简化版：
pFun a[5];
```

**<mark>147.在c++中最常用的数据结构</mark>**

vector，string，queue，unordered_map

**<mark>148.vector的缺点</mark>**

（1）插入删除效率低，在头部进行插入删除时需要移动整个数组

（2）当动态添加的数据超过vector默认分配的大小时，要进行整体的重新分配、拷贝与释放

（3）访问元素时没有边界检查

（4）不支持多维数组，需要通过嵌套vector来表示

**<mark>149.sort排序的底层实现</mark>**

快排时间复杂度为O(nlogn)

底层是根据传入数组的大小来判断使用的排序方式。

（1）如果长度小于40，直接使用插入排序，否则进入快排

（2）但如果快排的递归层数过多可能会导致栈溢出，因此sort限制递归层数为1.5logN，如果超过了层数限制就使用堆排序

（3）sort快排还对基准值进行了优化，它将每一段排序的数组分成了8段，9个位置，每三个位置进行一次冒泡排序，再对这三组的中间值进行一次冒泡，最后得到一个中间值作为基准值

**为什么sort选择快排？**

因为默认需要排序的数组的分布是比较随机的那种分布，然后快排在比较随机的分布上，表现的比较好，速度比较快

**<mark>150.野指针</mark>**

```
int main(void) { 

    int* p;     // 未初始化
    std::cout<< *p << std::endl; // 未初始化就被使用

    return 0;
}
```

指的是没有被初始化过的指针。

为了防止出错，对于指针初始化应该要赋值为NULL

**<mark>151.悬空指针</mark>**

```
int main(void) { 
  int * p = nullptr;
  int* p2 = new int;

  p = p2;

  delete p2;
}
```

指针最初指向的内存已经被释放了的一种指针

**<mark>152.如果使用已经被释放的内存是否会出现错误？可能会出现什么错误？</mark>**

会，应该在释放完内存之后将指针设置为NULL，以避免使用已经被释放的内存。

可能出现的错误：

（1）程序崩溃：如果使用已经释放的内存，还进行写操作，会导致程序崩溃

（2）数据损坏：可能会覆盖其他重要内存

（3）安全漏洞

**<mark>153.为什么用reactor</mark>**

（1）高性能：reactor使用了事件驱动，异步非阻塞的特性，可以高效的处理大量的客户端请求，提高系统的并发能力

（2）可扩展性：reactor可以灵活的通过增加reactor实例的个数来充分利用CPU资源

（3）灵活性：可以根据应用需求来配置线程数量，可以适应不同的负载，并保证高性能

（4）可维护性：使用reactor模式可以将业务逻辑与IO操作分离，这样有利于对系统进行维护和升级

（5）数据处理简单：数据处理基于事件的方式完成，可以处理大量的数据，避免了阻塞和死锁的问题

**<mark>154.reactor解决了什么实际问题</mark>**

reactor模式的核心是解决了多请求问题，如果有特别多的请求同时发生，reactor模式不会因为线程池被短时间占满而拒绝服务。一般实现多请求的模块，会使用线程池的实现方案，但如果瞬间有大量并发，则会一下子消耗所有线程，整个服务就陷入阻塞，后续请求将无法接入。

reactor模式则会有一个分发者对象先接收事件，然后再快速的分发给对应连接的处理对象进行处理，这样就不会阻塞请求的接收

**<mark>155.假设线程池有100个线程，但有1000个用户同时使用，reactor的具体表现</mark>**

reactor的核心思想就是使用少量的线程来处理大量的并发请求，通过事件循环（event loop）和非阻塞 I/O 操作来实现高效的处理。

在这种情况下， Reactor 模式使用单个线程作为事件循环线程（Event Loop Thread），该线程负责处理所有的事件调度和 I/O 操作。这个线程负责监听所有的输入事件，并调用相应的处理函数进行处理。

当有新的事件到达时，事件循环线程会将事件分发给线程池中的空闲线程进行处理。每个线程负责处理自己分配到的事件。处理完成后，将结果返回给事件循环线程，由事件循环线程进行后续的回调处理或响应给用户。

通过这种方式，使用较少的线程来处理大量的并发请求，能够充分利用系统资源，提高系统的吞吐量和响应性能。同时，采用非阻塞的 I/O 操作可以避免线程在等待 I/O 完成时的阻塞，进一步提高系统的并发能力和资源利用率。

**<mark>156.IO多路复用的流程和原理</mark>**

流程：

（1）创建socket文件描述符，并将需要监听的IO事件添加到事件集合中（如select集合）

（2）调用IO多路复用函数，将所有待处理事件的集合传递给函数

（3）IO多路复用函数会等待并监听所有传递的事件集合中的IO事件，并自动挂起当前进程，直到有事件发生或超时

（4）当某个IO事件触发时，IO多路复用函数会返回该事件的文件描述符，并从事件集合中删除该事件

（5）处理完该事件后，将该事件重新加入到事件集合中

（6）循环上面的2到5步，直到IO操作都完成

原理：

利用操作系统提供的事件通知机制，将多个IO事件添加到一个事件集合中进行监听。当事件发生时，操作系统会通知正在等待的进程，进程就可以及时处理该事件。

**<mark>157.有没有考虑程序崩溃场景，项目程序崩溃了怎么办</mark>**

（1）加入了异常捕获机制，以防止出现程序崩溃的情况

（2）加入日志系统，来监控系统运行情况，以便于追踪问题的根源

（3）开发完成后，使用webbench进行了测试和验证，以确保程序的稳定性和安全性

**<mark>158.项目具体应用场景，为什么做这个项目</mark>**

**应用场景**：

（1）目前实现的主要是提供web服务，将静态的页面通过http协议呈现给用户，可以提供给上万个客户端同时访问

（2）后续完善可以实现文件的传输和下载，以及在线视频和音频等内容的传播。

**为什么做这个项目**：

实验室的项目偏向于机器视觉，感觉自身对于后台开发的知识有点薄弱，而Webserver项目涉及到很多基础的网络知识和编程技术，通过做这个项目能够提高自己的技术和理论水平。并且可以通过实践搭建Web服务器，能够深入了解Web服务器的工作原理和机制。

**<mark>159.为什么裸写socket编程而不是使用一些成熟的协议</mark>**

成熟协议：ISAPI, CGI，WinInet，Winsock

（1）主要是因为裸写socket编程可以更好地理解和掌握网络通信原理，从而更好的应对一些特殊的需求或问题。

（2）利用成熟的协议可以简化开发和部署的工作量，并且减少出现问题的可能性，但是有些时候我们会需要更加细节的控制，例如需要进行网络延迟测试，此时裸写socket编程就可以实现更好的优化。

补充：裸写socket可以实现网络延迟测试是因为它可以直接控制底层的网络数据传输过程，包括对数据包的发送时间、延迟、丢失等进行细粒度的控制。而成熟的协议涉及到许多层次的网络协议，其控制的粒度更为宏观，无法对底层数据进行如此细节的控制

<mark>**160.项目中遇到的印象深刻的问题**</mark>

（1）使用优先级队列来优化定时器的时候，最先想到的就是直接使用STL库自带的priority_queue来实现就可以了。但写到调整定时器adjust_timer操作的时候，发现需要修改priority_queue中保存的定时器指针内部的expire_time的值。但是直接修改priority_queue内部的值后，不会进行自动排序，所以不能直接对其保存的指针内部的值进行修改。后来参考了别人的写法，选择使用vector数组来重新实现一个小顶堆，通过unordered_map来保存定时器的下标。当需要调整指定的定时器的时候，先通过哈希表找到定时器在vector中的位置，然后修改内部的值后，再通过下沉的操作把它移动到合适的位置。

（2）线程池初始化时，通过pthread_create生成线程的时候，工作线程运行的函数一定要声明为static。因为pthread_create函数的第三个参数为函数指针，指向工作线程运行的函数，他要求线程处理函数的参数类型为void*，如果线程函数为类成员函数，那么this指针会作为默认的参数传进函数中，this指针的类型为线程池类的类型，从而和void*不匹配，不能通过编译。改成static成员函数，就不会有this指针

**<mark>161.TCP如何保证可靠传输</mark>**

（1）确认和重传：接收方收到报文就会进行确认，并返回一个确认应答消息，发送方发送一段时间后没有收到确认应答消息就会进行重传

（2）数据校验：TCP报文头有校验和，用于校验报文是否损坏

（3）数据合理分片和排序：TCP会按最大传输单元（MTU）合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层

（4）流量控制：当接收方来不及处理发送方的数据时，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失

（5）拥塞控制：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失

**<mark>162.使用TCP编程时，如果服务端程序崩溃了，那么客户端会出现什么情况</mark>**

（1）如果是服务端的进程崩溃了，那么内核会发送FIN报文，与客户端进行四次挥手断开连接

（2）如果服务端主机宕机，那么就不会发生四次挥手：

    （a）如果客户端会发送数据：

由于服务端已经不存在了，所以客户端会进行超时重传，超过一定时间后，会断开TCP连接；

   （b）如果客户端一直不会发送数据：

如果开启了TCP Keepalive机制，则在一段时间没有进行数据交互后，客户端会发送探测报文，达到一定次数没收到响应后，就会断开连接；

如果没有开启，则TCP连接会一直存在

<mark>**163.服务器关机时，一定要等到客户端触发TCP的keepalive后客户端才会关闭吗，有什**么</mark>**<mark>优化方法吗</mark>**

可以在客户端实现心跳机制，自己设定一个时间来发送心跳包，当服务器关机后，心跳包无法收到响应，就可以选择关闭连接

**<mark>164.线程之间共享全局变量如何协调</mark>**

（1）锁机制：通过互斥锁、信号量等线程同步机制来保证共享变量在同一时间只能被一个线程访问，避免多个线程同时读写同一块内存

（2）原子操作：使用atomic关键字，让多个线程对共享变量的读写操作都是原子性的

（3）使用条件变量，让线程在一定条件下等待或唤醒，从而实现线程之间的同步

**<mark>165.为什么使用条件变量时总会使用互斥锁</mark>**

为了保证wait操作的原子性。如果一个线程调用了pthread_cond_wait()函数，但此时还没进入wait状态，另一个线程就调用了pthread_cond_singal()，就会导致此次唤醒丢失。而加了锁的情况下，第二个线程必须等到第一个线程的pthread_cond_wait()释放锁进入wait状态后，才能调用pthread_cond_singal()

**<mark>166.对于大一点的项目如何快速找出泄漏的代码</mark>**

（1）可以利用valgrind的memcheck工具，来检测程序运行短时间内出现的内存泄漏

（2）利用valgrind的massif工具，来检测程序运行长时间内的内存泄漏

（3）用cppcheck来检测一些我们可能忽略的代码错误

**<mark>167.c++和python有什么区别</mark>**

（1）c++是一种编译型语言，需要将代码编译成可执行文件才能运行；

python是一种解释型语言，可以直接运行脚本

（2）c++是一种静态类型语言，需要在编译时指定变量的数据类型；

python是一种动态类型的语言，可以在运行时解析变量类型

（3）c++可以直接操作内存，效率高；python具有很高的开发效率，但性能较低

**<mark>168.调用new之后底层会做什么</mark>**

new会调用自定义类型的构造函数来初始化对象，并调用一个全局函数operator new。

operator new是对malloc的封装，实际还是通过malloc来申请空间，申请成功则直接返回，失败则会执行用户设置的应对措施，如果没有设置则抛出异常

**<mark>169.操作系统如何分配内存，在哪里分配内存</mark>**

（1）当一个进程启动时，操作系统会为该进程分配一部分内存。这部分内存被分为更小的单元，称为页面

（2）操作系统会在页表中维护所有的可用页面

（3）当进程请求内存时，操作系统会检查页表以查看是否有可用的页面：

如果有，就把该页面分配给进程；如果没有，就使用页面置换算法来淘汰某页面腾出空间

在哪里分配内存：分配给进程的是虚拟内存

**<mark>170.归还内存时操作系统会做什么</mark>**

操作系统会将该内存区域的页面标记为空闲，移入空闲页面列表，以便其他程序可以使用这些页面

**<mark>171.内存碎片怎么处理</mark>**

内存碎片分为：

（1）内部碎片：就是已经分配出去，却不能被利用的内存空间

（2）外部碎片：指的是还没有被分配出去，但由于太小了无法分配给申请内存空间的新进程的内存空闲区域

采用分段式分配内存，按需分配可以避免内部碎片

对于外部碎片通过紧凑技术消除，也就是内存交换, 并在回收内存的时候要尽可能地将相邻的空间合并

比如有1G的物理内存，用户执行了多个程序，分别占用512MB，128MB, 256MB，这时候如果关闭128MB的程序，则此时空闲内存还有256MB，如果这个256MB不是连续的，被分成了俩段128MB内存，就会导致没有空间再打开一个200MB的程序。

可以把256MB程序占用的内存写到硬盘上，然后再从硬盘上读回来到内存里。不过在读回来的时候，我们不能装载回原来的位置，而是要紧跟再那已经被占用的512MB内存后面，这样就能空出连续的256MB内存。

**<mark>172.c++有什么情况会导致宕机</mark>**

（1）内存泄漏：如果程序分配了内存但没有正确释放，重复执行这种操作可能导致内存泄漏。当内存资源耗尽时，程序可能会崩溃。

（2）数组越界访问：当访问数组时，如果访问了超出数组边界的元素，即访问了未分配给数组的内存，可能会导致程序崩溃。数组越界是一种常见的编程错误，需要小心处理。

（3）野指针：使用未初始化的指针（野指针）进行访问操作会导致不可预测的行为，可能导致程序崩溃。

（4）空指针访问：当使用空指针（未初始化或已释放的指针）进行访问操作（如解引用、访问成员变量或调用成员函数）时，会导致程序崩溃。空指针访问是一种常见的编程错误，需要避免。

（5）栈溢出：无限递归

（6）未处理异常：当异常被抛出但未被捕获和处理时，程序会终止并抛出异常信息。如果异常没有被适当地处理，程序可能会崩溃。

**<mark>173.数组越界为什么会导致宕机</mark>**

因为数组在内存中是连续存储的，当访问一个数组元素时，会根据数组的起始地址和下标计算出该元素的内存地址，如果下标越界了，就会访问无效的内存地址，破坏了内存的安全性

**<mark>174.迷宫寻路算法，如果迷宫有环怎么办</mark>**

BFS,DFS, Dijkstra，A*

如果有环：不能只是简单地将走过的路径标记为2，然后通过判断当前点是不是2来决定能不能落脚，可以将入口点标记为2，每走一步加一，然后通过上一个点pre和当前点cur的值来判断能不能落脚

[(157条消息) 数据结构---复杂迷宫求解（多路径带环）_数据结构图求多个路径的方法_y6_xiamo的博客-CSDN博客](https://blog.csdn.net/y6_xiamo/article/details/80102163)

**<mark>175.客户端输入名字的前部分，如有玩家ABC，当客户端输入A时，会有下拉框提示ABC</mark>**，**<mark>问数据结构和算法设计</mark>**

数据结构：字典树

算法设计：

（**1**）初始化：一棵空的字典树仅包含一个根节点，该节点的字符指针为空

（**2**）插入：当需要插入一个字符串S时，首先让一个指针P指向根节点，然后依次扫描字符串S中的每个字符c：

（a）如果P的子节点中没有c这个节点，则创建一个c节点，然后将P移动到节点c

（b）如果有c这个节点，则直接让P节点移动到c

重复上述操作，直到字符串S扫描完毕，在当前节点P上标记一下字符串末尾

（**3**）检索：检索和插入类似，假设我们需要检索一个字符串s，首先让一个指针P指向根节点，然后依次扫描S中的每个字符c：

（a）如果P的子节点中没有c这个节点，则字符串不存在，结束检索

（b）如果有c这个节点，则直接让P节点移动到c，继续检索

重复上述操作，当S中的字符扫描完毕时，若当前p有被标记为字符串末尾，则说明S存在，否则不存在

**<mark>176.文件读写流程（问磁盘到内存的那些步骤）</mark>**

**读文件**：

（1）应用程序通过调用open函数打开要读取或写入的文件。

（2）然后调用函数read函数进行读取

（3）内核通过检查进程的文件描述符定位到虚拟文件系统的已打开文件列表表项

（4）read()函数则通过文件表项链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的inode模块

（5）在inode模块中，通过文件内容偏移量计算出要读取的页，并可以找到文件对应的address_space

（6）在 address_space中访问该文件的页缓存树，查找对应的页缓存节点：

如果页缓存命中，那么直接返回文件内容；

如果页缓存缺失，那么产生一个缺页异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页，然后重新查找页缓存，返回文件内容

**写文件**：

前5步和读文件一致

（6）如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去

（7）如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过 inode找到文件该页的磁盘地址，读取相应的页填充该缓存页，此时缓存页命中，执行第6步

（8）一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块，有两种方式可以把脏页写回磁盘：

（a）手动调用sync() 或fsync()系统调用把脏页写回

（b）pdflush进程会定时把脏页写回到磁盘

同时需要注意的是，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放

![](https://i0.hdslb.com/bfs/article/f3b8ae4ba0e53ea8f08ce792909120ac632c8fe1.jpg@903w_735h_progressive.webp)

https://www.bilibili.com/read/cv15988841/

**<mark>177.七层，五层，四层网络结构</mark>**

七层：OSI网络模型

应用层；表示层；会话层；传输层；网络层；数据链路层；物理层

五层：TCP/IP模型

应用层；传输层；网络层；数据链路层；物理层

四层：TCP/IP模型

应用层；传输层；网络层；网络接口层

**<mark>178.内存分配方式，如何让类中数据只保存在栈（堆）中</mark>**

**内存分配方式**：

（1） 从静态/全局存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。

（2） 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

（3） 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意大小的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

**如何让类中数据只保存在栈（堆）中**：等同于---->如何限制一个类对象只在堆（栈）上分配空间。

（1）如何限制一个类只在堆上分配空间：

将析构函数设置为私有，写一个公有的destroy函数释放内存。

如果这个类要作为基类使用，可以将析构函数设置为protected。

限制一个类对象只在堆上分配空间，即这个对象只可以new出来，却不可以直接声明出来。我们都知道在new的时候其实执行是分两个步骤，首先是调用operator new()函数，在堆中申请类大小的内存，其次就是调用类的构造函数。如果我们简单粗暴地将构造函数设置为私有成员，我们在无法直接声明对象的同时也无法通过new来创建对象，故这种方法不可以。

当对象建立在栈上面，是由编译器分配内存空间，调用类的构造函数的，当对象“生命”结束的时候，也是由编译器来进行资源回收，调用类的析构函数。也就是说这个对象的整个生命周期都是编译器掌握的。那么如果编译器无法调用析构函数会发生什么情况呢？我们创建一个类，并将类析构函数权限设置为私有，在程序中直接声明一个对象看看结果如何。

```
class A
{
private:
    ~A(){}
};
int main()
{
    A a;//无法通过编译
    return 0;
}
```

如上面代码所示，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性，其实不光是析构函数，只要是非静态的函数，编译器都会进行检查。如果类的析构函数是私有的，则编译器不会在栈空间上为类对象分配内存。因此，将析构函数设为私有，类对象就无法建立在栈上了。
由于我们的析构函数被我们设置成了私有，当我们需要销毁我们new出来的对象的时候，就无法直接使用delete。故我们需要在类中完成一个公有的destory方法，让我们在new之后可以调用destory函数释放内存，避免造成内存泄漏

```
class A
{
public:
    destory()
    {
        delete this;
    }
private:
    ~A(){}
};
```

（2）只在栈上分配空间：

在类中写出new和delete的重载函数，并将其设置为私有即可

```
class A()
{
public:
    A(){}
    ~A(){}
private:
    void* operator new(size_t t){}
    void  operator delete(void* ptr){}
};
```

**<mark>179.线程间通信方式</mark>**

全局变量

信号：类似进程间的信号处理

锁机制：互斥锁、读写锁和自旋锁

条件变量：使用通知的方式解锁，与互斥锁配合使用

信号量：包括无名线程信号量和命名线程信号量

**<mark>180.粘包的解决方法</mark>**

粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种解决粘包的方式：

- **固定长度的消息**：这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
  
  但是这种方式灵活性不高，实际中很少用。

- **特殊字符作为边界**：我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就认为已经读完一个完整的消息。
  
  HTTP 是一个非常好的例子。HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
  
  **但有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。**

- **自定义消息结构**：我们可以自定义一个消息结构，由包头和数据组成，其中包头是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整的用户消息来处理了。

**<mark>181.TCP，UDP分别在微信的哪个功能上使用比较多</mark>**

TCP协议更多应用于微信聊天、文件传输等功能，UDP协议更多用于语音、视频通话等实时通讯功能

**<mark>182.TIME_WAIT的作用（两个）</mark>**

（1）防止历史连接中的数据，被后面相同四元组的连接错误的接收：

因为序列号和初始序列号都不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据。

因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的**

（2）保证「被动关闭连接」的一方，能被正确的关闭

如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。

假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。

服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。

为了防止这种情况出现，客户端必须等待足够长的时间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间

客户端在收到服务端重传的 FIN 报文时，TIME_WAIT 状态的等待时间，会重置回 2MSL。

**<mark>183.拥塞控制算法</mark>**

拥塞控制的目的是为了**避免发送方的数据填满整个网络**。

为了在发送方调节所要发送数据的量，定义了一个叫做拥塞窗口的概念。

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化**

四大算法：

（1）**慢启动**：TCP连接刚建立时，一点一点进行提速，试探网络的承受能力。

（a）连接建立好的开始先初始化拥塞窗口大小为1，表示可以传一个MSS大小的数据

（b）每当收到一个ACK，拥塞窗口大小就会加一

（c）每当过了一个往返延迟时间RTT，拥塞窗口大小就会翻倍，呈指数上升

（d）慢启动算法受到慢启动门限的限制，有一个上限，小于这个上限时，使用慢启动算法，大于等于这个上限时，就会使用拥塞避免算法

（2）**拥塞避免算法**：

（a）每收到一个ACK，拥塞窗口大小 += 1 / 拥塞窗口大小

（b）每当过一个往返时间，拥塞窗口大小加一

过了慢启动阈值后，拥塞避免算法可以避免窗口增长过快导致窗口拥塞，此时还是增长阶段，一直增长，网络就会进入拥塞的状况了，会出现丢包现象，此时就需要对数据包进行重传，当触发重传机制后，就进入了拥塞发生算法

（3）**拥塞发生算法**：

重传机制主要有两种：**超时重传和快速重传**

发生超时重传时，就会使用拥塞发生算法。TCP认为这种情况比较糟糕，反应也比较强烈：

（a）它将慢启动阈值设置为当前拥塞窗口大小的一半

（b）将拥塞窗口直接重置为1，然后重新进入慢启动过程

但这种方式太激进了，会造成网络卡顿。

因此当收到三个重复确认ACK时，TCP就开启快速重传算法，TCP认为这种情况不严重，只丢失一小部分的数据，此时：

（a）拥塞窗口大小变为原来的一半

（b）将慢启动阈值置为当前改变后的拥塞窗口大小

（c）然后就进入快速恢复算法

（4）**快速恢复算法**：

在进入快速恢复算法之前，拥塞窗口和慢启动阈值已经被更新了

（a）然后将拥塞窗口大小设置为慢启动阈值 + 3，因为收到3个重复的ACK

（b）重传丢失的数据包

（c）如果再收到重复ACK，那么拥塞窗口  + 1

（d）如果收到新数据ACK后，表明重传的包成功了，那么退出快速恢复算法，将拥塞窗口大小设置为慢启动阈值，然后进入拥塞避免算法

![快速重传和快速恢复](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

**<mark>184.相比于其他语言，你觉得C++的特点有什么</mark>**

（1）引入了模板的概念，可复用性高

（2）运行效率高

（3）三大特性：封装、继承、多态

**<mark>185.项目中如何组织代码结构，用了什么版本管理工具</mark>**

（1）将代码按照不同的功能模块进行组织，每个模块放在一个文件夹下。主要有lock模块用于控制互斥锁和信号量，http模块负责解析报文，定时器模块，线程池模块等等

（2）将代码按照不同的功能分层组织：主线程作为异步线程只负责消息的收发，线程池中的工作线程负责解析具体的消息

（3）Git

**<mark>186.C++的虚函数有什么优势和劣势</mark>**

优势：实现了多态，可以使相同的函数实现不同的功能，提高代码的复用性和接口的规范化，更加符合面向对象的设计理念

劣势：

（1）运行时开销：由于虚函数的动态绑定需要在运行时进行额外的查找和解析，因此相对于非虚函数，虚函数会引入一定的运行时开销，可能导致性能稍微降低

（2）内存开销：：每个包含虚函数的类都会引入一个虚函数表（vtable）指针，以及额外的虚函数表。这增加了对象的内存开销，尤其是在大规模继承层次结构中。

（3）增加了设计的复杂性

**<mark>187.虚函数可以inline吗</mark>**

可以，但它的行为并不符合我们通常对inline函数的预期。

在C++中，使用`inline`关键字可以告诉编译器尝试将函数的定义内联展开，以减少函数调用的开销。

然而，对于虚函数，`inline`关键字的使用并不会实现我们期望的内联行为。虚函数的调用是通过虚函数表（vtable）进行的，这个调用过程涉及动态绑定和运行时查找。由于内联函数需要在编译时展开，而虚函数的调用在运行时才能确定，因此无法将虚函数的定义内联展开。

因此，虽然虚函数可以使用`inline`关键字进行声明，但编译器通常会忽略该关键字，并将其视为一个普通的虚函数。对于需要使用虚函数的情况，不建议使用`inline`关键字，而是依赖编译器自身的优化来决定是否将其内联展开。

**<mark>188.虚函数对性能上除了虚函数表查询的开销以外还有什么缺陷？</mark>**

（面试官提示：从现代编译器角度看。提示之后还是想不到，面试官回答要考虑，是否在一个CPUcache里面，有了虚函数以后，编译器不会做一些很强大的优化）

（1）缺少内联以及其他的优化机会：编译器在编译阶段无法确定实际调用的函数版本，从而无法进行函数内联优化。还会限制编译器其他方面的优化能力，例如可能无法进行循环优化

（2）缓存不友好：虚函数的调用涉及到动态绑定，而动态绑定需要在运行时根据对象的实际类型进行函数调用。这种动态绑定导致了缓存不友好的情况。由于虚函数表中存储了不同函数的地址，而不同的对象可能具有不同的虚函数表指针，这会导致虚函数调用所涉及的代码和数据分散在不同的内存位置上，可能导致缓存失效和不连续的内存访问，从而降低了缓存的命中率。

**<mark>189.在linux下查看进程所耗资源命令</mark>**

（1）top命令：用于实时监视系统中运行的进程。可以使用top命令查看各进程所占用的 CPU、内存、虚拟内存、磁盘 I/O 等资源占用情况。

（2）ps命令：用于列出当前系统中运行的进程。可以使用ps命令查看各进程的 PID、CPU 占用、内存占用、状态等信息。

（3）htop命令：是top命令的升级版，提供了更丰富的功能和界面。可以使用htop命令查看进程的 CPU 占用、内存占用、线程数量、进程状态等信息。

（4）pidstat命令：用于显示进程的资源使用情况。可以使用pidstat命令查看各进程的 CPU 使用情况、内存使用情况、I/O 操作情况等。

（5）iostat命令：用于监视系统的磁盘 I/O 性能。可以使用iostat命令查看各进程的磁盘 I/O 操作情况，包括每个进程的读写速度、请求队列长度、磁盘利用率等。

**<mark>190.查看网络连接数有多少条的命令</mark>**

```
netstat -an | grep ESTABLISHED | wc -l
```

wc（word count）命令用于统计文件字节、字符、单词与行的数量。

-l, --lines
 仅显示行数

**<mark>191.netstat能查看什么连接协议</mark>**

（1）TCP

（2）UDP

（3）Unix 域套接字：本地进程间socket通信

（4）RAW协议：RAW 协议是一种基本的传输层协议，提供对 IP 层的直接访问

（5）ICMP：ICMP 是一种网络层协议，用于发送控制和错误消息

**<mark>192.tcp/ip握手和挥手的区别</mark>**

- 握手是建立 TCP 连接时进行的，而挥手是终止 TCP 连接时进行的。
- 握手是为了协商连接参数和初始序列号，挥手是为了协商连接终止请求。
- 握手过程中，客户端和服务器交换多个报文段以建立连接；而挥手过程中，双方交换多个报文段以完成数据传输并关闭连接。

**<mark>193.挥手的状态timewait状态和closewait状态发生在什么地方什么时候</mark>**

（1）time_wait状态发生在**主送关闭方**接收到第三次挥手的SYN报文后，回一个ACK报文，进入time_wait状态，然后等待2MSL时间，如果没有新的数据到来，就关闭连接.

Timewait 状态的主要目的是确保在连接终止后的一段时间内，处于 Timewait 状态的一方能够接收到可能延迟到达的报文段，并防止早期建立的连接的重复报文段干扰后续连接。

（2）close_wait状态发生在被动关闭方收到第一次挥手的SYN报文后，发送ACK报文，然后进入close_wait状态

Closewait 状态表示被动关闭的一方已经完成数据传输并等待主动关闭的一方发送最后的关闭请求

一旦进入 Closewait 状态，被动关闭的一方可以继续发送可能积压的数据，但不会再接收数据。

**<mark>194.timewait数量很多是什么原因造成的</mark>**

TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接

有三个场景服务器会主动断开连接：

- 第一个场景：HTTP 没有使用长连接
- 第二个场景：HTTP 长连接超时
- 第三个场景：HTTP 长连接的请求数量达到上限

（1）**当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive**，因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。

针对这个场景下，解决的方式也很简单，让客户端和服务端都开启 HTTP Keep-Alive 机制。

（2）**如果客户端在发送完一个 HTTP 请求后，在一段时间内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接**。

当服务端出现大量 TIME_WAIT 状态的连接时，如果现象是有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么大概率就是因为 HTTP 长连接超时，导致服务端主动关闭连接，产生大量处于 TIME_WAIT 状态的连接。

（3）Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。

**对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果最大请求数量参数值是 100，这时候服务端就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态**。

**<mark>195.http协议消息报文</mark>**

（1）请求报文

由三部分组成：请求行，请求头，请求体

请求行：主要由请求方法（一般是GET和POST），请求URL和HTTP协议及版本组成

请求头：包含若干个属性，格式为属性名：属性值，包含Connection、Content-Length 等信息

请求体：主要包含POST方法的请求数据

（2）响应报文

也由三部分组成：响应行、响应头、响应体

响应行：包含报文协议及版本，还有状态码和状态描述

响应头：也由多个属性组成

响应体：包含服务器返回给客户端的数据

**<mark>196.POST和GET的区别</mark>**

（1）get是获取数据，post是修改数据

（2）get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内，相对较为安全

（3）get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。

（4）GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200 OK(返回数据); POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue表示继续发送，浏览器再发送data，服务器响应200 ok(返回数据)。

（5）GET请求会被浏览器主动缓存，而POST不会，除非手动设置。

（6）GET是幂等的，而POST不是幂等的

- 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

**<mark>197.http是无状态的，开发web的时候怎么知道当前的用户态信息</mark>**

客户端在第一次访问服务器的时候，服务器端会针对这次请求创建一个会话，并生成一个唯一的session ID来标注这个会话，然后服务端会把这个session ID写入到客户端浏览器的cookie里面，用来实现客户端状态的保存，那么在后续的请求里，客户端每一次请求都会携带session ID ，服务器端就可以根据session ID来识别当前会话的状态。

**cookie是客户端的存储机制，而session是服务端的存储机制**

**<mark>198.cookie怎么找到服务器端的信息</mark>**

在首次登陆某个网站的时候，没有任何cookie，服务器会返回一个自生成的session id。这个id作为cookie值写入浏览器。当再次登陆的时候，请求会携带这个cookie值传入后台服务器，服务器拿到 session  id 之后，在内存找到与之对应的 session 就可以继续操作了。
**<mark>199.http请求怎么知道成功还是失败？状态码</mark>**

通过HTTP响应的状态码

同3

**<mark>200.LT和ET的区别</mark>**

ET：边缘触发，使用边缘触发模式时，当被监控的socket描述符上有可读事件发生时，**服务器端只会从epoll_wait中苏醒一次**，即使进程没有调用read函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完

LT：水平触发，使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，目的是告诉我们有数据需要读取；

**<mark>201.线程池怎么保证线程安全</mark>**

（1）使用了互斥锁，通过对共享资源的加锁和解锁来保证并发访问的安全

（2）使用信号量，信号量是一种计数器，可以用来实现多个线程的同步和互斥。

（3）还可以使用读写锁，条件变量和原子操作来保证线程安全

**<mark>202.互斥锁可以重入吗</mark>**

C++标准库中用 mutex 表示不可重入的互斥锁，用 recursive_mutex 表示可重入的互斥锁。

在同一个线程中连续lock两次mutex会产生死锁。一般情况下，如果同一个线程先后两次调用 lock，在第二次调用时，由于锁已经被占用，该线程会挂起等待占用锁的线程释放锁，然而锁正是被自己占用着的，该线程又被挂起而没有机会释放锁，因此 就永远处于挂起等待状态了，于是就形成了死锁。

此时就需要使用递归式互斥量 recursive_mutex 来避免这个问题。recursive_mutex 不会产生上述的死锁问题，只是会增加锁的计数，但必须确保 unlock 和 lock 的次数相同，其他线程才可能获取到这个锁

**<mark>203.线程会有自己独立的栈区吗？会有独立的堆区吗？</mark>**

C++中的线程会有自己独立的栈区，用于保存线程的局部变量和调用栈信息。

至于堆区，线程通常会共享同一个堆区，即使用malloc、new等内存分配方法所分配出的内存块可以在多个线程之间共享。当然，也可以通过手动编写线程安全的内存分配方法，为每个线程分配独立的堆区。

**<mark>204.你了解 Linux 虚拟内存空间吗？</mark>**

（1）从程序局部性原理中我们可以得到这样一个结论：进程在运行时，不会一下子就要访问所有的内存，相反进程对于内存的访问会表现出明显的倾向性。进程更倾向于访问最近访问过的数据，以及热点数据附近的数据。

（2）所以无论一个进程实际可以占用的内存资源有多大，根据程序局部性原理，在某一段时间内，进程真正需要的资源只是很少的一部分，我们只需要为每个进程分配很少的内存就可以保证进程的正常运行

（3）而虚拟内存的引入正是为了解决这个问题，虚拟内存引入后，进程的视角就会变得非常开阔，每个进程都拥有属于自己的虚拟地址空间，进程与进程之间的虚拟地址空间是相互隔离，互不干扰的。

（4）每个进程都认为自己独占所有的内存空间，所有内存资源都属于自己，但其实任何一个虚拟内存里存储的数据，本质上还是保存在物理内存里的，只不过内核帮我们做了虚拟内存到物理内存这一层的映射，将不同进程的虚拟地址和不同内存的物理地址映射起来。

（5）当CPU访问进程的虚拟地址时，将虚拟地址转换成不同的物理地址，这样不同的进程运行时，虽然操作的是同一虚拟地址，真正写入的却是不同的物理地址，就不会造成冲突了。

（6）通过将多进程之间协同的相关复杂细节全部交给内核中的内存管理模块来处理，极大降低了编程的复杂性，这一切都是因为虚拟内存能够提供内存地址空间的隔离，极大的扩展了可用空间。

**<mark>205.虚拟内存有什么好处？</mark>**

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。

这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

**<mark>206.两个进程 malloc 可能会返回一个值吗？会映射到一个物理地址吗？</mark>**

可以，不会

**<mark>207.影响 C++ class 类的大小的因素有哪些？</mark>**

（1）class对象数据成员占用内存大小，会影响类对象大小。

（2）class对象采用的内存对齐策略，会影响类对象大小

（3）class对象中普通成员函数不会影响对象大小，但class中virtual函数会影响类对象的大小。因为虚函数导致对象增加4字节空间, 这是 vptr的缘故。

（4）虚承继的情况：由于涉及到虚函数表和虚基表，会同时增加一个（多重虚继承下对应多个）vptr指针指向虚函数表vTable和一个vptr指针指向虚基表vbTable，这两者所占的空间大小为：8（或8乘以多继承时父类的个数）；

**<mark>208.死锁产生的条件是什么？Cpp 中如何避免死锁？</mark>**

死锁概念：两个或者多个并发的进程，如果每个进程持有某个资源的同时又在等待其他的进程释放资源导致程序无法向前推进，称这一组进程产生了[死锁]。通俗的来说就是两个或者多个进程无限期的阻塞，互相等待的状态。

死锁产生的四个条件：

（1）互斥：一个资源每次只能被一个进程使用

（2）不可抢占：进程已获得的资源，在未使用完之前，不能强行剥夺

（3）占有并等待：一个进程因请求资源而阻塞时，对已获得的资源保持不放  
（4）循环等待：若干进程之间形成一种首尾相接的循环等待资源关系。

这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。

Cpp 中可以通过以下方法避免死锁：

（1）破坏互斥条件：修改代码使得资源可以被多个进程并发使用，如使用共享内存；

（2）破坏占有并等待条件：进程在请求资源时，先释放已经占有的资源，再去请求新的资源；

（3）破坏不可抢占条件：在一些情况下，允许系统强制剥夺进程所占有的资源；

（4）破坏循环等待条件：按照一定的规则对资源进行排序，要求每个进程按照相同的顺序请求资源，从而避免进程循环等待的发生。

**<mark>209.哈希表怎么处理碰撞问题？最差能退化到什么复杂度？</mark>**

碰撞（Collision）指的是哈希函数将不同的键映射到了同一个哈希桶（或槽位）的情况。在哈希表中，处理碰撞问题是关键之一，常用的解决碰撞的方法有以下两种：

（1）链接法（Chaining）：每个哈希桶维护一个链表（或其他数据结构），所有映射到该桶的键值对都存储在链表中。当发生碰撞时，新的键值对可以直接添加到链表的末尾。这样，不同的键可以共享同一个哈希桶，通过链表进行存储和查找。链表长度的增加会导致查找效率降低，但通常情况下链表长度较短，对性能影响较小。

（2）开放地址法（Open Addressing）：所有键值对都存储在哈希表的桶中，发生碰撞时会尝试寻找下一个可用的空桶。常见的开放地址法有线性探测（Linear Probing）、二次探测（Quadratic Probing）和双重散列（Double Hashing）等。这些方法在发生碰撞时会通过一定的规则寻找下一个可用的桶，直到找到空桶或达到一定的探测次数。开放地址法相比链接法占用更少的内存，但对于哈希表的装载因子（Load Factor）有一定的限制。

***哈希表装载因子是指哈希表中已经存储的元素数量与哈希表大小的比值***

最差情况下，哈希表的性能可能退化为 O(N)，其中 N 是哈希表中存储的键值对数量。这种情况通常发生在哈希函数设计不合理、哈希表装载因子过高或发生大量的碰撞时。在最坏的情况下，哈希表中的所有键值对都映射到同一个桶，导致链表或探测序列非常长，从而降低了查找、插入和删除操作的效率。因此，在设计和使用哈希表时，需要选择合适的哈希函数、调整装载因子，并根据实际情况进行性能分析和优化，以避免最差情况的发生。

**STL库中的unordered_set设置为如果元素个数 >= 篮子个数，篮子就要扩充为原来的2倍左右，然后将元素重新打散，挂在不同的篮子上**

**<mark>210.一个类空指针可以调用虚函数吗？可以调用普通函数吗？</mark>**

- （1）空指针调用非虚成员函数，若函数中没有需要解引用this的地方，函数运行不会出错，但是若用到this，因为this=nullptr，运行出错。
- （2）空指针调用虚函数运行时会出错。
- （3）这两种情况在编译时都能通过。

```
class A {
private:
    int data;
public:
    void fun0() { }
    virtual void fun1(){ }
};

int main() {
    A *p = nullptr;
    p->fun0();
    p->fun1();
}
```

（a）**空指针为什么能调用非虚成员函数？**
        首先，调用非虚函数，采用的是静态联编的方式，在编译期间，编译器会根据对象的静态类型来确定调用哪个函数。
       不管p指向什么，都不会影响p的静态类型，只要p的静态类型确定了，编译器就会根据这个静态类型找到对应的函数地址，就算p指向了NULL，也能找到A::fun0()地址，自然能成功调用了。
（b）**空指针调用的非虚成员函数中，引用了数据成员，为什么运行时会报错？**
        p->fun0();这种成员函数调用，在编译器里面会转变成A::fun0(this);，this指针会当作一个参数传给函数的。也就是说类对象被当作一个参数传给了成员函数，除了多了个this参数之外，成员函数和一般的函数并没有区别。只要函数内部不对这个this指针做取址操作，就不会报错。
       如果现在在函数内部要访问数据成员data，即使你写的是data，实际上也是通过this->data去访问这个数据成员的，现在this是空指针，你对空指针进行->操作，当然是非法的。
（c） **空指针为什么无法调用虚函数？**

虚表指针保存在实例化对象的前四个字节中，而空指针无法找到对应的对象的地址，因此就找不到虚表指针，也就无法找到虚表来调用虚函数

**<mark>211.手写生产者消费者模型</mark>**

```
#include <pthread.h>
#include <iostream>
#include <queue>
#include <unistd.h>
using namespace std;

template<typename T>
class BlockQueue {
private:
    bool isFull() {
        return que.size() == _capacity;
    }

    bool isEmpty() {
        return que.empty();
    }

public:
    BlockQueue(int cap = 5):_capacity(cap) {
        pthread_init_mutex(&_mutex, NULL);
        pthread_init_cond(&_full, NULL);
        pthread_init_cond(&_empty, NULL);
    }
    ~BlockQueue() {
        pthread_mutex_destory(&_mutex);
        pthread_cond_destory(&_full);
        pthread_cond_destory(&_empty);
    }

public:
    void push(const T& data) {
        pthread_mutex_lock(&_mutex);

        //判断是否满足生产消费条件时不能用if，而应该用while：
        //pthread_cond_wait函数是让当前执行流进行等待的函数，
        //是函数就意味着有可能调用失败，调用失败后该执行流就会继续往后执行,
        //就会出现错误(没有数据还拿，没有空间还放)。
        //在多消费者的情况下，
        //当生产者生产了一个数据后如果使用pthread_cond_broadcast函数唤醒消费者，
        //就会一次性唤醒多个消费者，但待消费的数据只有一个，此时其他消费者就被伪唤醒了。
        //为了避免出现上述情况，我们就要让线程被唤醒后再次进行判断，
        //确认是否真的满足生产消费条件，因此这里必须要用while进行判断。
        while (isFull()) {
            pthread_cond_wait(&_full, &_mutex);
        }
        que.push(data);
        pthread_cond_signal(&_empty);
        pthread_mutex_unlock(&_mutex);
    }

    void pop(T& data) {
        pthread_mutex_lock(&_mutex);
        while (isEmpty()) {
            pthread_cond_wait(&_empty, &_mutex);
        }
        data = que.front();
        que.pop();
        pthread_cond_signal(&_full);
        pthread_mutex_unlock(&_mutex);
    }


private:
    queue<T> que;
    int _capacity;
    pthread_mutex_t _mutex;
    pthread_cond_t _full;
    pthread_cond_t _empty;

};
```

### pthread_cond_signal的两种写法

```cobol
lock(&mutex);//一些操作
pthread_cond_signal(&cond);//
一些操作unlock(&mutex);
```

  缺点：在某些线程的实现中，会造成等待线程从内核中唤醒（由于cond_signal)回到用户空间，然后pthread_cond_wait返回前需要加锁，但是发现锁没有被释放，又回到内核空间所以一来一回会有性能的问题。  
  但是在LinuxThreads或者NPTL里面，就不会有这个问题，因为在Linux 线程中，有两个队列，分别是cond_wait队列和mutex_lock队列， cond_signal只是让线程从cond_wait队列移到mutex_lock队列，而不用返回到用户空间，不会有性能的损耗。所以Linux中这样用没问题。

```scss
lock(&mutex);//一些操作
unlock(&mutex);
pthread_cond_signal(&cond);
```

优点：不会出现之前说的那个潜在的性能损耗，因为在signal之前就已经释放锁了

缺点：如果unlock之后signal之前，发生进程交换，另一个进程（不是等待条件的进程）拿到这把梦寐以求的锁后加锁操作，那么等最终切换到等待条件的线程时锁被别人拿去还没归还，只能继续等待。

**<mark>212.存字符串用`unordered_map`还是用`map`好？为什么？要怎么优化？</mark>**

如果不要求字符串的有序性，用unorder_map好。因为unorder_map底层是哈希表实现的，而map是红黑树，所以相较于map，unorder_map的效率更高

优化：

（1）reserve预分配足够的内存

（2）尽量使用字符串的引用或指针来操作元素

（3）可以自定义特定的哈希函数

（4）使用移动语义来避免不必要的复制

**<mark>213.有一个请求队列,有读者线程和写者线程 在同时操作这个共享的请求队列,属于什么</mark>**

**<mark>样的读写模型 ？</mark>**

应该是公平读写模型

因为读者线程和写者线程都可以同时操作共享的请求队列，没有明确的读者或写者优先级。这意味着读者和写者之间没有特定的顺序限制，可以并发地访问请求队列。

**<mark>214.一写多读模型的情况下怎么解决读写冲突的问题？加锁是一种方案,但是会影</mark>**

**<mark>响性能,有没有更好的办法？</mark>**

可以使用双BUFFER及shared_ptr的机制来实现对同一变量的高效访问，同时又能保证不会出现竞争条件

（1）双buffer就是指对于通常要被多个线程访问的变量，再额外定义一个备份变量，由于是一写多读，写线程只向备份变量中写入，而所有线程只需要访问主变量本身即可，当写线程对备份变量的写操作完成后，会触发主变量指针和备份变量指针的互换操作，将原变量和备份变量进行交换，从而更新数据

（2）共享指针shared_ptr记录了对变量的引用次数，可以避免指针切换时的**访问丢失**问题

**在指针的切换过程中，会出现如下两个问题：**

假设使用map作为缓冲buffer

（1）由于对主map 的读是多线程的读，会出现多线程同时使用主map 共享指针ptr 的情形，而互换指针时，需要对主map 的指针进行写操作，为了避免对 ptr 的读写出现竞争条件，可以使用自旋锁来对ptr 的读写进行同步。使用自旋锁的原因有两个：

（a）只在指针切换时使用锁，而不是在读写两个map 时使用锁，因而锁的使用频率会非常的低，由此导致的上下文切换的代价是可接受的。
（b）由于指针切换时 ptr 处于的情形是一写多读，指针互换准备对 ptr 进行写操作时，要获取锁的等待时间并不长，并不会有长时间的锁等待出现，因而可以使用代价更小的自旋锁，而不是使用代价更高的读写锁。

（2）在准备互换ptr 和 bak_ptr 指向的内容时，如果某个读线程正在使用 ptr 访问主map，直接互换就可能出现读线程再通过ptr获取数据时访问失效的问题，严重的情况下会访问到无效内存导致程序崩溃。为了避免出现读线程会读取到无效数据，可以利用共享指针的引用计数来实现指针的延迟互换。

**<mark>215.epoll中可以无限承载socket的连接吗？创建socket时的返回值是什么？</mark>**

（1）epoll本身没有连接数的限制，但内存是有限的，1G的内存上能监听约10W个端口

（2）如果socket创建成功，返回的是一个整数文件描述符，用于后续的socket操作。如果创建失败，返回-1，并且可以使用errno变量来获取具体的错误信息

**<mark>216.fd在系统中有限制吗？可以无限申请吗？</mark>**

有限。

（1）单个进程中默认是1024，可以通过

```
ulimit -n   #查看当前进程的fd数量限制
ulimit -n num  #修改当前进程的fd数量限制
```

程序中可以用系统函数修改

```
#include <sys/resource.h>

struct rlimit {
    rlim_t rlim_cur; // soft limit
    rlim_t rlim_max; // hard limit    
};

// get resource limit
int getrlimit(int resource, struct rlimit *rlim);

// set resource limit
int setrlimit(int resource, const struct rlimit *rlim);
```

（2）操作系统对文件描述符也有限制，进程分配的文件描述符数量不能超过操作系统的限制，可以通过修改内核参数来调整阈值

```
sysctl fs.file-max=655360
```

文件描述符的数量总是有限的，取决于系统的配置和硬件资源

**<mark>217.一个服务端进程最多可以和多少个客户端进行连接？和fd的数量有关吗？</mark>**

最多可以同时连接的客户端数量取决于多个因素，包括操作系统的设置、硬件资源和应用程序的设计。

文件描述符的数量与同时连接的客户端数量有关，因为每个客户端连接都需要一个文件描述符。但是，需要注意的是，文件描述符的数量并不是唯一影响同时连接的客户端数量的因素。

其他因素包括：

（1）内存：每个连接都会消耗一定的内存，因此可用内存的大小限制了同时连接的客户端数量。

（2）网络带宽：每个连接的数据传输需要使用网络带宽，如果带宽有限，可能会限制同时连接的客户端数量。

（3）处理器性能：处理客户端请求需要消耗处理器资源，处理器的性能限制了同时处理请求的数量。

因此，尽管文件描述符的数量可能很大，但同时连接的客户端数量仍然受到其他因素的限制。实际可支持的连接数取决于这些因素之间的平衡和限制。

**<mark>218.假设这样一个场景，客户端在和服务端进行TCP的三次握手的过程中，突然间</mark>**

**<mark>客户端宕机了，那么这个socket怎么处理？可以删除吗？是怎么删除的？</mark>**

此时还没有建立TCP连接，此时客户端宕机，服务端收不到应答消息，服务端就会进行超时重传，重传超过一定的次数后，就会断开连接。超过超时时间后，服务端会自动关闭相应的socket，并释放相应的资源。这个过程由操作系统自动处理，应用程序无需显式进行操作。

**<mark>219.在服务端调用`accept()`之后,socket就是一直可读的吗？就是调用read()函数</mark>**

**<mark>就一直可以读吗？会阻塞吗？</mark>**

在服务端调用`accept()`函数之后，返回的新socket描述符可以用于后续的数据读取操作，例如调用`read()`函数。

当调用`read()`函数时，它会尝试从socket中读取数据。根据socket的状态和接收缓冲区中是否有数据可用，`read()`函数的行为可能会有所不同。

（1）阻塞模式：如果socket处于阻塞模式，并且接收缓冲区中没有数据可用，`read()`函数会阻塞当前线程，直到有数据到达为止。它会一直等待，直到有数据可读或发生错误。

（2）非阻塞模式：如果socket处于非阻塞模式，并且接收缓冲区中没有数据可用，`read()`函数会立即返回，并返回一个特定的错误码或值（如EWOULDBLOCK、EAGAIN等），表示当前没有数据可读。

在非阻塞模式下，通过轮询或使用事件驱动的方式，可以不断调用`read()`函数，以检查是否有数据可读。当有数据到达时，`read()`函数会返回读取的数据量；如果没有数据可读，它可能会返回一个指示暂时无数据可读的错误码或值。

**<mark>220.如果服务端read()函数发生了阻塞,对方客户端异常关闭了,一直没有发数据过来</mark>**

**<mark>服务端会一直阻塞吗？会导致服务端卡死吗？</mark>**

（1）如果客户端进程崩溃，内核会发送FIN报文通知服务端关闭连接，服务端read函数就会返回一个表示连接已关闭的值，通常是0，并结束阻塞状态

（2）如果客户端宕机：

（a）如果服务端设置了接收超时时间，在超过一定时间后，就会结束阻塞状态

（b）如果没有设置超时时间：

如果开启了TCP Keepalive保活机制，那么一定时间后服务端内核就会向应用程序发送错误通知，通常read返回0，结束阻塞；

如果没有开启保活机制，那么服务端就会一直阻塞

**<mark>221.epoll可以解决上面这个问题吗？如果要识别这个问题，怎么识别？</mark>**

如果客户端宕机，且双方没有数据交互，且没有开启保护机制，那么epoll不会立即返回错误消息。所以只能通过第（3）种方法来识别问题。

（1）读取返回值：当服务端通过 `epoll` 进行非阻塞读取时，如果连接已关闭或出现异常，`read()` 函数会返回一个特定的值，通常为 0。这表明连接已断开或发生错误，服务端可以根据返回值判断连接状态。

（2）事件通知：使用 `epoll` 监听的套接字在连接断开时会触发相应的事件通知。当客户端连接异常断开时，服务端可以通过检查 `epoll` 返回的事件列表来判断是否存在连接断开的事件，如 `EPOLLRDHUP` 事件。

（3）超时机制：服务端可以在 `epoll_wait()` 函数中设置超时时间，当超过指定的时间后仍未收到任何事件，可以认为连接出现异常。服务端可以根据超时时间来判断连接状态是否正常。

**<mark>222.linux进程创建线程的流程是怎么样的？</mark>**

 Linux内核通过一个被称为进程描述符的task_struct结构体来管理进程，这个结构体包含了一个进程所需的所有信息

（1）用户程序调用pthread_create库函数

（2）尝试从栈缓存里获取合适大小的内存，如果有合适大小的内存，则设置为线程栈，如果没有则从堆中申请指定大小的空间作为线程栈

（3）线程控制块的地址放在栈底，其中存放当前线程的数据

（4）然后调用create_thread()函数, create_thread()函数中调用clone()函数

（5）**将主线程的寄存器信息保存在主线程内核栈中**，然后调用sys_clone()

（6）紧接着调用do_fork()，do_fork函数的第一个参数可以用来控制父子进程共享或拷贝哪些进程资源，就可以设置线程共享进程的task_struct，类似于浅拷贝

（7）然后将该线程的task_struct加入链表队列中，返回用户空间

（8）接着调用start_thread函数，指向线程函数

（9）线程结束后，释放线程栈

**<mark>223.线程共享进程的资源在linux中是怎么实现的？</mark>**

do_fork函数中，会调用copy_process()函数，负责进程复制或克隆的核心实现

（1）创建新进程结构：`copy_process()`函数首先会为新的线程分配一个新的`task_struct`，用于跟踪线程的状态和资源。

（2）复制进程资源：接下来，`copy_process()`函数会复制父进程的资源到新线程结构中，包括页表、文件描述符表、信号处理器等。这样，新的线程就与父进程共享相同的资源。其中通过复制父进程的页表，就可以确保线程与父进程共享相同的虚拟地址空间。这样，线程可以直接访问进程的全局变量、静态变量和堆上的动态分配内存。

补充：设置线程特定的资源：在创建线程时，内核会为新线程设置线程特定的资源，例如线程 ID（tid）、线程局部存储（TLS）等。这些资源是线程独有的，与其他线程不共享。

需要注意的是，线程共享进程资源是通过复制父进程的资源来实现的，因此线程之间共享的资源是相同的。但是，线程也可以通过使用同步机制（如互斥锁、条件变量）来保护共享数据，以避免并发访问问题。

**<mark>224.线程有自己私有的栈，那么这个栈的内存是被分配到哪里的？是放在进程所属</mark>**

**<mark>的内存里面，还是说放在独立于进程外部的内存中？</mark>**

线程的栈内存是分配在进程的内存空间中，而不是独立于进程外部的内存。所以线程可以共享进程的其他资源，如代码段、全局变量和堆内存等。同时，线程之间的通信和同步也更加方便，因为它们可以直接访问相同的地址空间。

**<mark>225.什么是协程？协程有什么用？</mark>**

协程就是用户态的线程

（1）协程是由用户代码控制的，而不是由操作系统内核调度。它不依赖于操作系统提供的线程管理机制，因此可以在用户空间实现，并避免了线程切换的开销。

（2）可以在一个线程内同时执行多个协程，并且可以通过协程之间的切换来实现多任务并发。这种切换是协作式的，也就是说一个协程在执行过程中可以主动让出执行权给其他协程。

```
void A() {
   cout << 1 << " ";
   cout << 2 << " ";
   co_yield_ct();  // 切出到主协程
   cout << 3 << " ";
}

void B() {
   cout << "x" << " ";
   co_yield_ct();  // 切出到主协程
   cout << "y" << " ";
   cout << "z" << " ";
}

int main(void) {
  ...  // 主协程
  co_resume(A);  // 启动协程 A
  co_resume(B);  // 启动协程 B
  co_resume(A);  // 从协程 A 切出处继续执行
  co_resume(B);  // 从协程 B 切出处继续执行
}
```

```
输出：1 2 x 3 y z
```

作用：

（1）异步编程：协程能够简化异步任务的调度和等待，使我们能够以顺序、同步的方式编写异步代码。

（2）状态机：协程能够暂停和恢复执行，保留函数的上下文状态，从而能够编写具有复杂状态转换逻辑的代码，而无需显式地编写状态机的逻辑。

（3）生成器：协程可以作为生成器（Generator）使用，生成器可以逐步生成数据，而不是一次性生成全部数据，这在处理大量数据或需要按需计算的情况下非常有用。

（4）轻量级线程：协程可以用于并发任务的调度和执行，避免共享状态和线程安全性等并发编程问题。

**<mark>226.一致性哈希，场景、解决问题</mark>**

[9.4 什么是一致性哈希？ | 小林coding](https://www.xiaolincoding.com/os/8_network_system/hash.html#%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E8%AF%B7%E6%B1%82)

哈希算法在面对节点数量变化时，**最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(N)**，这样数据的迁移成本太高了。

一致性哈希算法就很好解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。

一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而**一致哈希算法是对 2^32 进行取模运算，是一个固定的值**。

我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为**哈希环**，如下图：

![](https://cdn.xiaolincoding.com//mysql/other/0ea3960fef48d4cbaeb4bec4345301e7.png)

一致性哈希要进行两步哈希：

- 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；
- 第二步：当对数据进行存储或访问时，对数据进行哈希映射；

所以，**一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上**。

对「数据」进行哈希映射的结果值，往**顺时针的方向找到的第一个节点**，就是存储该数据的节点。

**在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响**。

但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。

为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。

引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景

**<mark>227.对new和malloc的理解</mark>**

new和malloc都是动态内存分配函数。其中，new是C++中的操作符，malloc是C语言中的函数。new会调用对象的构造函数，而malloc不会。使用new可以简化代码，并且更加类型安全。

**补充：**

new和malloc区别：

(1)  **分配内存的位置**：malloc是从堆上动态分配内存，new是从自由存储区为对象动态分配内存。自由存储区的位置取决于operator new的实现。自由存储区不仅可以为堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。

(基本上，所有的C++编译器默认使用堆来实现自由存储，也即是缺省的全局运算符new和delete也许会按照malloc和free的方式来被实现，这时藉由new运算符分配的对象，说它在堆上也对，说它在自由存储区上也正确。但程序员也可以通过重载操作符，改用其他内存来实现自由存储)

(2)  **返回类型安全性**：malloc内存分配成功后返回void*，然后再强制类型转换为需要的类型；new操作符分配内存成功后返回与对象类型相匹配的指针类型；因此new是符合类型安全的操作符。

(3)  **内存分配失败返回值**：malloc内存分配失败后返回NULL。new分配内存失败则会抛异常（bac_alloc）。

(4)  **分配内存的大小的计算**：使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而malloc则需要显式地指出所需内存的尺寸。

(5)  **是否可以被重载**：opeartor new /operator delete可以被重载。而malloc/free则不能重载

**<mark>228.new是在内存上哪一块去分配的内存</mark>**

new是从自由存储区为对象动态分配内存。自由存储区的位置取决于operator new的实现。自由存储区不仅可以为堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。基本上，所有的C++编译器默认使用堆来实现自由存储

**<mark>229.如果new内存失败了会是怎么样？</mark>**

会抛出std::bad_alloc异常。

如果加上std::nothrow关键字，

```
A* p = new (std::nothrow) A;
```

new 就不会抛出异常而是会返回空指针

**<mark>230.右值引用有什么作用</mark>**

右值引用是C++11引入的特性，它是指对右值进行引用的一种方式。右值引用的作用主要有两个：

（1）可以通过右值引用来实现移动语义。移动语义可以在不进行深拷贝的情况下，将对象的资源所有权从一个对象转移到另一个对象，从而提高代码的效率。

（2）右值引用还可以用于完美转发。在函数模板中，通过使用右值引用类型的形参来接收参数，可以实现完美转发，即保持原参数的值类别（左值还是右值），将参数传递给另一个函数。如图中的forward(2),右值在传递给forward函数后就变成了左值

![](C:\Users\win\AppData\Roaming\marktext\images\2023-06-29-15-48-29-9f460065111b253e46e8d069313eeee.jpg)

**<mark>231.在哪些场景下会应用智能指针</mark>**

我自己是在动态内存管理中，使用智能指针可以避免手动管理内存的麻烦和出错风险。

**<mark>232.如果遇到内存泄漏这种问题，你一般是怎么去解决</mark>**

（1）在程序中加入必要的错误处理代码，避免程序因为异常情况而导致内存泄漏。

（2）使用智能指针等RAII机制，自动管理内存，避免手动管理内存的麻烦和出错风险。

（3）使用内存分析工具，检测程序中的内存泄漏，并进行相应的修复。

**<mark>233.class中缺省的函数</mark>**

在C++中，如果一个类没有显式地定义「构造函数、析构函数、拷贝构造函数、赋值运算符重载函数」，那么编译器会自动生成这些函数，这些函数被称为缺省函数。

**<mark>234.多线程锁是什么</mark>**

多线程锁是一种用来保护共享资源的机制。在多线程编程中，如果多个线程同时访问同一个共享资源，可能会发生竞态条件（Race Condition），导致程序的行为出现未定义的情况。为了避免这种情况的发生，可以使用多线程锁来保护共享资源。

多线程锁的基本思想是，在访问共享资源之前先获取锁，访问完成之后再释放锁。这样可以保证同一时刻只有一个线程可以访问共享资源，从而避免竞态条件的发生。

常见的多线程锁包括互斥锁、读写锁、条件变量等。其中，互斥锁用于保护共享资源的访问，读写锁用于在读多写少的情况下提高并发性能，条件变量用于线程之间的同步和通信。

**<mark>235.mysql的事务是什么</mark>**

在数据库中，事务（Transaction）是一组操作单元，这些操作单元要么全部执行成功，要么全部执行失败。事务是保证数据库一致性的重要机制之一，它可以将一系列的操作看作一个整体，从而保证数据库的完整性和正确性。

事务具有四个特性：

- 原子性（Atomicity）：事务中的所有操作要么全部执行成功，要么全部执行失败，不会出现部分执行的情况。

- 一致性（Consistency）：事务执行前后数据库的状态是一致的，即数据库中的约束和规则都得到了保持。

- 隔离性（Isolation）：多个事务并发执行时，相互之间不会影响彼此的执行结果。

- 持久性（Durability）：事务执行完成后，对数据库所作的修改将被永久保存到数据库中。

MySQL是一种常见的关系型数据库，支持事务的机制。在MySQL中，事务可以

通过使用事务控制语句（Transaction Control Statements）来进行管理，包括以下三个语句：

- START TRANSACTION：开始一个事务。

- COMMIT：提交一个事务，使之生效。

- ROLLBACK：回滚一个事务，使之失效。

在MySQL中，事务默认是关闭的，需要通过设置autocommit参数为0来启用事务。启用事务后，可以通过执行SQL语句来进行事务操作

**<mark>236.TCP连接中间会有什么操作</mark>**

在TCP连接中，客户端和服务器之间会进行以下操作：

- 握手阶段：客户端向服务器发送SYN包（同步包），请求建立连接。服务器收到SYN包后，向客户端发送SYN+ACK包（同步确认包），表示可以建立连接。客户端收到SYN+ACK包后，再向服务器发送ACK包（确认包），表示连接建立成功。

- 数据传输阶段：连接建立成功后，客户端和服务器之间可以进行数据的传输。客户端向服务器发送数据包，服务器接收数据包并进行处理，然后向客户端发送响应包。客户端收到响应包后，可以再次向服务器发送数据包，以此类推。

- 断开连接阶段：当客户端或服务器不再需要连接时，可以发送FIN包（结束包）来请求断开连接。对方收到FIN包后，也发送FIN包进行响应，表示同意断开连接。当两端都收到对方的FIN包后，连接才真正关闭。

需要注意的是，在TCP连接中可能会出现丢包、拥塞等情况，需要进行相应的处理，例如重传丢失的数据包、调整发送窗口大小等。

**<mark>237.谈一下对面向对象的看法</mark>**

"面向对象"是一种以事物为中心的编程思想，它是一种编程范式，满足面向对象编程的语言，一般会提供类、封装、继承等语法和概念来辅助我们进行面向对象编程。

所谓的面向对象就是将我们的程序模块化，对象化。它具有许多优点：

（1）**封装性（Encapsulation）**：面向对象的一个关键概念是封装，它允许将数据和对数据的操作封装在对象内部。这种封装性可以隐藏实现细节，使得对象的使用者只需关注对象的接口而不需要了解内部实现细节。这有助于提高代码的可维护性和可复用性。

（2）**继承性（Inheritance）**：继承是面向对象的另一个重要特性，它允许一个类继承另一个类的属性和方法。通过继承，可以实现代码的重用，并且可以建立类之间的层次关系，提供了一种更为灵活的代码组织方式。

（3）**多态性（Polymorphism）**：多态性是面向对象的重要特征之一。它允许使用统一的接口来处理不同的对象类型，而不需要关心对象的具体类型。多态性可以提高代码的灵活性和可扩展性，使得代码更加通用和易于理解。

（4）**模块化（Modularity）**：面向对象的设计方法鼓励将程序划分为相互独立的模块或对象，每个模块负责特定的功能。这种模块化的设计使得程序更易于理解、调试和维护。同时，模块化也促进了团队协作，不同成员可以独立开发和测试各自负责的模块。

**<mark>238.c++有几种继承</mark>**

无论是哪种继承方式，基类的私有成员在派生类中都是不可被访问的。只能通过基类的成员函数访问基类的私有数据成员

在C++中，有以下几种类型的继承：

（1）**公有继承（Public Inheritance）**：公有继承是最常见的继承方式。在公有继承中，基类的公有成员和保护成员都会成为派生类的公有成员和保护成员，私有成员不会被继承。公有继承表示派生类是基类的一种类型，可以访问基类的公有成员。

（2）**私有继承（Private Inheritance）**：在私有继承中，基类的公有成员和保护成员都变成了派生类的私有成员，无法直接访问。私有继承常用于实现继承的代码重用，而不是通过派生类对象访问基类的成员。

（3）**受保护继承（Protected Inheritance）**：受保护继承是介于公有继承和私有继承之间的一种继承方式。在受保护继承中，基类的公有成员和保护成员都变成了派生类的受保护成员，无法通过派生类对象访问。受保护继承较少使用，但在某些特定的设计情况下可能会有用。

此外，C++还提供了一种特殊的继承方式：

（4）**虚继承（Virtual Inheritance）**：虚拟继承用于解决多继承中的菱形继承问题。当一个派生类从两个或多个基类派生，并且这些基类又有一个共同的基类时，如果不使用虚拟继承，会导致共同基类的多份实例。虚拟继承通过使共同基类在继承链中只有一份实例，解决了菱形继承的问题。

**<mark>239.子类已经重写，如何调用父类的函数</mark>**

通过使用作用域解析运算符

```
#include <iostream>

class Base {
public:
    void display() {
        std::cout << "Base class display() function" << std::endl;
    }
};

class Derived : public Base {
public:
    void display() {
        std::cout << "Derived class display() function" << std::endl;
    }

    void callBaseDisplay() {
        Base::display();  // 调用父类的display()函数
    }
};

int main() {
    Derived derivedObj;
    derivedObj.display();  // 调用子类的display()函数
    derivedObj.callBaseDisplay();  // 调用父类的display()函数

    return 0;
}
```

**<mark>240.有向图和无向图是什么，都作用在什么方向</mark>**

有向图（Directed Graph）是一种图形结构，其中图中的边具有方向。每条边连接两个顶点，并且从一个顶点指向另一个顶点。换句话说，有向图中的边具有起点和终点，且有指定的方向。

无向图的边则没有方向，可以在两个顶点之间进行双向移动。

有向图可用于表示网页链接、软件模块之间的依赖关系、任务调度和流程图等。在算法和数据结构中，有向图应用在拓扑排序、最短路径算法和网络流算法等

无向图可用于表示社交网络中的用户关系、道路或交通网络中的路径等。在图论中，无向图应用在最小生成树、连通分量等算法中。

**<mark>241.了解完全二叉树吗</mark>**

完全二叉树（Complete Binary Tree）是一种特殊的二叉树结构，其中除了最后一层外，其他层的节点都是满的，并且最后一层的节点从左到右连续排列。换句话说，完全二叉树是按照从上到下、从左到右的顺序依次填充节点的二叉树。

特点：

（1）在完全二叉树中，每个节点都与其在二叉树中的位置相对应，可以使用数组或链表等数据结构来存储完全二叉树。

（2）如果用数组表示完全二叉树，假设节点的索引从 1 开始，那么对于任意一个节点的索引 i，它的左子节点的索引为 2i，右子节点的索引为 2i+1。

（3）完全二叉树通常是通过层次遍历（Level Order Traversal）来构建和访问的，因为层次遍历可以按照从左到右的顺序访问节点。

完全二叉树的特性使得它在某些应用中具有优势，例如堆数据结构和优先级队列等。

顺序结构存储就是使用数组来存储，一般只适合表示完全二叉树，因为如果不是完全二叉树，存储时会有空间的浪费

![在这里插入图片描述](https://img-blog.csdnimg.cn/2021050811100827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81MTk4MzYwNA==,size_16,color_FFFFFF,t_70#pic_center)

由图中可以看出，左侧一棵完全二叉树存储进一个数组时不存在空间浪费；而右侧非完全二叉树在存储时下标为3、6、7、8的位置没有数据，造成了空间的浪费。

**<mark>242.vim如何删除一行</mark>**

将光标移动到需要删除的行
按一下ESC键，确保退出编辑模式
按两次键盘上面的d键，即 dd ，就可以删除了

**<mark>243.https协议怎么保证安全的，保证的是哪部分安全</mark>**

HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，以确保传输的数据在网络上的安全性

HTTPS保证了三个主要方面的安全：

（1）数据加密：HTTPS使用**对称加密**和**非对称加密**结合的混合加密的方式对传输的数据进行加密，防止第三方截获和窃听。

（2）数据完整性：HTTPS使用消息摘要算法来确保数据的完整性，以检测数据是否在传输过程中被篡改。摘要算法就是一个哈希函数，可以用来计算出内容的哈希值，这个**哈希值是唯一的，且无法通过哈希值推导出内容**。接收方收到后也对内容进行计算，如果结果相同，就说明消息是完整的。

并可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；

（3）身份认证：但公钥可能会被伪造，所以HTTPS通过使用数字证书来验证服务器的身份。数字证书由权威的证书颁发机构（Certificate Authority）签发，用于证明服务器的身份。客户端在与服务器建立连接时，会验证服务器的证书是否有效和可信。这确保了客户端与服务器之间的通信是安全的，解决了冒充的风险

**<mark>244.多态的几种类型</mark>**

（1）子类型多态：就是运行时多态，也就是c++中通过虚函数实现的多态

（2）参数多态：也称编译时多态，提供了对任何类型执行相同代码的方法，在c++中，参数多态性是通过模板实现的

（3）重载多态：使具有相同名称的函数对于每种类型的行为不同

（4）强制多态：例如整型变量和浮点型变量相加时，需要先把整型变量强制转换为浮点型再进行加法运算

**<mark>245.虚基类是什么概念</mark>**

虚基类用于解决多重继承中的二义性和冗余问题。在C++中，当一个派生类从多个基类继承，而这些基类又有共同的基类时，可以使用虚基类来避免派生类中对共同基类数据成员的多次拷贝和访问的冲突。

**虚基类并不是在声明基类时声明的，而是在声明派生类时，指定继承方式声明的。**

当一个类被声明为虚基类时，它的派生类中对该虚基类的成员访问将通过虚基类指针进行。这样，在继承层次中只保留一个虚基类的实例，所有派生类共享该实例。这种共享机制确保了对虚基类成员的访问是一致的，避免了数据冗余和二义性问题。

[虚基类的基本概念_#Neo的博客-CSDN博客](https://blog.csdn.net/lsw15834115977/article/details/125836798)

**<mark>246.glibc的内存管理实现</mark>**

glibc使用ptmalloc作为内存分配器，

（1）当一个进程中包含多个线程时，线程之间共享同一个堆内存空间（即共享资源）。由于linux中共享资源的申请需要获取对应的资源锁，同一时刻仅有一个线程能够获取到锁并操作共享资源，其他线程只能够等待锁的释放，这样就造成了堆内存分配和释放效率的低下。为解决这个问题，可为每个线程单独划分一片堆内存区域，用于各个线程的堆内存分配。基于这种思想，glibc中引入了分配区(Arena)的概念，用于多线程的堆内存管理。其中，对于进程中的主线程来说，堆内存空间通过brk系统调用进行扩展，而对于其他线程的堆内存（即Arean）则通过mmap系统调用来扩展。

（2）堆由内存块组成，分为已使用的内存块和未使用的内存块。

未使用的内存块则可以分为top chunk和bin chunk，bin chunk是指夹在已使用内存块之间内存碎片，ptmalloc将这些内存碎片按照大小缓存在4个回收箱（bins）内进行管理。

（3）当与空闲内存块(free chunk)相邻的已分配的内存块(allocated chunk)被释放时，将已分配的内存块allocated chunk和相邻的空闲内存块free chunk合并为一个新的空闲内存块free chunk，并根据空闲内存块的大小和类型转移到相应的回收箱内（如转移到unsorted bin/small bin）。其中，fast bin中的free chunk不会进行合并，以保证fast bin中的chunk足够碎片化，能够尽快满足小内存的申请。

**<mark>247.TCP序列号增长到了最大值怎么办</mark>**

序列号是一个32位的无符号数，因此在到达4G之后再循环回到0

**<mark>248.webbench原理</mark>**

![](https://i0.hdslb.com/bfs/article/4039685f02cbec9f02dd3b2eca071921fbd3e63e.png@794w_918h_progressive.webp)

父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。

**<mark>249.EPOLLONESHOT</mark>**

epoll有两种触发的方式即LT（水平触发）和ET（边缘触发）两种，在前者，只要存在着事件就会不断的触发，直到处理完成，而后者只触发一次相同事件或者说只在从非触发到触发两个状态转换的时候才触发。

这会出现下面一种情况，如果是多线程在处理，一个SOCKET事件到来，数据开始解析，这时候这个SOCKET又来了同样一个这样的事件，而我的数据解析尚未完成，那么程序会自动调度另外一个线程或者进程来处理新的事件，这造成一个很严重的问题，不同的线程或者进程在处理同一个SOCKET的事件，这会使程序的健壮性大降低而编程的复杂度大大增加！！即使在ET模式下也有可能出现这种情况！！

这里用EPOLLONESHOT这种方法进行解决，可以在epoll上注册这个事件，注册这个事件后，如果在处理当前的SOCKET后不再重新注册相关事件，那么这个事件就不再响应了或者说触发了。要想重新注册事件则需要调用epoll_ctl重置文件描述符上的事件，这样前面的socket就不会出现竞态，这样就可以通过手动的方式来保证同一SOCKET只能被一个线程处理，不会跨越多个线程。

**<mark>250.为什么要三次握手，四次挥手</mark>**

三次握手的原因：

- 三次握手可以阻止重复历史连接的初始化

- 三次握手可以同步双方的初始序列号

- 三次握手可以避免资源浪费

四次次挥手的原因：

服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，因此是需要四次挥手。

**<mark>251.进程通信机制和优缺点</mark>**

**<mark>252.两个人仍一枚硬币，规定仍到正面可以吃苹果，请问先扔硬币的人吃到</mark>**

**<mark>苹果的概率有多大？</mark>**

对于先仍硬币的人，

其第一轮吃到苹果的概率是：1/2

第二轮吃到苹果的概率是：1/2^3

第三轮吃到苹果的概率是：1/2^5

.............................

总的吃到苹果的概率是一个无穷项的等比数列

首项为1/2，公比为1/4

等比数列前n项和公式为：

![](https://img-blog.csdnimg.cn/2021062214405341.png)

因此总的概率为：
![](https://img-blog.csdnimg.cn/2021062214423274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Noa19wbHVzcGx1cw==,size_16,color_FFFFFF,t_70)

**<mark>253.两个进程之间可以访问一个全局变量吗</mark>**

Linux环境下，进程地址空间相互独立，每个进程各自有不同的用户地址空间。任何一个进程的全局变量在另一个进程中都看不到，所以进程和进程之间不能相互访问，要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信
**<mark>254.基类构造函数能调用子类构造函数吗</mark>**

不能

在C++中，基类构造函数**无法**直接调用子类构造函数。基类构造函数的目的是初始化基类的成员和执行基类特定的初始化逻辑。子类构造函数则负责初始化子类的成员和执行子类特定的初始化逻辑。

然而，子类构造函数可以调用基类的构造函数来初始化继承的基类部分。这是通过在子类构造函数的初始化列表中调用基类构造函数来实现的。初始化列表是子类构造函数的一部分，它位于子类构造函数的函数体之前，用于初始化成员变量和基类。

下面是一个简单的示例，演示了如何在子类构造函数中调用基类构造函数：

```
class Base {
public:
    Base(int value) {
        // 基类构造函数逻辑
    }
};

class Derived : public Base {
public:
    Derived(int value1, int value2) : Base(value1) {
        // 子类构造函数逻辑
        // 这里调用了基类的构造函数Base(value1)
    }
};
```

在上面的例子中，`Derived` 是从 `Base` 派生出来的子类。在 `Derived` 的构造函数中，通过调用 `Base(value1)`，可以调用 `Base` 类的构造函数来初始化基类部分。然后，可以在 `Derived` 的构造函数中添加自己的逻辑。

需要注意的是，基类构造函数在子类构造函数的初始化列表中调用的位置很重要，它应该位于初始化列表的最开始部分。这是因为基类部分在子类部分之前初始化，所以必须首先调用基类构造函数来初始化基类部分，然后才能执行子类的构造函数逻辑。

**<mark>255.你这个项目是多线程的，那用多进程可不可以实现？</mark>**

可以，但性能较差

Web服务器通常选择使用多线程而不是多进程的主要原因有以下几点：

（1）资源共享：多线程可以共享同一个进程的内存空间，这意味着线程之间可以直接访问和操作同一份数据，而无需进行复杂的进程间通信（IPC）。这样可以方便地共享数据结构、缓存和连接池等资源，提高服务器的性能和效率。

（2）轻量级：线程的创建和销毁比进程更加轻量级，开销更小。创建线程所需的系统资源远远少于创建进程的资源。线程之间的切换也更快速，因为它们共享同一份内存空间。

（3）响应时间：线程之间的通信和切换比进程更快速，因为它们无需通过操作系统的进程间通信机制。这对于需要快速响应客户端请求的Web服务器非常重要，可以减少延迟并提高并发处理能力。

（4）扩展性：使用多线程可以更方便地实现服务器的扩展性。当有新的请求到达时，可以创建新的线程来处理请求，而不需要为每个请求创建一个全新的进程。这样可以减少系统开销，更好地适应高并发的请求负载。

（5）灵活性：多线程允许更细粒度的控制和管理，可以根据需求动态地创建、销毁和调度线程。线程之间的通信和同步也更加灵活，可以使用线程间的共享内存来进行数据共享和同步操作。

尽管多线程具有许多优点，但也存在一些挑战，如线程间的同步和互斥、共享资源的安全性等问题。这些问题需要仔细的线程设计和管理，以确保线程之间的正确协作和数据一致性。

**<mark>256.多线程和多进程都能实现并发，什么情况下用多进程，什么情况下用多线程？</mark>**

多线程适合以下情况：

（1）共享数据：如果应用需要在多个线程之间共享数据，以便实现高效的数据访问和共享资源的管理，那么多线程是一个不错的选择。线程可以直接访问共享的内存空间，因此数据共享更为方便。

（2）轻量级任务：如果应用需要频繁创建和销毁任务，并且任务之间的切换开销相对较小，那么多线程是更合适的选择。线程的创建和销毁比进程更快速，开销更小。

（3）响应时间：如果应用需要快速响应客户端请求，并且对于延迟要求较高，多线程可以更快速地进行线程切换和通信，提高响应时间。

多进程适合以下情况：

（1）独立性要求高：如果应用的不同部分需要具有较高的隔离性和独立性，以避免彼此之间的影响，那么多进程是更好的选择。每个进程拥有独立的内存空间和资源，它们之间相互隔离，可以提高应用的稳定性和安全性。

（2）CPU密集型任务：如果应用主要涉及计算密集型任务，例如图像处理、数值计算等，多进程可能更为适合。多个进程可以利用多核处理器的并行性，提高整体计算性能。

（3）故障隔离：如果应用需要具备故障隔离的能力，即当一个进程发生故障时，不会影响其他进程的正常运行，那么多进程可以提供更高的稳定性。

**<mark>257.定时器 用什么数据结构：比如数组增删性能较差  </mark>**
如果值涉及增删定时器，可以采用链表结构

如果涉及查找呢，可以使用哈希表加priority_queue
**<mark>258. 如果给你十万个高考生的高考成绩，你会选择用什么排序算法，为什么。</mark>**

（为什么我想说时间复杂度，结果给忘了！！！）O(nlogn)

我会用快排，因为在十万规模数据的情况下也能用较好的平均性能，但是一般是优化过的快排比如并行化，还有当子数组数据较小可以切换到插入排序进行优化，因为数据规模较小，插入排序效率更高。标准库的sort就是这种策略模式实现的，根据数据规模，选择不同的策略，也就是不同的排序算法，标准库也有sort并行化版本

```cpp
#include <iostream>
#include <vector>
#include <algorithm>
#include <execution>

int main() {
    std::vector<int> data = {5, 2, 7, 1, 3};

    // 使用并行化sort算法对容器进行排序
    std::sort(std::execution::par, data.begin(), data.end());

    // 打印排序后的结果
    std::cout << "排序结果：";
    for (int num : data) {
        std::cout << num << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

**<mark>259.c++11  vector新特性</mark>**

（1）列表初始化：C++11允许使用初始化列表语法来初始化std::vector对象。例如：

`std::vector<int> numbers = {1, 2, 3, 4, 5};`

隐式的使用了initializer_list：每当在程序中出现一段以{}包围的字面量时，就会自动构造一个initializer_list对象。

（2）自动推导类型：可以使用auto关键字来自动推导std::vector的类型。例如：

`auto numbers = std::vector<int>{1, 2, 3, 4, 5};`

（3）foreach循环：引入了范围的for循环，可以更方便地遍历std::vector中的元素。例如：

```
`std::vector<int> numbers = {1, 2, 3, 4, 5}; 
for (auto& num : numbers) {     
// 使用num进行操作 }
```

（4）移动语义：C++11引入了右值引用和移动语义的概念，使得在std::vector之间进行元素移动更高效。通过使用std::move函数，可以将对象的所有权从一个std::vector转移到另一个std::vector。例如：

```
`std::vector<int> source = {1, 2, 3, 4, 5}; 
std::vector<int> destination = std::move(source);`
```

（5）emplace_back函数：C++11引入了emplace_back成员函数，用于在std::vector的末尾直接构造对象，而无需进行拷贝或移动操作。例如：

```
`std::vector<std::string> words; 
words.emplace_back("hello"); words.emplace_back("world");
```

**<mark>260.TCP粘包问题（原因）</mark>**

（1）数据流传输：TCP协议将应用程序提交给它的数据视为一连串的字节流，而不是一个个独立的数据包。TCP会尽可能将这些字节流打包成适当大小的数据包进行传输，以提高传输效率。这样就可能导致多个应用层数据包在传输过程中被合并在一起形成粘包。

（2）MSS限制：TCP协议中有一个最大报文段长度（Maximum Segment Size，MSS）的限制，表示在一个TCP报文段中可以携带的最大数据量。当应用程序发送的数据超过MSS时，TCP会将数据进行分段，每个分段作为一个TCP报文段进行传输。但在接收端，TCP协议会尝试将接收到的多个报文段合并成完整的数据流。这可能导致多个应用层数据包被合并在一起形成粘包。

（3）Nagle算法和延迟确认：TCP协议还实现了Nagle算法和延迟确认机制，以优化网络传输性能。Nagle算法将较小的数据块合并成更大的报文段进行发送，以减少网络传输的开销。延迟确认机制将接收方对接收到的数据进行延迟确认，以减少确认报文的数量。这些机制也会增加粘包的可能性。

**UDP为什么不粘包？**

UDP协议本身不提供粘包和拆包的机制，因此UDP不会粘包。下面是一些解释：

（1）无连接性：UDP是一种无连接的协议，它不会对数据进行分割或重新组装。每个UDP数据报都是独立的数据单元，它们之间没有关联。UDP将应用程序交给它的数据报发送到网络，而网络将这些数据报传送给接收方。因此，在UDP中，没有对数据报进行合并或拆分的机制，也就不存在粘包和拆包的问题。

（2）数据报边界：UDP将应用程序提交给它的数据报作为一个完整的单元发送，而不会将数据划分为更小的片段。每个UDP数据报都有自己的数据报头，其中包含了目标端口、源端口和校验和等信息。这使得接收方能够将每个数据报作为独立的消息处理，而不需要进行粘包和拆包的处理。

虽然UDP本身不会发生粘包，但是在应用层实现UDP时，如果应用程序连续发送多个UDP数据报，这些数据报可能在网络传输中会被一起接收，从而导致看起来像是粘包的现象。这是因为底层的网络传输可能会将多个UDP数据报一起打包和传输，但这不是UDP协议本身造成的。

**<mark>261.如果网络延迟会发生粘包吗?</mark>**

会。

拥塞控制算法：TCP使用拥塞控制算法来避免网络拥塞。当网络出现拥塞时，TCP会减少发送速率以避免进一步加重拥塞。在这种情况下，多个数据包可能会被合并成一个数据包发送，从而导致粘包

**<mark>262.UDP会出现粘包吗？</mark>**
不会

虽然UDP本身不会发生粘包，但是在应用层实现UDP时，如果应用程序连续发送多个UDP数据报，这些数据报可能在网络传输中会被一起接收，从而导致看起来像是粘包的现象。这是因为底层的网络传输可能会将多个UDP数据报一起打包和传输，但这不是UDP协议本身造成的。

（1）数据发送速率：如果发送方以较高的速率发送UDP数据包，并且接收方无法及时处理这些数据包，多个数据包可能会在接收方的接收缓冲区中积累，导致粘包。

（2）IP分片：UDP数据包在IP层进行分片传输，当数据包超过网络的最大传输单元（MTU）时，会被分割成多个IP分片进行传输。这些分片可能会以不同的路径到达接收方，导致顺序错乱，进而出现粘包。

（3）网络拥塞：当网络出现拥塞时，UDP数据包可能会被合并或延迟传输，这可能导致多个数据包在一次接收操作中被接收到，形成粘包。

**<mark>263.tcp网络编程说一下会用到哪几个函数</mark>**

（1）`socket()`：用于创建一个套接字，指定协议族和套接字类型。

（2）`bind()`：将套接字与本地地址（IP地址和端口号）绑定。

（3）`listen()`：将套接字设置为监听模式，等待连接请求。

（4）`accept()`：接受客户端的连接请求，创建一个新的套接字来处理与客户端的通信。

（5）`connect()`：向服务器发起连接请求。

（6）`send()`/`write()`：向已连接的套接字发送数据。

（7）`recv()`/`read()`：从已连接的套接字接收数据。

（8）`close()`：关闭套接字连接。

（9）`shutdown()`：优雅地关闭套接字连接，可选择是关闭读取、写入或两者。

**<mark>264.然后又问我UDP可以用bind绑定吗？</mark>**
可以，同43

**<mark>265.线程池请求队列是用什么实现的？</mark>**

queue

**<mark>266.线程池中的线程是怎么运作的?</mark>**

（应该是想让我回答互斥锁+信号量）

线程池中的队列初始化后，判断任务队列为空，就会阻塞等待条件变量，当主线程读取完数据后，将数据封装成任务对象插入到任务队列中，然后调用条件变量的notify_one，通知线程池中的线程获取任务，线程池中的某个线程就会解除阻塞，获取数据并进行解析

**<mark>267.讲讲内存管理，不管理会怎么样</mark>**

如果不管理：

（1）内存泄漏（Memory Leaks）：当程序在使用完内存后没有正确释放它时，就会发生内存泄漏。这意味着系统中的可用内存不断减少，直到耗尽所有可用内存。内存泄漏会导致程序性能下降甚至崩溃。

（2）内存碎片化（Memory Fragmentation）：内存分配和释放的不规则性会导致内存碎片化。内存碎片化分为外部碎片和内部碎片。外部碎片指的是内存中存在的不连续、但无法分配给新请求的空闲内存块。内部碎片指的是分配给进程的内存块比其所需的内存块大。

（3）内存访问错误（Memory Access Errors）：如果程序访问了未分配给它的内存，或者在已释放的内存上继续进行读写操作，就会发生内存访问错误。这可能导致程序崩溃、数据损坏或安全漏洞。

（4）性能下降：没有进行有效的内存管理会导致系统性能下降。当可用内存不足时，操作系统可能需要频繁地进行页面交换（将内存中的数据移入磁盘），这会增加磁盘访问的开销，导致程序响应时间延长。

**<mark>268.如果频繁进行内存的分配释放会有什么问题吗？</mark>**

（1）性能下降：内存分配和释放都会从用户态切换到内核态，频繁进行会增加系统负担并降低性能。

（2）内存碎片化：频繁的内存分配和释放可能导致内存碎片化。内存碎片化分为外部碎片和内部碎片。外部碎片指的是内存中存在的不连续、但无法分配给新请求的空闲内存块。内部碎片指的是分配给进程的内存块比其所需的内存块大。内存碎片化会浪费内存并导致内存分配效率降低。

（3）内存泄漏和野指针：频繁的内存分配和释放操作容易引入内存泄漏和野指针问题。如果在程序中频繁进行内存分配和释放，存在可能忘记释放内存或使用已释放的内存的风险，导致内存泄漏或产生野指针。

**<mark>269.内存池了解吗？</mark>**

内存池（Memory Pool） 是一种**内存分配**方式。通常我们习惯直接使用new、malloc 等申请内存，这样做的缺点在于：由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。内存池则是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块， 若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。

**<mark>270.如果频繁分配释放的内存很大（>128k）,怎么处理？</mark>**

如果>128K，则Linux会使用mmap系统调用来分配内存，分配结束后会直接归还给操作系统，那么如果频繁的分配释放，每次都会触发缺页中断，会造成性能损耗。可以考虑禁用mmap分配内存，以及禁止brk的内存紧缩操作，从而可以获得大块的内存池，减少频繁的缺页中断，但需要注意内存碎片的问题

```
    // 禁止malloc调用mmap分配内存
    mallopt(M_MMAP_MAX, 0);
    // 禁止内存紧缩
    mallopt(M_TRIM_THRESHOLD, -1);
```

或者自己实现一个内存池来管理大块内存的分配与释放

[(163条消息) Linux进程分配内存的两种方式--brk() 和mmap()_linux brk_正版两只羊的博客-CSDN博客](https://blog.csdn.net/liangzhiyang/article/details/124273428)

**<mark>271.讲讲进程管理</mark>**

（1）进程创建：操作系统通过提供系统调用（如`fork()`或`createProcess()`）来创建新进程。在创建进程时，操作系统会为新进程分配必要的资源（如内存空间和文件描述符），并为其分配一个唯一的进程标识符（Process ID，PID）。

（2）进程调度：进程调度是操作系统根据一定的调度算法从可运行的进程队列中选择下一个要执行的进程的过程。调度算法决定了进程在 CPU 上执行的顺序和时间片分配等策略。

（3）进程同步与通信：在多进程环境下，进程之间可能需要进行同步和通信。操作系统提供了各种机制，如信号量、互斥锁、条件变量和管道等，以便进程之间进行数据共享和协调工作。

（4）进程状态管理：操作系统维护进程的状态信息，包括运行、就绪、阻塞等。进程状态的改变是由操作系统根据进程的执行和事件发生情况进行管理和更新的。

（5）进程终止：进程终止是指进程完成执行或由于异常情况（如错误、中断等）而终止执行。操作系统负责回收终止进程所占用的资源，并通知父进程有关终止状态。

（6）进程间关系：操作系统记录和管理进程间的关系，如父子进程关系、进程组、会话等。这些关系在进程管理和进程通信中起到重要作用。

（7）进程资源管理：操作系统分配、追踪和管理进程所使用的资源，包括内存、文件、I/O设备等。进程资源管理确保资源的合理分配和利用，以满足不同进程的需求

**<mark>272.你平时自己有过进程管理吗？</mark>**

双臂进程管道通信

**<mark>273.堆栈溢出怎么处理</mark>**

 （1）使用迭代来代替递归，避免深层次的函数嵌套，或者使用动态分配的内存来存储大型的数据结构

（2）可以修改操作系统的设置，增加栈的大小

（3）减少函数中局部变量的大小，使用静态变量或全局变量

**<mark>274.c++标准库里优先队列是怎么实现的？  </mark>**

（1）优先队列通常使用一个数组（或容器）来存储元素，并使用索引来表示元素之间的关系。i节点的左右节点下标分别为 2 * i + 1 和 2 * i + 2

（2）插入操作：将新元素插入到数组的末尾，并根据堆的性质将其上浮到合适的位置。上浮操作将新元素与其父节点进行比较，如果满足堆的性质，则交换位置，并继续向上比较，直到满足堆的性质或达到根节点。

（3）删除操作：从堆的根节点移除元素，即移除优先级最高的元素。将根节点与数组末尾的元素交换位置，然后将根节点下沉到合适的位置。下沉操作将根节点与其较大（或较小）的子节点进行比较，如果不满足堆的性质，则交换位置，并继续向下比较，直到满足堆的性质或达到叶子节点。
**<mark>275.堆排序是怎么做的  </mark>**

（1）将无序序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆

（2）将堆顶元素与末尾元素交换，将最大元素“沉”到数组末端

（3）重新调整结构使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序

[(163条消息) 堆排序算法（图解详细流程）_堆排序的详细过程_温文艾尔的博客-CSDN博客](https://blog.csdn.net/wenwenaier/article/details/121314974)

**<mark> 276.多线程怎么保证引用计数的安全的</mark>**

答：引用计数这个变量是std::atomic，操作时自带锁

**<mark>277.常见的锁有哪些</mark>**

答：读写锁、互斥锁这些，再就是一些锁思想，比如乐观锁、悲观锁、自旋锁

**<mark>278.valotile关键字的用处</mark>**

答：避免编译器额外优化

**<mark>279.不同地区的用户的请求怎么打到附近的地区呢？</mark>**

CDN 将内容资源分发到位于多个地理位置机房中的服务器上，这样我们在访问内容资源的时候，不用访问源服务器。而是直接访问离我们最近的 CDN 节点 ，这样一来就省去了长途跋涉的时间成本，从而实现了网络加速。

找到离用户最近的 CDN 节点是由 CDN 的**全局负载均衡器（*Global Sever Load Balance，GSLB*）**负责的。

那 GSLB 是在什么时候起作用的呢？在回答这个问题前，我们先来看看在没有 CDN 的情况下，访问域名时发生的事情。

在没有 CDN 的情况下，当我们访问域名时，DNS 服务器最终会返回源服务器的地址。

比如，当我们在浏览器输入 www.xiaolin.com 域名后，在本地 host 文件找不到域名时，客户端就会访问本地 DNS 服务器。

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfg8KBLwPAE6ktepRPahjT7TyX6BwTp8IcDsOAkGvvWiaUcg2dQZc3ExHZyHr2ngzib5HfeMqvHN35g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

这时候:

- 如果本地 DNS 服务器有缓存该网站的地址，则直接返回网站的地址；

- 如果没有就通过递归查询的方式，先请求根 DNS，根 DNS 返回顶级 DNS（.com）的地址；再请求 .com 顶级 DNS 得到 xiaolin.com 的域名服务器地址，再从 xiaolin.com 的域名服务器中查询到 www.xiaolin.com 对应的 IP 地址，然后返回这个 IP 地址，同时本地 DNS 缓存该 IP 地址，这样下一次的解析同一个域名就不需要做 DNS 的迭代查询了。

**但加入 CDN 后就不一样了**。

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfg8KBLwPAE6ktepRPahjT7Ve7FiaAianuWiaZic1anXPYAST8dccKtcwJ5uzia8ZqicxiciaWfGOlgyDpVWg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

会在 xiaolin.com 这个 DNS 服务器上，设置一个 CNAME 别名，指向另外一个域名 www.xiaolin.cdn.com，返回给本地 DNS 服务器。

接着继续解析该域名，这个时候访问的就是 xiaolin.cdn.com 这台 CDN 专用的 DNS 服务器，在这个服务器上，又会设置一个 CNAME，指向另外一个域名，这次指向的就是 CDN 的 GSLB。

接着，本地 DNS 服务器去请求 CDN 的 GSLB 的域名，GSLB 就会为用户选择一台合适的 CDN 节点提供服务，选择的依据主要有以下几点：

- 看用户的 IP 地址，查表得知地理位置，找相对最近的 CDN 节点；

- 看用户所在的运营商网络，找相同网络的 CDN 节点；

- 看用户请求 URL，判断哪一台服务器上有用户所请求的资源；

- 查询 CDN 节点的负载情况，找负载较轻的节点；

GSLB 会基于以上的条件进行综合分析后，找出一台最合适的 CDN 节点，并返回该 CDN 节点的 IP 地址给本地 DNS 服务器，然后本地 DNS 服务器缓存该 IP 地址，并将 IP 返回给客户端，客户端去访问这个 CDN 节点，下载资源。

**<mark>280.TCP的close_wait在哪端，如果我们场景中出现了大量的close_wait，要怎么排查</mark>**

CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。

所以，**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接**。

那什么情况会导致服务端的程序没有调用 close 函数关闭连接？这时候通常需要排查代码。

我们先来分析一个普通的 TCP 服务端的流程：

1. 创建服务端 socket，bind 绑定端口、listen 监听端口

2. 将服务端 socket 注册到 epoll

3. epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket

4. 将已连接的 socket 注册到 epoll

5. epoll_wait 等待事件发生

6. 对方连接关闭时，我方调用 close

可能导致服务端没有调用 close 函数的原因，如下。

**第一个原因**：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。

不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。

**第二个原因**：第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。

发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。

**第三个原因**：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。

发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：[一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析](https://mp.weixin.qq.com/s?__biz=MzU3Njk0MTc3Ng==&mid=2247486020&idx=1&sn=f7cf41aec28e2e10a46228a64b1c0a5c&scene=21#wechat_redirect)

**第四个原因**：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。

可以发现，**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close**。

**<mark>281.protobuf</mark>**

Protobuf 是用于数据序列化和反序列化的格式，类似于 json。但它们有以下几点区别：

- 数据大小：Protobuf是一种二进制格式，相对于JSON来说，数据大小更小，序列化和反序列化的效率更高，因此在网络传输和存储方面具有一定的优势。

- 性能：由于Protobuf是二进制格式，相对于JSON来说，解析速度更快，占用的CPU和内存资源更少，因此在高并发场景下，性能更优。

- 可读性：JSON是一种文本格式，可读性更好，易于调试和排查问题。而Protobuf是一种二进制格式，可读性较差。

Protobuf适用于高性能、大数据量、高并发等场景，而JSON适用于数据交换、易读性要求高的场景。

**<mark>282.说一下代码里使用异步的思路</mark>**

（a）主线程充当异步线程，负责监听所有socket上的事件

（b）若有新请求到来，主线程接收得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件

（c）如果socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成任务对象插入到任务队列中

（d）所有工作线程睡眠在任务队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。

**<mark>282.IO特别密集时epoll效率还高吗</mark>**

答：可以考虑select/poll，这种情况轮询也很高效，且结构简单。

**补充：**

可以先解释io特别密集时为什么 epoll 效率不高。原因是：

- 连接密集（短连接特别多），使用epoll的话，每一次连接需要发生epoll_wait->accpet->epoll_ctl调用，而使用select只需要select->accpet，减少了一次系统调用。

- 读写密集的话，如果收到数据，我们需要响应数据的话，使用epoll的情况下， read 完后也需要epoll_ctl 加入写事件，相比select多了一次系统调用

**<mark>283.kafka了解吗</mark>**

Kafka是一种高[吞吐量](https://baike.baidu.com/item/%E5%90%9E%E5%90%90%E9%87%8F/157092?fromModule=lemma_inlink)的分布式[发布订阅](https://baike.baidu.com/item/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/22695073?fromModule=lemma_inlink)消息系统，它可以处理消费者在网站中的所有[动作流](https://baike.baidu.com/item/%E5%8A%A8%E4%BD%9C%E6%B5%81/15738974?fromModule=lemma_inlink)数据
**<mark>284.乐观锁怎么实现的  </mark>**
使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。用下面的一张图来说明：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201115202324396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RsOTYyNDU0,size_16,color_FFFFFF,t_70#pic_center)

如上图所示，如果更新操作顺序执行，则数据的版本（version）依次递增，不会产生冲突。但是如果发生有不同的业务操作对同一版本的数据进行修改，那么，先提交的操作（图中B）会把数据version更新为2，当A在B之后提交更新时发现数据的version已经被修改了，那么A的更新操作会失败。

**<mark>285.extern C</mark>**

extern "C"是C++特有的指令（C无法使用该指令），目的在于支持C++与C混合编程。

extern “C”**的作用是告诉**C++编译器**用C规则编译指定的代码（除函数重载外，extern “C”不影响C++其他特性）。

[(163条消息) extern “C“的作用及理解_externc_米碎师兄的博客-CSDN博客](https://blog.csdn.net/sinat_36817189/article/details/110423243)

**<mark>286.vector增加元素是值拷贝还是指针拷贝</mark>**

在 C++ 的标准库中，`std::vector` 是一个动态数组容器，它的元素在内存中是连续存储的。当你向 `std::vector` 中添加元素时，会发生值拷贝。

具体来说，当你使用 `push_back()` 或 `emplace_back()` 函数向 `std::vector` 中添加元素时，容器会在内部分配一块新的内存来存储新元素，并将新元素的值拷贝到这个内存空间中。这意味着原始元素和新元素是完全独立的，它们在内存中占用不同的位置，修改一个元素不会影响到其他元素。

以下是一个示例，演示了向 `std::vector` 添加元素时的值拷贝行为：

```cpp
#include <iostream>
#include <vector>

int main() {
    std::vector<int> myVector;
    int originalValue = 10;

    myVector.push_back(originalValue);

    originalValue = 20; // 修改原始值，不会影响 vector 中的元素

    std::cout << "Original value: " << originalValue << std::endl;
    std::cout << "Vector value: " << myVector[0] << std::endl;

    return 0;
}
```

输出结果为：

```
Original value: 20
Vector value: 10
```

可以看到，虽然原始值 `originalValue` 被修改为 20，但是 `myVector` 中的元素仍然保持为添加时的原始值 10。

需要注意的是，当 `std::vector` 存储的是指针类型时，指针本身被值拷贝，而不是指针指向的内容。如果你希望在 `std::vector` 中存储指针，并且希望通过修改指针指向的内容来影响 `std::vector` 中的元素，那么你需要小心管理指针的生命周期，确保指针指向的内存不会被释放或重复使用。

**<mark>287.最后输出结果是什么</mark>**

```
//问最后的输出结果，*(p + 4) - *(p + 0)我第一次说16，最后说4，感觉就是16啊，为啥子？
#include <stdio.h>
int a[] = {1, 3, 5, 7, 9};
int *p[] = {a, a + 1, a + 2, a + 3, a + 4};

int main()
{
    printf("%d %d %d\n", a[4], *(a + 2), *p[1]);                                  // 9 5 3
    printf("%d %d %d\n", **(p + 1) + a[2], *(p + 4) - *(p + 0), *(a + 3) % a[4]); // 8 4 7
    printf("%d %d \n", *(p + 4), *(p + 0)); //4206640 4206624 不懂为啥减完成4了？
    return 0;
}
```

```
p[1]就是a[1]的地址，等同于*(p + 1)
int 占4个字节，所以地址加一会使指针移动4个字节
```

**<mark>288.ros框架</mark>**

ROS（Robot Operating System）是一个灵活、分布式的框架，用于开发机器人软件应用。它提供了一系列工具、库和约定，用于帮助开发者构建机器人系统。下面是关于ROS框架的一些关键特点和组成部分：

（1）软件包（Packages）：ROS使用软件包来组织和管理代码。软件包包含了相关的功能、库、可执行文件和配置文件等。开发者可以创建自己的软件包，也可以使用其他人共享的ROS软件包。

（2）消息传递：ROS使用发布/订阅模型（Publisher/Subscriber）进行消息传递。节点可以发布（publish）消息到一个特定的主题（topic），其他节点可以订阅（subscribe）该主题以接收消息。这种松耦合的通信模型使得不同的节点可以独立开发和测试。

（3）工具集：ROS提供了一系列实用工具来辅助开发、构建和部署机器人应用。例如，ROS包含了用于可视化、调试、数据记录和仿真的工具。常用的工具包括rviz、rqt、rosbag、roscore等。

（4）跨平台支持：ROS可以在多种操作系统上运行，包括Linux、Windows和macOS等。这使得开发者可以在不同的环境中使用ROS进行机器人应用的开发和部署。

总之，ROS提供了一个强大的框架和工具集，使得开发者能够更轻松地构建复杂的机器人软件应用。它的模块化设计和灵活的通信机制使得不同的功能模块可以独立开发和集成，为机器人应用的开发和研究提供了便利性和可扩展性。

**<mark>289.vim里替换一段字符串怎么做</mark>**

```
（1）vim 中可用 :s 命令来替换字符串，具体如下：
:s/str1/str2/ 替换当前行第一个 str1 为 str2
:s/str1/str2/g 替换当前行中所有 str1 为 str2
:m,ns/str1/str2/ 替换第 n 行开始到最后一行中每一行的第一个 str1 为 str2
:m,ns/str1/str2/g 替换第 n 行开始到最后一行中所有的 str1 为 str2
(注：m和n 为数字，若m为 .，表示为当前行开始；若n为$，则表示到最后一行结束)
如果使用 # 作为分隔符，则中间出现的 / 不会作为分隔符，比如：
:s#str1/#str2/# 替换当前行第一个 str1/ 为 str2/
:%s+/oradata/apras/+/user01/apras1+ (使用+ 来 替换 / )： /oradata/apras/替换成/user01/apras1/
```

```
（2）其他:%s/str1/str2/（等同于 :g/str1/s//str2/） 替换每一行的第一个 str1 为 str2
:%s/str1/str2/g（等同于 :g/str1/s//str2/g 和 :1,$ s/str1/str2/g ） 替换文中所有 str1 为 str2
从替换命令可以看到，g 放在命令末尾，表示对搜索字符串的每次出现进行替换；不加 g，表示只对搜索
```

**~~<mark>290.linux中替换某个文件中的字符串</mark>~~**

在 Linux 中，你可以使用 `sed` 命令来替换某个文件中的字符串。`sed` 是一个流编辑器，可以对文本进行流式处理和转换。以下是使用 `sed` 命令进行替换的基本语法：

`sed 's/old/new/g' filename`

其中，`old` 是要被替换的字符串，`new` 是替换后的字符串，`filename` 是要进行替换操作的文件名。使用 `s/old/new/g` 表示替换操作，`g` 是全局替换标志，表示每行中的所有匹配都会被替换。

示例：将文件 `example.txt` 中的所有 "hello" 替换为 "world"，可以使用以下命令：

`sed 's/hello/world/g' example.txt`

该命令会将替换结果打印到标准输出

**<mark>291.linux查找某个字符串</mark>**

```
grep 'pattern' filename
```

**<mark>292.git问题：merge时候出现conflict怎么办？</mark>**

查看完了冲突之后当然是解决冲突，最简单的方法将去做手动合并。手动合并的方法很简单，就是我们选择我们要保留的代码，然后再把>>>>>, ======, <<<<<<这些提示行给去掉。最后重新add commit。

**<mark>293.面向过程</mark>**

就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了。

**<mark>294.TCP四次挥手第二次和第三次不能合并吗</mark>**

当被动关闭方在 TCP 挥手过程中，如果「没有数据要发送」，同时开启了 TCP 延迟确认机制「没有开启 TCP_QUICKACK（默认情况就是没有开启，没有开启 TCP_QUICKACK，等于就是在使用 TCP 延迟确认机制）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。

**所以，出现三次挥手现象，是因为 TCP 延迟确认机制导致的。**

[4.22 TCP 四次挥手，可以变成三次吗？ | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/network/3_tcp/tcp_three_fin.html#%E5%AE%9E%E9%AA%8C%E9%AA%8C%E8%AF%81)

**<mark>295.设计模式几大原则</mark>**

**单一职责原则**：每个类应该专注于做一件事情。

**里氏替换原则**：超类存在的地方，子类是可以替换的。

**依赖倒置原则**：实现尽量依赖抽象，不依赖具体实现。

**接口隔离原则**：应当尽量为客户端提供小的单独的接口，而不是提供大的总的接口。

**迪米特法则**：又叫最少知识原则，一个软件实体应当尽可能少的与其他实体发生相互作用。

**开闭原则**：面向扩展开放，面向修改关闭。

**组合/聚合原则**：尽量使用组合聚合来达到复用效果，尽量少使用继承。继承一定程度上是牺牲了封装性来达到复用的效果的，这样有时是得不偿失的。

[设计模式的七大基本原则 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/153276460)

[(163条消息) 设计模式六大原则_设计模式原则_西京刀客的博客-CSDN博客](https://blog.csdn.net/inthat/article/details/106097509)

**<mark>296.多态和继承在什么情况下使用</mark>**

这些都是需要尽可能大的进行代码重用的时候用到的。

继承和多态经常一起使用。通过继承可以建立类之间的层次结构，通过多态可以根据对象的实际类型来调用适当的方法。这样可以提高代码的可重用性、可扩展性和可维护性，使代码更加灵活和易于扩展。

继承通常用于描述"is-a"的关系，比如一个子类可以继承父类的特征和行为，并且可以添加自己的特定特征和行为。继承的主要优点是代码的重用和扩展性。当存在明确的层次关系和共享代码的需求时，可以使用继承。

多态的主要优点是增加了代码的灵活性和可扩展性。当需要根据不同的对象类型来执行不同的操作时，可以使用多态。

**<mark>297.除了多态和继承还有什么面向对象方法</mark>**

（1）封装（Encapsulation）：封装是将数据和操作封装在一个单独的类中。通过封装，可以隐藏内部实现的细节，并通过公共接口提供对数据和操作的访问。这样可以提高代码的安全性和可维护性，并且可以方便地修改内部实现而不影响其他部分的代码。

（2）抽象（Abstraction）：抽象提供了一种逻辑上的分类和组织方式，使得程序设计更具可理解性和可扩展性（抽象是指将复杂的现实世界问题简化为适当的模型和概念。在面向对象编程中，抽象可以通过类和接口来实现。类是对具有共同特征和行为的对象的抽象，而接口定义了一组方法的契约，描述了对象应该具有的行为）

（3）接口（Interface）：接口定义了一组方法，描述了对象应该具有的行为。接口提供了一种规范，规定了类应该实现哪些方法，并描述了这些方法应该做什么

**<mark>298.情景题。手机店。不同品牌的不同型号手机有不同的业务逻辑。怎么设计系统</mark>**

（1）使用继承和多态：定义一个基础的手机类，作为所有手机的父类，包含一些通用的属性和方法，比如品牌、型号、价格等。然后，针对不同品牌和型号的手机，创建具体的子类，继承基础手机类，并根据其特定的业务逻辑实现相应的方法。通过多态的机制，可以使用父类对象来指向不同品牌和型号的手机对象，并根据实际对象的类型来调用适当的方法。

（2）使用接口：定义一个手机接口，描述手机应该具有的基本行为，比如打电话、发送短信等。然后，每个具体的手机品牌和型号都可以实现该接口，并根据自身的特点来实现相应的方法。通过接口的方式，可以实现多态，方便对不同品牌和型号的手机进行统一的操作。

（3）使用组合：考虑将手机店系统中的各个角色（比如顾客、销售员）和手机进行组合。例如，可以定义一个顾客类，其中包含一个手机对象作为其成员变量，表示顾客拥有的手机。销售员类可以包含一个手机库存对象，用于管理和提供不同品牌和型号的手机。通过组合的方式，可以实现不同对象之间的关联关系，并进行相应的操作。

（4）使用抽象类或接口进行业务分类：如果不同品牌的手机在业务逻辑上有相似的特点，可以考虑定义一个抽象类或接口，描述该类手机的业务行为，然后每个具体品牌的手机都实现该抽象类或接口，并根据实际情况进行具体实现。这样可以方便对不同品牌的手机进行分类和管理。

**<mark>299.DNS服务器用的是什么协议</mark>**

UDP协议

将主机域名转换为ip地址，属于**应用层协议**，使用UDP传输。（DNS应用层协议，以前有个考官问过）因为UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了。

而使用基于TCP的DNS协议要三次握手、发送数据以及应答、四次挥手，但是UDP协议传输内容不能超过512字节。

不过客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可

**<mark>300.ping命令 用的是什么协议。在哪一层。</mark>**

使用ICMP，工作在网络层，与IP协议紧密关联

`ping`命令使用的是ICMP协议（Internet Control Message Protocol）。ICMP是位于网络层（第3层）的协议，它与IP协议紧密关联。尽管ICMP不是独立的传输协议，但它在网络通信中发挥了重要作用。

`ping`命令用于测试主机之间的连通性和往返延迟时间。它发送一个ICMP Echo Request消息（类型为8）到目标主机，并等待目标主机的ICMP Echo Reply消息（类型为0）作为响应。通过这种方式，`ping`命令可以确定主机是否可达，并测量到目标主机的往返延迟时间。

**<mark>301.为什么要使用线程池</mark>**

（1）**减少线程创建和销毁的开销：** 创建和销毁线程是一项开销较大的操作。使用线程池，可以预先创建一组线程并将它们保持活动状态，减少了创建和销毁线程的频率，从而降低了开销。

（2）**提高系统资源利用率：** 在多线程环境中，每个线程都需要占用一定的系统资源，如内存和处理器时间。线程池可以限制并发线程的数量，从而避免资源过度消耗，提高系统的资源利用率。

（3）**提高响应性：** 当有新任务到达时，线程池中的线程可以立即处理它们，而不需要等待新线程的创建。这减少了任务开始执行的延迟时间，提高了系统的响应性能。

**<mark>302.怎么查内存泄漏</mark>**

**<mark>303.reactor和proactor的好处和坏处。</mark>**

Reactor模式:

优点：

- Reactor实现相对简单，对于耗时短的处理场景处理高效；   
  操作系统可以在多个事件源上等待，并且避免了多线程编程相关的性能开销和编程复杂性；   
- 简单易懂：相对于Proactor模式，Reactor模式更简单易懂，容易实现和维护。

缺点：

- 对于并发度很高的场景，由于单个线程负责监听和分发所有的IO事件，会出现性能瓶颈。
- Reactor处理耗时长的操作会造成事件分发的阻塞，影响到后续事件的处理；

Proactor模式：

优点：

- 可以充分利用异步I/O的特性，提高I/O操作的并发度。在高负载的情况下，能够保证系统的稳定性和可靠性。
- 适合处理长时间运行的任务，如大规模数据传输，文件复制等操作。

缺点：

- 实现较为困难：相对于Reactor模式来说，Proactor模式的实现较为复杂。
- 对于小规模任务的处理效率略低。因为Proactor模式需要进行线程切换和上下文切换，这些额外的开销可能会影响小规模任务的处理效率。

**<mark>304.为什么要用reactor而不用proactor</mark>**

在 Linux 下的异步 I/O 是不完善的， `aio` 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，所以基于 Linux 的高性能网络程序都是使用 Reactor 方案。

**<mark>305.小根堆定时器，如果一次Pop一个的话，高并发情况下会不会有问题</mark>**

性能会较差，在有大量定时任务的情况下，可以选择使用时间轮定时器
