**<mark>1.介绍智能指针</mark>**

智能指针的作用是用来管理一个指针，防止程序员申请的空间在函数结束时没有释放，从而造成内存泄漏的发生。

使用智能指针可以很大程度上避免这个问题，因为智能指针是一个类，当超出了类的作用域范围时，会自动调用类的析构函数，从而释放资源。

有四种智能指针，auto_ptr, unique_ptr, shared_ptr, weak_ptr 

**auto_ptr**采用所有权的模式，在c++11中被废弃了，其原因是：

（1）auto_ptr在拷贝和赋值操作时会导致所有权转移。auto_ptr以copy的语义来转移指针资源，转移指针资源的所有权的同时，会将原指针置为NULL，这和我们通常理解上的copy行为是不一致的（通常不会修改原数据）。

（2）使用容器保存auto_ptr后，在进行操作后，可能导致容器中保存的原auto_ptr所管理的对象失效，如sort快排实现中有将元素复制到某个局部临时对象中，但对于auto_ptr，却将原元素置为NULL，这就会导致最后的排序结果中可能会存在大量的NULL。

**unique_ptr**同样采用所有权模式，它实现严格拥有的概念，保证同一时间内只能由一个智能指针指向该对象，即两个unique_ptr不能同时指向一个对象，不能进行复制操作，只能进行移动操作。当它指向其他对象时，之前所指向的对象会被摧毁。因此，unique_ptr 比auto_ptr 更安全。

**shared_ptr**实现共享式拥有的概念，多个智能指针可以同时指向相同的对象，使用引用计数的机制来表明资源被几个指针所共享，对象和相关资源会在最后一个引用被销毁时释放，

可以通过调用use_count()来查看资源的所有者个数，并调用release()，来释放当前指针的资源所有权，使计数减一，当计数减为0时，资源会被释放。

**weak_ptr**叫弱引用指针，是一种不控制对象生命周期的智能指针，他指向一个shared_ptr管理的对象。进行该对象内存管理的是强引用的shared_ptr。weak_ptr只是提供了对管理对象的一个访问手段，他设计的目的是为了协助shared_ptr，它可以解决shared_ptr循环引用的问题，weak_ptr只可以从一个shared_ptr或另一个weak_ptr对象构造，他的构造和析构不会引起引用计数的增加或减少。

**循环引用**：两个对象相互使用shared_ptr指向对方

**<mark>2.final修饰符的作用</mark>**

（1）用来修饰类时，使该类不能被继承

（2）用来修饰类的成员函数时，使该成员函数不能被派生类重写。final关键字可以帮助确保程序的安全性，可以防止有人不小心修改或覆盖定义好的函数从而造成错误。

**<mark>3.HTTP状态码</mark>**

1xx: 100, 101

2xx: 200, 204, 206

3xx: 301, 302, 304

4xx: 400, 403, 404

5xx: 500, 501, 502, 503, 504, 505

**<mark>4.MYSQL索引</mark>**

索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是索引是数据的目录。

innoDB主要使用B+ Tree索引类型，创建表时，innoDB存储引擎会根据不同的场景选择不同的列作为索引：

（1）如果有主键，默认使用主键作为聚簇索引的索引键

（2）如果没有主键，就选择第一个不含NULL值的唯一列作为聚簇索引的索引键

（3）如果俩个都没有，InnoDB将会自动生成一个隐式自增ID列作为聚簇索引的索引键

其他索引都称为辅助索引，或二级索引、非聚簇索引。

B+ Tree是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，且每个节点里的数据是按主键顺序存放的。每一层父节点的索引值都会出现在下层子节点的索引值中，所以叶子节点包含所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。

在二级索引的B+Tree就能查询到结果的过程叫做**覆盖索引**，也就是只需要查一个B+Tree就能找到数据

联合索引，存在最左匹配原则

**<mark>5.MYSQL的buffer pool怎么清空</mark>**

使用FLUSH BUFFER POOL

这个命令可以清空所有的缓存页，使得MYSQL需要重新读取磁盘上的数据，这意味着下一次查询的速度会比较慢，因为需要重新从磁盘中读取数据到内存。

**<mark>6.虚函数</mark>**

主要是用来实现多态，在基类的函数前加上virtual关键字，在派生类中重写该函数，运行时将根据对象的实际类型来调用对应的函数，如果对象类型是派生类，就调用派生类的函数，如果是基类，就调用基类函数。

当一个类中包含虚函数时，编译器会为该类生成一个虚函数表，保存该类中虚函数的地址，同样，派生类继承基类，自然也会有虚函数，所以编译器也会为派生类生成自己的虚函数表，当我们定义一个派生类对象时，编译器检测该类型有虚函数，所以为这个派生类对象生成一个虚函数指针，指向该类型的虚函数表，这个虚函数指针的初始化是在构造函数中完成的。

如果有一个基类类型的指针，指向派生类，那么当调用虚函数时，就会根据所指真正对象的虚函数表指针去寻找虚函数的地址，也就可以调用派生类的虚函数表中的虚函数以此实现多态。

**<mark>7.析构函数写成虚函数原因</mark>**

防止内存泄漏，如果定义了一个基类的指针指向一个派生类对象，在使用完毕准备销毁时，如果基类的析构函数没有定义成虚函数，则编译器根据指针类型就会认为当前对象的类型是基类，调用基类的析构函数，仅执行基类的析构，派生类自身的内容无法被析构，造成内存泄漏。

如果基类的析构函数定义为虚函数，那么编译器就可以根据实际对象，执行派生类的析构函数，再执行基类的析构函数，成功释放内存。

**<mark>8.构造函数为什么不能声明为虚函数</mark>**

（1）因为创建一个对象时需要确定对象的类型，而虚函数是在运行时确定其类型的。而在构造一个对象时，由于对象还未创建成功，编译器无法知道对象的实际类型是类本身还是类的派生类。

（2）虚函数的调用需要虚函数表指针，而该指针存放在对象的内存空间中；若构造函数声明为虚函数，那么由于对象还未创建，还没有内存空间，也就没有虚函数表地址用来调用虚函数即构造函数。

**<mark>9.构造函数或析构函数中调用虚函数会怎样</mark>**

语法上没有问题，但会失去多态性。

如果在构造或析构函数中调用虚函数，会先调用父类中的实现。

因为构造函数没有将虚函数指针和虚函数表初始化完毕，就调用了虚函数，此时必然调用基类中的实现。

析构函数中，则因为子类的那部分已经析构掉了，此时在父类的析构函数中调用虚函数，调用的也只能是父类中的实现。

**<mark>10.c++编译过程</mark>**

主要分为预处理，编译，汇编，链接

预处理阶段：主要处理源代码中#开头的预处理指令，如#include，将文件内容替换到它的位置；删除所有#define，展开所有宏定义等。生成.i文件

编译阶段：将.i文件翻译成文本文件.s ,生成汇编语言程序。每条语句都以标准的文本格式确切描述一条低级机器语言指令。

汇编阶段：汇编器将.s 翻译成机器语言指令。把这些指令打包成可重定位的目标程序，生成.o文件。它是一个二进制文件，它的字节码是机器语言指令，不再是字符。前面俩个阶段都还有字符。

链接阶段：将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接

之所要经过预处理，编译，汇编这么一系列步骤才生成目标文件，是因为在每一个阶段都有相应的优化技术，只有在每个阶段分别优化并生成最为高效的机器指令才能达到最大的优化效果，如果一步到位直接从源程序生成目标文件，可能就会失去很多代码优化的机会。

**<mark>11.静态链接，动态链接</mark>**

静态链接就是把Lib文件中用到的函数代码直接链接进目标程序，程序运行时不再需要调用其它的库文件；

动态链接就是把调用的函数所在文件模块（DLL）和调用函数在文件中的位置等信息链接进目标程序，程序运行时再从DLL中寻找相应函数代码，因此需要相应DLL文件的支持

静态链接：

空间浪费：每个可执行文件对所有需要的目标文件都要有一份副本

更新速度：每当库函数代码修改了，需要重新编译链接形成可执行程序

运行效率：因为在可执行程序中已经具备了所有执行程序所需要的东西，在执行的时候运行速度快。

动态链接：

空间少：多个程序在执行时共享同一份副本。

更新速度快：只需要替换原来的目标文件，不需要重新编译链接。

性能损耗大：因为把链接推迟到了运行时。     

**<mark>12.map和unordered_map区别</mark>**

有序，无序；

红黑树，哈希表；

查询和增删效率：map为O(logn) ，unmap为O（1）。

**<mark>13.inline函数</mark>**

（1）由inline关键字定义，引入inline函数主要是为了替代C中复杂易错不易维护的宏函数

（2）编译器在编译阶段完成对inline函数的处理，即把inline函数的调用替换为函数的本体。inline只是对编译器的一种建议，编译器可以不去做。

**优点**：

（1）省去了参数压栈，栈帧开辟与回收，结果返回等，提高运行速度

（2）与宏定义相比，在代码展开时，会做安全检查或自动类型转换

（3）在类中声明同时定义的成员函数，会自动转化为内联函数，因此可以访问类的成员变量，宏定义则不能

（4）在运行时可调试，宏定义不能。

**缺点**：

（1）代码膨胀，inline函数带来的运行效率是典型的空间换时间的做法，内联是以函数膨胀为代价，消除函数调用带来的开销，如果执行函数体内代码的时间，相比函数调用的开销较大，那么效率的收获会很少。且每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。

（2）inline函数不会随着库函数的升级而升级，必须重新编译。如果是non-inline的，用户只需要重新链接。

（3）是否内联不可控

**<mark>14.webserver项目的作用</mark>**

一个webserver就是一个服务器软件。主要功能是通过HTTP协议与客户端（通常是浏览器）进行通信，来接收，存储，处理来自客户端的HTTP请求，并对其请求做出HTTP响应，返回给客户端其请求的内容或返回一个ERROR信息，可实现上万的并发连接。

**<mark>15.reactor高并发</mark>**

IO多路复用监听事件，收到事件后，根据事件类型分配给某个进程/线程。

reactor模式主要由reactor和处理资源池这两个核心部分组成，其中：

Reactor负责监听和分发事件，事件类型包含连接事件，读写事件；

处理资源池负责处理事件，如read-业务逻辑-send

经典方案有：单reactor单进程/线程；单reacto多进程/线程；多reactor多进程/线程

假设当前进程中有三个对象，分别是Reactor、acceptor、Handler。

其中reactor负责监听和分发事件；acceptor负责获取连接；handler负责处理业务逻辑

**单单**：（1）reactor通过IO多路复用接口监听事件，根据事件的类型决定分发给acceptor还是handler处理

（2）如果是连接建立的事件，则交由Acceptor对象处理，accptor对象会通过accept系统调用来获取连接，并创建一个handler对象来处理后续的响应事件

（3）如果不是连接建立的事件，则交由当前连接对应的Handler对象来进行响应

（4）handler对象通过read-业务处理-send的流程来完成完整的业务流程。

优点：实现简单，不用考虑进程间通信，以及多进程竞争

缺点：无法充分利用多核CPU；Handler在进行业务处理时，整个进程是无法处理其他连接事件的。如果业务处理耗时较长，就会造成响应的延迟。

**单多**：（1）（2）（3）同单单

（4）handler对象不再负责业务逻辑的处理，只负责数据的接收和发送。Handler对象通过read读取到数据后，会将数据发给子线程里的processor对象进行业务处理。

子线程里的Processor对象处理完后，将结果发送给主线程里的handler对象，handler对象再通过send方法将响应结果发给client

优点：能充分利用多核CPU性能

缺点：一个reactor对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能瓶颈的地方。

**多多**：（1）主线程中的MainReactor对象通过IO多路复用接口监听连接建立事件，收到事件后通过acceptor对象中的accept获取连接，将新的连接分配某个子线程

（2）子线程中的SubReactor对象将MainReactor对象分配的连接加入IO多路复用接口继续监听，并创建一个Handler用于处理连接的响应事件。

（3）如果有新的事件发生，Subreactor通知当前连接对应的Handler对象来进行响应

（4）Handler对象通过read-业务处理-send的流程来完成完整的业务流程

优点：实现简单，主线程子线程分工明确，主线程和子线程交互简单。

**<mark>16.半同步/半反应堆模式</mark>**

（1）半同步/半反应堆模式是半同步/半异步模式的变体，将半异步具体化为某种事件处理模式

（2）并发模式中的同步指的是程序完全按照代码的顺序执行

异步指的是程序的执行需要由系统事件驱动。

（3）工作流程：

（a）主线程充当异步线程，负责监听所有socket上的事件

（b）若有新请求到来，主线程接收得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件

（c）如果socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成请求对象插入到请求队列中

（d）所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。

**<mark>17.IO多路复用技术</mark>**

即 使用一个进程来维护多个Socket的方式。

一个进程虽然任一时刻只能处理一个请求，但是如果处理每个请求事件的耗时控制在1毫秒以内，则1秒就可以处理上千个请求，把时间拉长了看，就是多个请求复用了一个进程，这就是多路复用，这种思想很类似与一个CPU并发多个进程，所以也叫时分多路复用。

linux内核提供了select/poll/epoll这三个多路复用的系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。

select/poll/epoll在获取事件时，先把所有的连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求。

**<mark>18.为什么使用EPOLL</mark>**

select：使用固定长度的bitsmap来表示文件描述符集合，他支持的文件描述符个数是有限制的，在Linux系统中，默认最大值为1024。

poll：使用动态数组来存储，以链表形式来组织，突破了select文件描述符个数限制

他们俩并没有太大的本质区别，都是使用线性结构来存储sokcet集合，因此都需要遍历文件描述符集合来找到可读或可写的Socket，时间复杂度为O(n)，而且都需要在用户态和内核态之间拷贝文件描述符集合，这种方式随着并发数的增加，性能的损耗会成指数增长。

epoll通过俩个方面，很好的解决了select和poll的问题

（1）epoll在内核中维护了一棵红黑树，可以保存所有待检测的socket，所以每次只需要传入一个待检测的socket，而不需要传入整个socket集合，减少了内核和用户空间大量的数据拷贝和内存分配。

（2）epoll使用事件驱动的机制，在内核里维护了一个链表来记录就绪事件，当某个socket有事件发生时，通过回调函数内核会将其加入到就绪事件链表中，当用户调用epoll_wait函数时，只返回有事件发生的文件描述符个数，这样就不需要像select/poll那样遍历整个集合，大大提高了检测的效率。

**<mark>19.void*的作用</mark>**

void*定义一个指针变量，但不说明他指向哪一种类型。即这个指针变量只有地址，没有大小。

（1）可以作为函数模板，链表等的通用参数，使用时，只需要强制类型转换就可以。

（2）可以用来表示指向全是0的地址 (void*)0, 相当于NULL

**<mark>20.函数中声明的不是malloc的数组怎么返回</mark>**

（1）声明一个静态数组，并返回一个指针。静态数组在超出范围时不会被释放，但他不安全，因为当下一次调用该函数时，将覆盖该数组，在多线程中使用更加糟糕。

（2）在调用函数时传入数组地址，在主函数中定义一个数组，然后在调用自定义函数时，将该数组的地址当作参数传入，并在自定义函数生命周期结束后将其内容返回。

**<mark>21.常见的内存泄漏情况。如果程序员不犯错，还有哪些情况会造成内存泄漏</mark>**

（1）在类的构造和析构函数中没有匹配的调用new和delete

（2）没有正确的清除嵌套的对象指针。如在一个对象的成员变量为另一个对象的指针。

（3）在释放对象数组时在delete中没有使用方括号

（4）释放指向对象的指针数组时，只释放了对象空间，没有释放指针空间。

指针数组是指：数组中存放的是对象，只需要调用delete[]，即可调用对象数组中每个对象的析构函数释放空间

指向对象的指针数组是指：数组中存放的是指向对象的指针，不仅要释放每个对象的空间，还要释放每个指针的空间。

（5）缺少拷贝构造函数和重载赋值运算符。默认的是浅拷贝，如果有成员变量是指针，会造成俩个指针指向同一块空间，在释放空间时就会俩次释放同一块空间。所以要么重写拷贝构造函数和重载赋值运算符，要么将他们禁用。

（6）没有将基类的析构函数定义为虚函数。

除了编程错误：

（1）操作系统或硬件的限制

（2）程序使用的某些软件库或者插件

（3）使用效率低下的算法，消耗超过必要的内存

（4）在高负载和压力测试下。

内存泄漏分为：

（1）堆内存泄漏，我们经常说的内存泄漏就是堆内存泄漏，在堆上申请了资源，用完后却没有释放，从而导致该块内存永远不可用。

（2）资源泄漏，通常指的是系统资源，如socket，文件描述符等，因为这些在操作系统中都是有限制的，如果创建了而不归还，久而久之就会耗尽资源。

**<mark>22.匿名函数和函数指针的区别</mark>**

Lambda函数的引入主要就是为了消除使用函数指针的复杂性。要使用函数指针，需要创建一个单独的函数，之后创建指向该函数的函数指针，并将其作为参数传递给所需的函数。

而使用函数指针执行的任务很小，一般不值得写那么多行代码。Lambda函数可以更轻松地完成相同的任务。

匿名函数是动态创建的，不与特定的内存位置相关联，而函数指针被显式定义为保存特定函数在内存中的地址的变量。匿名函数通常用于高阶函数，而函数指针更常用于回调。

**<mark>23.vector, list, map, unordered_map各自的特点和原理</mark>**

vector和list：

（1）vector底层通过数组实现，存储空间上一段连续的内存空间；list通过双向链表实现，把不连续的内存空间通过链表的方式连接在一起。

（2）vector插入删除操作需要移动元素，时间复杂度为ON，而list为O(1)

（3）vector支持随机访问，时间复杂度O(1)， list不支持，需要遍历整个链表来查询，为O(N)

（4）vector空间不足时需要另开辟一个俩倍于当前空间大小的空间，然后将原有的元素复制过去，再析构原空间，会造成原有的迭代器失效。list在每次插入和删除的时候分配和释放空间，所以不会引起迭代器失效。

map和unordered_map：

（1）map的底层是红黑树，unordered_map 是哈希表。

（2）所以map的增删、查找时间复杂度为Ologn，unordered_map为O1。

（3）map的key有序，unordered_map无序。

**<mark>24.vector怎么实现扩容</mark>**

若空间不足，会申请一块2倍于当前大小的新内存，然后把旧内存的元素拷贝至新内存空间，并释放旧内存空间，此时原有的迭代器都指向原空间，因此会失效。

**<mark>25.怎么降低vector扩容次数</mark>**

（1）使用reserve预分配足够大的空间

（2）选择合理的初始容量

**<mark>26.reserve和resize区别</mark>**

resize是用来改变容器里的元素个数，如果参数大于当前元素个数，则新增默认0元素直到元素个数等于参数，如果小于则截断

reserve则用来改变当前容器的最大容量，他不会生成新元素，只是确定这个容器允许放入多少对象，如果参数len大于当前的capacity，那么会开辟一个新的len大小的空间，将之前的对象复制过来，并销毁旧空间。

**<mark>27.map为什么采用红黑树，不采用AVL树</mark>**

因为红黑树在效率和简单性之间提供了良好的平衡。

红黑树确保没有一条路径会比其他路径长出两倍，因此红黑树是一种弱平衡树，相对于要求严格的AVL树来说，旋转次数更少。AVL树比红黑树更加平衡，意味着他需要更加频繁的旋转来维护。

因此AVL树一般适用于读取查找密集型任务。而红黑树适用于插入修改密集型任务。

**<mark>28.TCP三次握手</mark>**

（1）一开始，客户端和服务端都处于closed状态。先是服务端主动监听某个端口，处于LISTEN状态。

（2）客户端随机初始化一个序列号（client_isn)，将此序号置于TCP首部的序列号字段中，同时把SYN标志位置为1，表示SYN报文。接着把第一个SYN报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于SYN-SENT状态。

（3）服务端收到客户端的SYN报文后，首先服务端也随机初始化自己的序列号（server_isn），将此序号填入首部的序列号字段中，其次把TCP首部的确认应答号字段填入client_isn+ 1，接着把SYN和ACK标志位置为1，最后把该报文发给客户端，该报文不包含应用层数据。之后服务端处于SYN-RCVD状态。

（4）客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文TCP首部ACK标志位置为1，其次确认应答号字段填入server_isn + 1，最后把报文发送给服务端，这次报文可以携带客户端到服务端的数据，之后客户端处于ESTABLISHED状态。

（5）服务端收到客户端的应答报文后，也进入ESTABLISHED状态。

**<mark>29.TCP四次挥手</mark>**

（1）客户端打算关闭连接，此时会发送一个TCP首部FIN标志位被置为1的报文，也即FIN报文，之后客户端进入FIN_WAIT_1状态。

（2）服务端收到FIN报文后，就向客户端发送ACK应答报文，接着服务端进入CLOSE_WAIT状态。

（3）客户端收到服务端的ACK应答报文后，进入FIN_WAIT_2状态。

（4）等待服务端处理完数据后，也向客户端发送FIN报文，之后服务端进入LAST_ACK状态。

（5）客户端收到服务端的FIN报文后，回一个ACK报文，之后进入TIME_WAIT状态

（6）服务端收到了ACK应答报文，就进入了CLOSE状态，至此服务端已经完成连接的关闭。

（7）客户端在经过2MSL时间后，自动进入CLOSE状态，至此客户端也完成连接的关闭。

**<mark>30.三个门，两个门后面是羊，一个门后面是车，现在你选择一个门</mark>**

**<mark>主持人会给你打开一个不是车的门，你有一次换门的机会</mark>**

**<mark>请问，是否要换？(是否会提升你的中奖概率)</mark>**

换。只有第一次选对了，不换才能中奖，而第一次选对的概率为1/3，所以换比不换合适

**<mark>31.c++的static和const的区别</mark>**

（1）修饰局部变量：

const修饰的局部变量为只读，其值不可以修改。

static修饰局部变量则改变了它的生命周期，让静态局部变量在出了作用域后仍然存在，到程序结束，生命周期才结束。

（2）修饰全局变量：

如果修饰的全局变量只在一个文件中使用，那么const的作用和局部变量处的作用一样。

一个全局变量被static修饰，则使得这个全局变量只能在本源文件中使用，不能在其他源文件使用

（3）修饰类成员变量

const修饰类成员变量与修饰全局和局部变量类似，其在使用时不能被修改，因此必须使用构造函数初始化列表进行初始化。

static修饰的类成员变量，必须在类外定义，定义时不添加static关键字，但需要添加作用域限定符声明。静态成员变量不属于某个单独的对象，而属于类所有。所有对象共享静态成员变量。

（4）修饰类成员函数

const修饰类的成员函数，实际修饰该成员函数隐含的this指针，表明在该成员函数中不能对类的任何成员变量进行修改，但也可以在某些变量前加上mutable关键字，使其可以被修改。

static修饰的类成员函数，也被所有的类对象所共享，不属于某个具体的实例。没有this指针，不能访问任何非静态成员。

（5）修饰类对象和类

const修饰类对象，对象中的变量均不可被修改，其只能调用const成员函数，非const对象既可以调用普通成员函数，也可以调用const成员函数。

static不能修饰一个普通类，但是可以修饰内部类，被修饰的内部类可以被当成一个普通类来使用，不需要先实例化一个外部类。

**<mark>32.进程和线程的区别</mark>**

调度：线程是程序执行的基本单位。进程是拥有资源的基本单位。

并发性：不同进程之间切换实现并发，各自占有CPU实现并行；一个进程内部的多个线程并发。

拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享属于进程的资源；进程是拥有资源的独立单位。

系统开销：线程切换时只需保存和设置少量寄存器内容，因此开销很小；进程需要切换虚拟地址空间，切换内核栈和硬件上下文等，开销很大。

**<mark>33.Linux中为什么设计了内核态和用户态</mark>**

出于保护机制，防止用户进程误操作或者是恶意破坏系统。内核态类似于c++的私有成员，只能在类内访问，用户态类似于公有成员，可以随意访问。

在CPU的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。如果允许所有的程序使用这些指令，那么系统的崩溃概率将大大增加，所以CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成危险的指令。

**<mark>34.有什么方式进行内核态和用户态的切换</mark>**

（1）系统调用。

由于用户态无法完成某些任务，所以会请求切换到内核态，内核态将通过为用户专门开放的中断完成切换。

（2）出现异常

在执行用户程序时出现某些不可知的异常时，会从用户程序切换到内核中处理该异常的程序，也就是切换到了内核态。

（3）外围设备中断。

外围设备发出中断信号，当中断发生后，当前运行的进程暂停运行，并由操作系统内核对中断进程处理，如果中断之前CPU执行的是用户态程序，就相当于从用户态切换到了内核态。

**<mark>35.4亿数据中找出几个数</mark>**

1.分治法。

对这4亿个数进行哈希运算，按照某个特征划分为多个小文件，然后将小文件直接读取到内存中进行遍历。

2.外排序+归并

也是将大文件分成多个内存足够容纳的小文件，然后对这些分片文件分别内部排序，最后通过归并算法将这些片段文件合并后通过二分搜索来寻找目标数。

**<mark>36.设计一个strcpy函数。dest长度不够怎么办。拷贝用memcpy，释放空指针，结尾补'\0'</mark>**

```
函数原型：char * strcpy(char* dest, const char* src) 
//将src复制到dest字符数组中
头文件：#include <string.h>
返回值：返回的是第一个参数的值，即目的数组的首地址

注意点：
1、strcpy只用于字符串复制，遇到‘\0’时停止，还会复制字符串的结束符‘\0’.
所以源字符串必须以‘\0’结束。
2、目标空间必须可变。
3、如果参数dest所指的内存空间不够大，可能会造成缓冲溢出的错误情况，在编写程序时
需特别留意，或者用strncpy（）来代替。


strncpy不会向dest追加结束标记'\0'


函数实现1：
char * mystr(char* dest, const char* src) {
    char* ret = dest;
    while(*src != '\0') {
        *dest = *src;
        dest++;
        src++;
    }
    *dest = *src; //复制'\0'
    return ret;
}


函数实现2：
char * mystr(char* dest, const char* src) {
    assert(dest != NULL && src != NULL)；
    if(dest == NULL || src == NULL) return NULL;
    if(dest == src) return dest;

    char* ret = dest;
    while(*dest++ = *src++) {
        ;
    }
    *dest = *src;
    return ret;
}
```

**<mark>37.strlen和sizeof的区别</mark>**

（1）sizeof是运算符，不是函数，结果是在编译时得到而非运行中获得，strlen是字符处理的库函数

（2）sizeof参数可以是任何数据的类型或者数据；strlen的参数只能是字符指针且结尾是‘\\0’

的字符串

（3）因为sizeof是在编译时确定，所以不能用来得到动态分配（运行时分配）的存储空间的大小。

**<mark>38.内存管理中堆和栈的区别</mark>**

（1）申请方式不同：

栈由系统自动分配，堆是由我们自己申请和释放的

（2）申请大小限制不同：

栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，ulimit -s修改。

堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。

（3）申请效率不同：

栈由系统分配，速度快，不会有碎片。

堆由程序员分配，速度慢，会有内存碎片。

**<mark>39.栈与队列的区别</mark>**

（1）队列先进先出，栈先进后出。

（2）对插入和删除操作的限制不同：

栈是只能在表的一端进行插入和删除操作的线性表。

队列是只能在表的一端进行插入和在另一端进行删除操作的线性表。

（3）遍历数据速度不同：

栈只能从头部取数据，也就是最先放入的需要遍历整个栈最后才能取出来，而且在遍历数据的时候还得数据开辟临时空间，保持数据在遍历前的一致性。

队列则不同，队列可以通过从头部取出数据再放入尾部的方式来遍历数据，不需要额外的空间。

**<mark>40.static是全局变量吗？</mark>**

不一定

**<mark>41.封装、继承、多态</mark>**

**封装**：

就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让自己信任的类或对象操作，对不信任的进行信息隐藏。一个类就是封装了数据以及操作这些数据的代码的逻辑实体。

**继承**：

是指可以让某个类型的对象获得另一个类型的对象的属性的方法。派生类可以使用其父类的所有功能，并在无需重新编写父类的情况下对这些功能进行扩展。继承的过程，就是从一般到特殊的过程。

实现继承：子类直接使用父类的属性和方法，而无需额外编码

接口继承：子类只继承属性和方法的名称，并提供自己的实现方式

**多态**：

即一个接口，可以实现多个方法。就是向不同的对象发同一个消息，不同对象在接收时会产生不同的行为（即方法）。

多态与非多态的实质区别就是函数地址是早绑定还是晚绑定的，如果函数的调用，在编译期间就可以确定函数的调用地址，并产生代码，则是静态的，即地址早绑定。而如果函数的调用地址需要在运行时才能确定，则是晚绑定。

**<mark>42.你项目中哪一种指针用的比较多。</mark>**

shared_ptr

**<mark>43.socket如何建立</mark>**

**TCP**：

（1）服务端和客户端初始化socket，得到文件描述符。

（2）服务端调用bind，绑定IP地址和端口。

（3）服务端调用listen，进行监听。

（4）服务端调用accept，等待客户端连接。

（5）客户端调用connect，向服务端的地址和端口发起连接请求。

（6）服务端accept返回用于传输的socket的文件描述符。

（7）客户端调用write写入数据，服务端调用read读取数据。

（8）客户端断开连接时，会调用close，那么服务端read读取数据时，会读取到EOF，待处理完数据后，服务端调用close，表示连接关闭。

**bind函数**的作用主要是socket函数并没有为套接字绑定本地地址和端口号，服务端必须显式绑定地址和端口号。

**listen函数**的主要作用就是将套接字（sock）变成被动的连接监听套接字（被动等待客户端的连接），参数backlog用于设置内核中连接队列的长度。

**accept函数**的功能是，从处于established状态的连接队列头部中取出一个已经完成的连接，如果没有则阻塞。

**connect**与三次握手直接相关。

**UDP**：

由于没有三次握手，所以不需要调用listen和connect。但是UDP交互仍需要IP地址和端口号，因此需要bind。

对于UDP来说，不需要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念。因此每一个UDP的socket都需要bind。

socket               socket

bind                   bind

sendto               sendto

recvfrom           recvfrom

**<mark>44.全连接队列，半连接队列</mark>**

![半连接队列与全连接队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg)

服务端收到客户端的SYN请求后，内核会把该连接存储到半连接队列，并向客户端响应SYN+ACK，接着客户端返回ACK，服务端收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的连接，并将其添加到全连接队列，等待进程调用accept函数时把连接取出来。

**<mark>45.TCP/IP模型</mark>**

应用层：主要为应用程序提供服务，工作在用户态，以下几层都工作在内核态。

传输层：包含TCP和UDP协议，负责建立、管理和维护端到端的连接。

网络层：负责IP选址和路由选择

网络接口层：也可分为数据链路层和物理层，主要为网络层提供链路级别的传输服务，负责在以太网、WiFi这样的底层网络上发送原始数据包。

**<mark>46.linux命令：chmod，scp，chattr，pgrep，awk</mark>**

**chmod**：改变文件或目录权限

**scp**：远程拷贝文件

scp root@www.runoob.com:/home/root/others/music /home/space/music/1.mp3

scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music

**chattr**：更改文件属性

用chattr命令防止系统中某个关键文件被修改：

chattr +i /etc/resolv.conf

**pgrep**：用于检索当前正在运行的进程

pgrep 命令中使用 `-l` 和 `-a` 选项可以列出与用户相关联的进程 id 和进程名。`-l` 选项将只列出进程名，而 `-a` 将列出进程名的完整路径。

```text
[root@linuxtechi ~]# pgrep -u apache -l
4353 httpd
4354 httpd
4355 httpd
4356 httpd
4357 httpd
4358 httpd
4359 httpd
4360 httpd
[root@linuxtechi ~]#

[root@linuxtechi ~]# pgrep -u apache -a
4353 /usr/sbin/httpd -DFOREGROUND
4354 /usr/sbin/httpd -DFOREGROUND
4355 /usr/sbin/httpd -DFOREGROUND
4356 /usr/sbin/httpd -DFOREGROUND
4357 /usr/sbin/httpd -DFOREGROUND
4358 /usr/sbin/httpd -DFOREGROUND
4359 /usr/sbin/httpd -DFOREGROUND
4360 /usr/sbin/httpd -DFOREGROUND
```

**awk**：文本和数据进行处理的编程语言

```
[root@dev01 yeyz_shell]# cat awk_test.txt 
this is a test file 
this is a test file 
this is a test file 
this is a test file 
this is a test file 
[root@dev01 yeyz_shell]# cat awk_test.txt | awk '{print $1,$2}'
this is
this is
this is
this is
this is
```

其中 awk '{print 1,2}'是指打印出这个文件的第一列和第二列。当我们不指定分隔符的时候，awk会默认按照空格来进行分割，当字符中间的空格有多个的时候，awk会将连续的空格理解为一个分隔符。

**<mark>47.如何后台运行程序</mark>**

（1）在命令的最后加上&，可以把这个命令放到后台执行

（2）ctrl+z可以挂起进程，进程处于暂停状态。使用**jobs**查看后台运行进程的序号，再使用**bg%序号** 在后台运行进程。

（3）nohup+&，将标准输出和标准错误缺省的话，会被重定向到nohup.out文件中，忽略所有SIGHUP信号。

**<mark>48.nohup和&区别</mark>**

在命令的末尾加&后，程序可以在后台运行，但一旦当前终端关闭，该程序就会停止运行。

那么假如我们想要退出当前终端，但又想让程序在后台运行，就需要用nohup。

比如想远程到服务器编译程序，但网络不稳定，一旦掉线就编译中止，就需要重新开始编译，很浪费时间。

nohup就是不挂起的意思（no hang up）。一般形式为：

```
nohup ./test &
```

这样使用则程序的输出默认重定向到一个nohup.out文件下。

```
nohup ./test > myout.txt 2>&1 &
```

2>&1 是指将标准错误重定向到标准输出，于是标准错误和标准输出都重定向到指定的myout.txt文件中。

使用nohup之后，需要使用exit正常退出当前账户，这样才能保证命令一直在后台运行。

**<mark>49.vector和list遍历哪个快</mark>**

vector为随机访问容器，数据在内存连续分布，cache miss概率小，而list通过头尾指针遍历，遍历时需要跳转，内存分布不连续，cache miss概率大，所以理论上vector更快。

**<mark>50.指针和引用的区别</mark>**

（1）指针是一个变量，存储一个地址，引用是原变量的别名

（2）指针可以有多级，引用只有一级

（3）指针可以为空，且可以先声明而不初始化，引用不能为NULL且在定义时必须初始化

（4）指针在初始化后可以改变其指向，引用在初始化之后不可以再改变

（5）sizeof指针得到的是这个指针的大小，sizeof引用得到的是引用所指向变量的大小

（6）当把指针作为参数进行传递时，也就是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，改变形参的指向对实参没有影响。而引用却可以。

**<mark>51.说一下缺页中断</mark>**

（1）概念：缺页中断就是当软件试图访问一个已经映射在虚拟地址空间中，但并未加载到物理内存中的分页时，由中央处理器的内存管理单元所发出的中断。

（2）分类：

**软性页缺失**：指页缺失发生时，相关的页已经被加载进内存，但是没有向MMU注册的情况，操作系统只需要在MMU中注册相关页对应的物理地址即可。（MMU：内存管理单元，负责将虚拟内存地址转换成物理地址）。

**硬性页缺失**：相关的页在页缺失发生时未被加载进内存的情况。

**无效页缺失**：当程序访问的虚拟地址是不存在于虚拟地址空间内的时候，则发生无效页缺失。

（3）中断：指计算机在执行程序的过程中，当出现异常情况或特殊请求时，计算机停止现在运行的程序，转向对这些异常情况或特殊请求的处理，处理结束后再返回程序暂停前的位置，继续运行程序。

具体的缺页中断处理也分为两类：

第一类是内存中还有空闲块，则直接将缺页从外存中调入内存；

第二类是内存已满，需要采用页面置换算法淘汰某页再进行调入。（最佳页面置换算法，FIFO，最近最久未使用，时钟，最不常用）

**<mark>52.TCP在哪一层</mark>**

传输层

**<mark>53.HTTP基于什么</mark>**

http协议是基于TCP/IP协议之上的应用层协议

基于请求-响应模型

**<mark>54.输入域名到页面渲染经历了什么</mark>**

（1）解析URL，生成发送给WEB服务器的HTTP请求信息。

（2）查询服务器域名对应的IP地址，如果缓存中有对应域名的缓存，就直接返回，没有就需要通过DNS服务器来解析

（3）通过DNS获取到IP后，就可以把HTTP的传输工作交给操作系统中的协议栈。

（4）协议栈上半部分是TCP/UDP协议，执行收发数据的操作，下半部分是IP协议，控制网络包的收发。

（5）首先通过三次握手建立TCP连接，将请求报文加上TCP、IP、MAC头部。

（6）然后浏览器向WEB服务器发送HTTP请求

（7）服务器收到请求后，进行对应的处理，把数据传给浏览器，也就是返回网络响应。

（8）完成以上过程后，数据已经到达浏览器端，接下来浏览器解析并渲染数据。

**<mark>55.B+ Tree</mark>**

B+树是一棵自平衡的多叉树。

（1）它只有叶子节点才存放数据（索引+记录），非叶子节点只存放索引。

（2）父节点的所有索引都包含在子节点中

（3）叶子节点保存所有的索引信息，并且叶子节点构成一个单向的有序链表。在INNODB存储引擎中有俩个指针，分别指向下一个和上一个叶子节点，形成双向链表。可以提高范围搜索的效率。

查询方式：

（1）单点查询：由于B+树的非叶子节点不存放实际的记录数据，仅存放索引，这样每个节点可容纳的元素个数多，所以它的深度很低，查询到底层节点的磁盘IO次数很少。

（2）插入和删除效率：B+树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，删除效率高。插入可能存在节点的分裂，但是最多只涉及树的一条路径。

（3）范围查询：双向链表，范围查询速度快

**<mark>56.红黑树原理</mark>**

红黑树在效率和简单性之间提供了良好的平衡。

红黑树是一种特殊的二叉查找树，每个节点都要存储节点的颜色，或红或黑。

它具有5个特性：

（1）每个节点或红或黑

（2）根节点是黑色

（3）空叶子节点是黑色

（4）如果一个节点是红色，那么它的子节点是黑色。

（5）从任意一个节点出发到空的叶子节点经过的黑节点个数相同

红黑树的任何一个节点的左右子树的高度差不会超过俩倍。

通过左旋右旋以及重新着色的操作来维持上述特性。

**<mark>57.O(logn)复杂度查询的数据结构</mark>**

（1）二叉搜索树。

和二分查找一样，插入和查询为O(logn)，但由于插入和删除操作时不保证平衡，所以最坏为O(n)。

（2）二叉平衡树

总是保持平衡，查找、插入、删除在最坏情况下都是O(logn)

（3）二叉伸展树

在每次查找后对树进行重构，把被查找的条目搬到离树根近的地方，但不保证最坏情况下O（logn）复杂度。

（4）跳表

跳表是一个多级索引的链表结构，从顶层链表开始搜索，直到找到一个大于等于目标的元素，或到达尾部。如果等于，则目标已经被找到，如果大于，则退回当前层的前一个元素，然后转入下一层搜索。![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430132656662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MDc4NQ==,size_16,color_FFFFFF,t_70)

（5）数组

二分查找

**<mark>58.4种隔离级别</mark>**

多个事务并发执行时可能会遇到【脏读，不可重复读，幻读】的现象。

脏读：读到其他事务未提交的数据；

不可重复读：前后读取的数据不一致；

幻读：前后读取的记录数量不一致。

SQL标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能越低

（1）读未提交：指一个事务还没提交时，他做的变更就能被其他事务看到

（2）读提交：指一个事务提交之后，他做的变更才能被其他事务看到

（3）可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的。MySQL InnoDB默认隔离级别

（4）串行化：对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突，后访问的事务必须等前一个事务执行完成，才能继续执行

在【读未提交】隔离级别下，可能发生脏读、不可重复读和幻读。

【读提交】：不可重复读，幻读

【可重复读】：幻读

【串行化】：都不会发生

**<mark>59.讲一下协程</mark>**

协程是用户态的轻量级线程，是线程内部调度的基本单位。

同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理。

它直接操作栈，基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快，可以通过共享内存和消息队列来通信。

**<mark>60.条件变量怎么用，说一个使用情况</mark>**

条件变量（cond）和锁（mutex）是紧密相关的。

锁的使用场景是：一件事同时只有一个人能做，我抢到锁我就进去操作，操作完毕后再给下一个人做。

而使用条件变量的场景是：

（1）首先，这件事还是同时只能一个人做，所以还要用到锁，但线程抢到锁之后，发现还要等待一些条件满足，才能做。

（2）这时如果让抢到锁的线程一直循环不停检查这个条件，不仅消耗高，而且每次检查完为了不让CPU一直空跑，需要sleep一下，而sleep的时间如果定少了，则消耗高，定的太大，则有延迟，无法即时发现条件满足了。而且抢到锁后一直检查，别的线程就拿不到锁了。

（3）所以引入了条件变量，抢到锁的线程发现条件未满足时，释放锁，使用pthread_cond_wait()挂起自己。这时别的线程也能获取锁进来，发现条件不满足同样挂起。直到条件满足后，由其他地方调用pthread_cond_broadcast()来唤醒全部挂起的线程，或调用pthread_cond_signal()来唤醒指定线程.

**使用情况**：消费者生产者模型

（1）生产者和消费者都需要操作同一个队列，同一时间只能由一个人操作

（2）消费者需要等待生产者生产完毕后，才能进行消费，所以消费者是pthread_cond_wait等待的那一方，生产者是pthread_cond_broadcast通知的那一方。

**<mark>61.构造函数能不能声明为虚函数</mark>**

同8

**<mark>62.动态链接库</mark>**

动态链接库（DLL）是一个包含函数和数据的模块，它可以被其他模块使用

在DLL中可以定义俩种函数：导出函数和内部函数。

导出函数可以被其他模块调用，内部函数一般而言用于DLL内部。DLL中定义的数据一般只在DLL内使用。

DLL提供了一种模块化应用程序的方法，在多个程序中同时使用相同的函数时，使用DLL有助于减少内存占用。

**<mark>63.c++中一个子类最多可以继承多少个父类</mark>**

c++中一个子类可以继承多个父类，对可以继承的父类数量没有具体限制。但是通常建议限制父类的数量，以避免复杂性和可维护性问题。

**<mark>64.工厂模式</mark>**

用一个简单的类来创建实例的过程就称为工厂，用工厂方式代替外部new操作的一种设计模式称为工厂模式。它是一种创建型的模式，提供了一个创建对象的最佳方法。在工厂模式中，我们创建对象时不会对上层暴露创建逻辑，

分类：简单工厂模式，工厂方法模式，抽象工厂模式

**简单工厂模式**：

简单工厂模式由一个工厂类根据传入的参数，动态决定应该创建哪一种产品类实例。

```
#include <iostream>
#include <vector>
#include <algorithm>
#include <queue>
#include <string>
#include <cmath>
#include <assert.h>
using namespace std;

class operation {
public:
    operation(){}
    virtual int getResult(int num1, int num2) = 0; //设置为纯虚函数，不可以生成该类的对象，但可以声明该类的指针
};

class operationAdd: public operation{
    int getResult(int num1, int num2) {
        return num1 + num2;
    }
};

class operationSub : public operation {
    int getResult(int num1, int num2) {
        return num1 - num2;
    }
};

class operationMult : public operation {
    int getResult(int num1, int num2) {
        return num1 * num2;
    }
};

class operationDiv : public operation {
    int getResult(int num1, int num2) {
        assert(num2 != 0);
        return num1 / num2;
    }
};

class OperationFactory { //工厂
public:
    operation* createOperate(char operate) {
        operation* oper = NULL;
        switch (operate) 
        {
            case '+': {
                oper = new operationAdd();
                return oper;
            }
            case '-': {
                oper = new operationSub();
                return oper;
            }
            case '*': {
                oper = new operationMult();
                return oper;
            }
            case '/': {
                oper = new operationDiv();
                return oper;
            }
        }
    }
};

int main() {
    int num1 = 0;
    int num2 = 0;
    char operate;
    cin >> num1 >> operate >> num2;
    operation* oper;
    OperationFactory fac;
    oper = fac.createOperate(operate);
    int res = oper->getResult(num1, num2);

    cout << res << endl;
}
```

[工厂模式（C++编码） - HOracle - 博客园](https://www.cnblogs.com/horacle/p/15494358.html)

**<mark>65.单例模式</mark>**

是为了保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。

**懒汉版**：单例实例在第一次被使用时才初始化。

```
class A{
private: 
    A() {} //私有构造函数，无法直接创建对象
    static A* instance;
public:
    static A* Getinstance() {
        if (instance == NULL) {
            instance = new A();
        }
        return instance;

    }
};

A* A::instance = NULL;

int main() {
    A* a1 = A::Getinstance();
    A* a2 = A::Getinstance();
    if (a1 == a2) cout << 1111 << endl;

}
```

线程安全问题：

（1）首先想到可以加锁：

```
static Singleton* getInstance() {
    Lock lock;  // 基于作用域的加锁，超出作用域，自动调用析构函数解锁
    if(instance == NULL) {
        instance = new Singleton();
    }
    return instance;
}
//这种方法锁的代价过高
```

```
static Singleton* getInstance() {
    if(instance == NULL) {
        Lock lock;  // 基于作用域的加锁，超出作用域，自动调用析构函数解锁
        if(instance == NULL) {
            instance = new Singleton();
        }
    }
    return instance;
}
//双检查锁，先检查是否为空，空的话才加锁
/*但由于内存读写reorder不安全，所以不能用
对于instance = new Singleton();这一行代码
我们默认的顺序是，先分配内存，再调用构造函数进行初始化，然后将这块内存的首地址返回给
instance。
但在CPU层面，这三个步骤有可能会被reorder。
执行的顺序有可能会变成：（1）先分配内存 （2）然后就将内存返回 （3）最后再调用构造函数
那么此时第二步执行完后instance就不等于NULL了，如果此时另一个线程进来，
判断instance ！= NULL，然后直接返回instance进行使用，就会产生错误。
因为此时的instance还未被构造出来，不可以使用。
*/
```

（2）更好的方式：C++11规定了local static在多线程条件下的初始化行为，要求编译器保证了内部静态变量的线程安全性。static在局部变量使用时初次定义就要初始化，且只能初始化一次，重复调用同一函数，第二次调用时不会执行static局部变量初始化的那句话。

```
// version 1.2
class Singleton
{
private:
    Singleton() { };
    ~Singleton() { };
    Singleton(const Singleton&);
    Singleton& operator=(const Singleton&);
public:
    static Singleton& getInstance() 
    {
        static Singleton instance;
        return instance;
    }
};
```

内存泄漏问题：

注意到第一种基础写法中，类中new出对象之后，没有调用delete释放，因此只有构造函数被调用，析构函数没有被调用，因此会造成内存泄漏。

解决方法：

（1）使用共享指针。

（2）使用局部静态变量，同线程下的（2）

[C++ 单例模式总结与剖析 - 一杯清酒邀明月 - 博客园](https://www.cnblogs.com/ybqjymy/p/14921444.html)

**饿汉版**：

```
//饿汉模式，没有线程安全问题，无需加锁
class singleHungry
{
private:
    int dataA;
    int dataB;
private:
    //构造函数私有化
    singleHungry(int a, int b):dataA(a),dataB(b){} 

    //禁用默认拷贝构造、赋值运算符函数
    singleHungry(const singleHungry& s) = delete;
    singleHungry& operator= (const singleHungry& s) = delete;
public:
    ~singleHungry(){}
    static singleHungry s_instacne;
    static singleHungry& getInstacne();

    //业务逻辑
    int getAddResult()
    {
        int result = dataA + dataB;
        cout<<"add result = "<<result<<endl;
        return result;
    }
};

//静态变量需要在类外进行初始化，由于对象是静态变量，存储在静态存储区，无需人为回收，进程结束自动回收内存
singleHungry singleHungry::s_instacne(1,2);
singleHungry& singleHungry::getInstacne()
{
    return s_instacne;
}
```

潜在问题在于static singleHungry s_instance 和 getAddResult二者初始化顺序不确定，如果在初始化完成之前调用getInstance方法会返回一个未定义的实例。

**<mark>66.malloc之后怎么在里面创建一个指针变量</mark>**

```
int** pptr = (int**)malloc(n * sizeof(int*);//分配一块内存用来存放指针变量

int* ptr = (int*)malloc(sizeof(int));//分配一块内存

*pptr = ptr;

cout << *ptr << endl; //ptr 指向的地址的值
cout << &ptr << endl;//ptr 本身的地址
cout << ptr << endl;//ptr 指向的地址
```

首先分配一块内存用来存放指针变量，pptr指向一块能够存放n个int* 类型的空间。然后将ptr指向的地址作为pptr指向的地址的值，即pptr所指向的空间里面存放的是ptr这个指针变量。

**<mark>67.接口怎么设计</mark>**

（1）需要确保如果客户企图使用某个接口而却没有获得他所预期的行为，这个代码就不应该通过编译；如果代码通过了编译，那它的行为就是客户想要的。

```
class Date
{
public:
    Date(int month, int day, int year);
    …
};
```

这个类做了一个假设---用户都能按月，日，年的顺序来传参。但一定会有不少用户记错这个顺序。

一种好的解决方法是，假定用户输入的数据都是不可靠的，需要对输入进行严格的检查。并提供好的引导方式，让用户知道自己传的是什么参数。

```
class Month
{
private:
    int m_month;
public:
    explicit Month(int month): m_month(month){}
};

class Day
{
private:
    int m_day;
public:
    explicit Day(int day): m_day(day){}
};

class Year
{
private:
    int m_year;
public:
    explicit Year(int year): m_year(year){}
};

class Date
{
private:
    Year m_year;
    Month m_month;
    Day m_day;

public:
    Date(Year year, Month month, Day day): m_year(year), m_month(month), m_day(day){}

};

int main()
{
    Date date(Year(2013), Month(5), Day(28));
}
```

其中Year、Month、Day类中的构造函数前有explicit关键字，也就是不允许隐式构造，如Data data(2013, 5, 28)会报错。

（2）让编译器对不正确的行为进行阻止，常见的方法是加上const。

```
if(a = b * c){…} //应写成==
const Object operator* (const Object& a, const Object& b); //使用const编译器就可以识别出赋值运算符不正确
```

（3）让自定义类型的行为尽量与内置类型行为一致。如不要重载乘号运算符，但里面却做加法。

（4）多使用shared_ptr来代替原始指针

**<mark>68.为什么TCP握手是三次而不是俩次</mark>**

（1）三次握手才可以阻止重复历史连接的初始化（主要原因）：

**三次握手如何避免历史连接**：

如果客户端发送了SYN报文（seq = 90），然后宕机了。而且这个SYN报文被网络阻塞了，服务端没有收到。接着客户端重启后，又重新向服务端建立连接。发送了SYN（seq = 100）报文。简单地说，客户端连续发送了多次建立连接的报文，在网络拥堵的情况下：

（a）一个【旧SYN报文】比【新SYN报文】先抵达服务端，服务端就会回一个SYN+ACK报文给客户端，此报文中的确认号是91（90 + 1）

（b）客户端收到后，发现自己期望的确认号应该是（100 + 1），而不是90 + 1，所以就会回RST报文。

（c）服务端收到RST报文后，就会释放连接。

（d）后续最新的SYN报文抵达服务端后，客户端与服务端就可以完成三次握手了。

如果服务端在收到RST报文之前，先收到了【新SYN报文】，那么就会回challenge ACK报文给客户端，这个ack报文并不是确认收到【新SYN报文】的，而是上一次的ack确认号，也就是90+1. 客户端收到后就会回复RST。

**二次握手为什么不行**：

在二次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。

在俩次握手的情况下，服务端在收到SYN报文后就进入了ESTABLISHED状态，意味着这时可以向对方发送数据，但是客户端此时还没有进入ESTABLISHED状态，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-04-21-15-00-04-image.png)

（2）同步双方初始序列号

当客户端发送携带【初始序列号】的SYN报文的时候，需要服务端回一个ACK应答报文，表示客户端的SYN报文已被服务端成功接收，那当服务端发送【初始序列号】给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步**。

而俩次握手只能确保一方的初始序列号能被对方成功接收。

（3）避免资源浪费

如果只有俩次握手，如果客户端发送的SYN报文在网络中阻塞了，重复发送多次SYN报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-04-21-15-06-50-image.png)

**<mark>69.线程池是什么？核心参数？你的项目什么时候用了线程池？怎么用的？</mark>**

**是什么**：

（1）所谓线程池，就是一个pthread_t类型的普通数组，通过空间换时间的方式，消耗服务器的硬件资源，换取运行效率。

（2）它是一组线程资源的集合，这组资源在服务器启动之前就被完全创建好并初始化。

（3）当服务器进入正式运行阶段，开始处理客户端请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配

（4）当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用释放资源。

**核心参数**：

（1）工作队列大小：

取决于每个工作任务的处理时间和系统资源，需要监控系统性能并进行调整，参考取值10000.

（2）线程池数量：

（a）**CPU核心数**：一般情况下线程池的内核数应该与CPU核心数相同或略多一些。对于CPU密 集型的任务，可以选择与CPU核心数相同，避免线程之间的竞争和影响CPU的性能；对于  
I/O密集型任务，可以适当多开一些线程，利用多线程并发机制降低I/O等待时间。  

（b）**系统资源**：考虑线程池所需的内存、CPU等系统资源，对线程池的内核数做出权衡。  
过多的线程会带来内存占用、CPU切换等开销，而过少的线程会导致任务排队等待，  
浪费系统资源。  

因此，选择线程池的内核数应该综合考虑各种因素和特性，并根据实际情况进行调整  
和优化。我设置为8

**项目中什么时候用了，怎么用的**：

项目中使用线程池并发处理用户请求，主线程负责读写，工作线程（即线程池中的线程）负责处理逻辑。主线程通过epoll_wait发现某个文件描述符上有可读事件后，主线程就将这个HTTP的请求报文读到该连接的读缓存中，然后将该任务对象插入线程池的请求队列中；线程池中的线程通过竞争锁资源来获取任务，完成报文解析。

**<mark>70.平时怎么提升编程能力</mark>**

学习编程语言，应用框架直接看官方文档，写demo通过github找项目，遇到不懂的去查 StackOverflow。

**<mark>71.实现一个string类</mark>**

```
class Mystring {
private:
    char* _str;
    size_t _size;
    size_t _capacity;

    static const size_t npos;
public:
    //当使用初始化列表时，初始成员变量的顺序与列表排列的顺序没有关系，只取决于声明这些成员变量的顺序
    Mystring(const char* str = ""):_size(strlen(str)), _capacity(_size) { 
        //我们要对形参设置缺省值。当我们没有给string对象赋值，我们默认初始化为空，但这里str实际上里还有一个’\0’.
        //我们在给_str 分配空间的时候，要分配_capacity个，
        //因为此时_capacity = _size = strlen(str).strlen()计算字符串长度的时候不包含’\0’, 所以我们实际开空间要多开一个留给’\0’
        _str = new char[_capacity + 1];
        strcpy(_str, str);
    }

    ~Mystring() {
        delete[] _str;
    }

    Mystring(const Mystring& s):_str(NULL) {
        Mystring tmp(s._str); //这里不是拷贝函数,而是调用的构造函数，构造的行参是指针，拷贝的行参是对象
        swap(tmp);
    }

    Mystring& operator=(Mystring s) {
        swap(s);
        return *this;
    }

    char& operator[](size_t pos) {
        assert(pos < _size);
        return _str[pos]; //等价于*(_str + pos)
    }
    const char& operator[](size_t pos) const{ //后加const，说明该函数不能改变成员变量
        assert(pos < _size);
        return _str[pos];
    }

    void reserve(size_t n) {
        if (n > _capacity) {
            char* temp = new char[n + 1];
            strcpy(temp, _str);
            delete[] _str;
            _str = temp;
        }
        _capacity = n;
    }

    void resize(size_t n, char ch = '\0') {
        if (n < _size) {
            _size = n;
            _str[_size] = '\0';
        }
        else {
            if (n > _capacity) {
                reserve(n);
            }
            for (size_t i = _size; i < n; ++i) {
                _str[i] = ch;
            }
            _size = n;
            _str[_size] = '\0';
        }
    }

    void push_back(char ch) {
        if (_size >= _capacity) {
            size_t newcapacity = 0;
            if (_capacity == 0) {
                newcapacity = 4;
            }
            else newcapacity = 2 * _capacity;
            reserve(newcapacity);
        }
        _str[_size] = ch;
        _size++;
        _str[_size] = '\0';
    }

    void append(const char* str) {
        size_t len = strlen(str);
        if (_size + len > _capacity) {
            reserve(_size + len);
        }
        strcpy(_str + _size, str);
        _size += len;
    }

    Mystring& insert(size_t pos, char ch) {
        assert(pos <= _size);

        if (_size == _capacity) {
            size_t newcapacity = 0;
            if (_capacity == 0) {
                newcapacity = 4;
            }
            else newcapacity = 2 * _capacity;
            reserve(newcapacity);
        }
        size_t end = _size + 1;
        while (end >= pos) {
            _str[end] = _str[end - 1];
            end--;
        }
        _str[pos] = ch;
        _size++;
        return *this;
    }

    Mystring& insert(size_t pos, const char* str) {
        assert(pos <= _size);
        size_t len = strlen(str);

        if (len == 0) return *this;
        if (_size + len > _capacity) {
            reserve(_size + len);
        }
        size_t end = _size + len;
        while (end >= pos + len) {
            _str[end] = _str[end - len];
            end--;
        }
        for (size_t i = 0; i < len; ++i) {
            _str[pos + i] = str[i];
        }
        _size += len;
        return *this;
    }

    Mystring& erase(size_t pos, size_t len = npos) {
        assert(pos < _size);
        if (len == npos || pos + len > _size) {
            _str[pos] = '\0';
            _size = pos;
        }
        else {
            strcpy(_str + pos, _str + pos + len);
            _size -= len;
        }
        return *this;
    }

    const char* c_str() const {
        return _str;
    }

    size_t size() const {
        return _size;
    }

    size_t capacity() const {
        return _capacity;
    }

    Mystring& operator += (char ch) {
        push_back(ch);
        return *this;
    }

    Mystring& operator += (const char* str) {
        append(str);
        return *this;
    }

    Mystring& operator += (const Mystring& s) {
        *this += s._str;
        return *this;
    }

    Mystring operator + (char ch) {
        Mystring temp = *this;
        temp += ch;
        return temp;
    }

    Mystring operator + (const char* str) {
        Mystring temp = *this;
        temp += str;
        return temp;
    }

    Mystring operator + (const Mystring& s) {
        Mystring temp = *this;
        temp += s;
        return temp;
    }

    bool operator > (const Mystring& s) {
        return strcmp(_str, s.c_str());
    }

    bool operator == (const Mystring& s) {
        return strcmp(_str, s.c_str()) == 0;
    }

    bool operator != (const Mystring& s) {
        return !(*this == s);
    }

    bool operator >= (const Mystring& s) {
        return *this > s || *this == s;
    }

    bool operator < (const Mystring& s) {
        return !(*this >= s);
    }

    bool operator <=(const Mystring& s) {
        return !(*this > s);
    }
    bool operator == (const Mystring& s) {
        return strcmp(_str, s.c_str()) == 0;
    }

    friend bool operator == (const Mystring& s1, const Mystring& s2) {
        size_t i1 = 0, i2 = 0;
        while (i1 < s1.size() && i2 < s2.size()) {
            if (s1[i1] != s2[i2]) {
                return true;
            }
        }
    }
public:
    typedef char* iterator;
    typedef const char* const_iterator;

    iterator begin() {
        return _str;
    }

    const_iterator begin() const {
        return _str;
    }

    iterator end() {
        return _str + _size;
    }

    const_iterator end() const {
        return _str;
    }

    void swap(Mystring& s) {
        std::swap(_str, s._str);
        std::swap(_size, s._size);
        std::swap(_capacity, s._capacity);
    }

};

const size_t Mystring::npos = -1;

int main() {
    Mystring s("hello");
    Mystring s1("asdfads");
    s = s + s1;
    for (int i = 0; i < s.size(); ++i) {
        cout << s[i] << endl;
    }

}
```

**<mark>72.排序算法</mark>**

快排，冒泡，选择，插入，归并，桶

```
//选择排序
void selection_sort(vector<int>& nums) {
    for(int i = 0; i < nums.size() - 1; ++i) {
        int minindex = i;
        for(int j = i + 1; j < nums.size(); ++j) {
            if(nums[j] < nums[minindex]) {
                minindex = j;
            }
        }
        swap(nums[i], nums[minindex]);
    }
}
```

```
//冒泡排序
void bubble_sort(vector<int>& nums) {
    for (int i = 0; i < nums.size() - 1; ++i) {
        for (int j = 0; j < nums.size() - 1 - i; ++j) {
            if (nums[j] > nums[j + 1]) swap(nums[j], nums[j + 1]);
        }
    }
}
```

```
//插入排序
void insertion_sort(vector<int>& nums) {
    for (int i = 1; i < nums.size(); ++i) {
        for (int j = i; j >= 1; --j) {
            if (nums[j] < nums[j - 1]) swap(nums[j], nums[j - 1]);
        }
    }
}
```

```
//归并排序
void merge(vector<int>& nums, int left, int mid, int right) {
    int s1 = left; //左数组起始位置
    int s2 = mid + 1; //右数组起始位置

    vector<int> temp;
    temp.reserve(right - left + 1);
    while (s1 <= mid && s2 <= right) {
        if (nums[s1] >= nums[s2]) {
            temp.push_back(nums[s2]);
            s2++;
        }
        else {
            temp.push_back(nums[s1]);
            s1++;
        }
    }

    if (s1 <= mid) {
        while (s1 <= mid) {
            temp.push_back(nums[s1]);
            s1++;
        }
    }
    else if(s2 <= right) {
        while (s2 <= right) {
            temp.push_back(nums[s2]);
            s2++;
        }
    }

    for (int i = 0; i < temp.size(); ++i) {
        nums[left] = temp[i];
        left++;
    }
}
void merge_sort(vector<int>& nums, int left, int right) {
    if (left >= right) {
        return;
    }

    int mid = left + ((right - left) >> 1);
    merge_sort(nums, left, mid);
    merge_sort(nums, mid + 1, right);
    merge(nums, left, mid, right);
}
```

```
//快速排序
void quick_sort(vector<int>& nums, int left ,int right) {
    if (left >= right) return;
    srand(time(nullptr));
    int key = rand() % (right - left) + left;
    swap(nums[left], nums[key]);

    int i = left, j = right;
    while (i < j) {
        //必须右先走，否则最后相遇的点不一定比key小
        while (i < j && nums[j] >= nums[left]) j--; 
        while (i < j && nums[i] <= nums[left]) i++;
        if(i != j) swap(nums[i], nums[j]);
    }

    swap(nums[left], nums[j]);

    quick_sort(nums, left, i - 1);
    quick_sort(nums, i + 1, right);

}
```

**<mark>73.虚拟地址空间</mark>**

（1）从程序局部性原理中我们可以得到这样一个结论：进程在运行时，不会一下子就要访问所有的内存，相反进程对于内存的访问会表现出明显的倾向性。进程更倾向于访问最近访问过的数据，以及热点数据附近的数据。

（2）所以无论一个进程实际可以占用的内存资源有多大，根据程序局部性原理，在某一段时间内，进程真正需要的资源只是很少的一部分，我们只需要为每个进程分配很少的内存就可以保证进程的正常运行

（3）而虚拟内存的引入正是为了解决这个问题，虚拟内存引入后，进程的视角就会变得非常开阔，每个进程都拥有属于自己的虚拟地址空间，进程与进程之间的虚拟地址空间是相互隔离，互不干扰的。

（4）每个进程都认为自己独占所有的内存空间，所有内存资源都属于自己，但其实任何一个虚拟内存里存储的数据，本质上还是保存在物理内存里的，只不过内核帮我们做了虚拟内存到物理内存这一层的映射，将不同进程的虚拟地址和不同内存的物理地址映射起来。

（5）当CPU访问进程的虚拟地址时，将虚拟地址转换成不同的物理地址，这样不同的进程运行时，虽然操作的是同一虚拟地址，真正写入的却是不同的物理地址，就不会造成冲突了。

（6）通过将多进程之间协同的相关复杂细节全部交给内核中的内存管理模块来处理，极大降低了编程的复杂性，这一切都是因为虚拟内存能够提供内存地址空间的隔离，极大的扩展了可用空间。

**<mark>74.malloc底层是怎么分配内存的</mark>**

malloc并不是系统调用，而是C库里的函数，用来动态分配内存。

maloc申请内存的时候，会有两种方式向操作系统申请堆内存。

**方式一**：通过brk（）系统调用从堆分配内存：

实现方式：通过brk（）函数将【堆顶】指针向高地址移动，获得新的内存空间。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/brk%E7%94%B3%E8%AF%B7.png)

**方式二**：通过mmap（）系统调用在文件映射区分配内存：

实现方式：通过mmap（）系统调用中【私有匿名映射】的方式，在文件映射区分配一块内存。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/mmap%E7%94%B3%E8%AF%B7.png)

内存映射即在进程的虚拟地址空间中创建一个映射，分为两种：

（1）文件映射：数据源是存储设备上的文件，把文件的一个区间映射到进程的虚拟地址空间

（2）匿名映射：没有数据源，把物理内存映射到进程的虚拟地址空间

根据**修改是否对其他进程可见和是否传递到底层文件**，内存映射分为共享映射和私有映射

（1）共享映射：修改数据时，映射相同区域的其他进程可以看见，如果是文件支持的映射，修改会传递到底层文件。

（2）私有映射：如果有数据源，第一次修改数据时会从数据源复制一个副本，然后修改副本，其他进程不可见，不影响数据源。

malloc源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

**<mark>75.malloc（）分配的是物理内存吗</mark>**

不是，分配的是虚拟内存。

如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。

只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存地址和物理内存之间的映射关系。

**<mark>76.malloc（1）会分配多大的虚拟内存</mark>**

malloc在分配内存的时候，会预分配更大的空间作为内存池。具体预分配多大的空间，和malloc使用的内存管理器有关。默认的内存管理器对于malloc（1）实际上预分配132K字节的内存。

**<mark>77.malloc申请的内存，free释放内存会归还给操作系统吗</mark>**

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
  
  因为brk（）申请的内存较小，与其把这一块内存释放给操作系统，不如先缓存着放进malloc的内存池里，当进程再次申请时就可以直接复用，速度会快很多。当然进程退出后，操作系统会回收进程的所有资源。

- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

**<mark>78.为什么不全部使用mmap来分配内存</mark>**

（1）因为向操作系统申请内存，要进行运行态的切换。如果每次都用mmap来分配内存，等于每次都要切换到内核态。

（2）因为mmap分配的内存每次释放的时候，都直接归还给操作系统，于是每次分配的虚拟地址都是缺页状态，第一次访问时就会触发缺页中断。导致CPU消耗增大。

为了改进这俩个问题，malloc通过brk申请内存时，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放时，就缓存在内存池中。

等下次再申请内存的时候，直接从内存池中取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还在，这样不仅减少系统调用的次数，还减少缺页中断次数。

**<mark>79.为什么不全部使用brk分配内存</mark>**

考虑一个场景：如果我们连续申请了10k，20k，30k这三片内存，如果10k，20k释放了变成了空闲的内存空间，那么如果下次申请的内存小于30k，就可以重用这个空闲内存空间。

但如果大于30k，此时没有可用的空闲空间，必须再次进行申请。

随着频繁调用malloc和free，堆内将产生越来越多不可用的小块内存碎片，导致内存泄漏

**<mark>80.free函数只传入一个内存地址，为什么能知道要释放多大的内存</mark>**

malloc返回给用户态的内存起始地址比进程的堆空间起始地址多了16个字节，这里面保存了该内存块的描述信息

**<mark>81.键入网址过程</mark>**

同54

**<mark>82.伙伴系统</mark>**

伙伴系统是一种内存碎片的解决方法。他将内存分成若干块，然后尽可能以最适合的方式满足程序内存需求。

定义伙伴的概念的目的是在分配与释放的过程中，能够动态的维护尽可能长的连续内存。

如果请求的连续内存数量是k，那么伙伴系统将选择满足2^n >= k的最小数字n对应的那个分组，如果伙伴系统中没有对应的分组，那么系统会将更大的分组劈开形成一对伙伴，然后看劈开后的分组是否合适，不合适的话就继续劈开，直到到达合适的大小为止。

当释放内存时，伙伴系统会查看释放分组的伙伴是否空闲，如果空闲的话便会合并两个分组形成一个更大的分组，并递归该操作直到当前分组的伙伴繁忙或已形成最大数量的数组。

**<mark>83.c++的内存结构</mark>**

分为5个区

（1）栈：用来存放局部变量和函数参数，由编译器管理分配和回收。

（2）堆：由程序员管理，需要手动分配和回收，空间较大，但可能会出现内存泄漏和空闲碎片的情况。

（3）全局/静态存储区：分为初始化和未初始化俩个相邻区域，存储初始化和未初始化的全局变量和静态变量。已经初始化的在.data区域，未初始化的在.bss区域

（4）常量存储区：存储常量，一般不允许修改。

（5）代码区：存放程序的二进制代码。

**<mark>84.什么情况使用堆，什么情况使用栈</mark>**

（1）因为与堆相比，栈不会导致内存碎片，且分配效率高。所以函数调用通过栈来完成，以及调用过程中的参数，返回地址，和局部变量等都采用栈的方式存放。如果少量数据需要频繁操作，那么在程序中动态申请少量栈内存（alloca函数），会获得很好的性能提升。

（2）堆可以申请的内存比栈大很多。所以如果需要分配大量的内存空间，最好使用堆内存。

**<mark>85.数组和链表的区别</mark>**

（1）内存分布：

数组占用的是一块连续的内存区

链表在内存中是分散的，通过指针来连接

（2）正是因为他们在内存分布上的差异，导致他们的增删查改时间复杂度不同。

**查改**：数组支持随机访问，O(1)

            链表只能顺序访问，O(n)

**增删**：因为数组在内存中是连续的，要想增加或者删除节点，就会导致其后面的节点都需要进行移动，最坏的情况下需要移动整个数组。

链表只需要改变节点的指向，就可以实现增加或删除的操作。

（3）内存预读：内存管理会将连续的存储空间提前读入缓存（程序局部性原理），所以数组往往都会被读入到缓存中，进一步提高了访问的效率。

链表由于在内存中是分散的，往往都不会读入到缓存中，效率较低。

**<mark>86.i=i+1执行多久</mark>**

i = i + 1, i += 1 , i++。

在实际编译过程中，编译器会自动优化，所以效率一样。

如果没有编译器优化：

（1）i = i + 1效率最低

它需要先读取右i地址；

将值+1；

读取左i地址；

将右值传给左边的i；

（2）i += 1其次；

他首先读取 i 的地址；

将值加一；

传给i；

（3）i++最快

他首先读取 i 的地址；

然后值自增1.

**<mark>87.进程的通信方式有哪些</mark>**

（1）管道：

管道是一种半双工的通信方式，数据只能单向流动。

分为俩类：

**无名管道**（即内存文件）：只能在具有亲缘关系的进程之间使用，通常指父子进程关系。

**有名管道**（即FIFO文件）：可以在不相关的进程之间交换数据。

（2）共享内存：共享内存就是映射一段能被其他进程访问的内存，这段内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式（*Inter-Process Communication，进程间通信*），往往与信号量配合使用来实现进程间的同步和通信。

（3）消息队列：是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

（4）套接字：适用于不同机器间进程通信，在本地也可以作为两个进程通信的方式。

（5）信号：用于通知进程某个事件已经发生，比如按下ctrl + c就是一个信号。

（6）信号量：是一个计数器，用来控制多个进程对共享资源的访问

**<mark>88.了解中断吗</mark>**

（1）**定义**：中断是系统用来响应硬件设备请求的一种机制，如敲击键盘的同时就会产生中断，当硬盘写完数据之后也会产生中断。操作系统收到硬件的中断请求，就会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

（2）中断请求会打断其他进程的运行，并且中断处理程序在响应中断时，可能还会临时关闭中断，这意味着，如果在当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就是说中断可能丢失，所以**中断处理程序要短且快**。

（3）linux为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分为了两个阶段，分别是上半部和下半部：

**上半部**直接处理硬件请求，也就是硬中断，一般会暂时关闭中断请求，主要负责耗时短的工作，特点是快速执行。

**下半部**是由内核触发，也就是软中断，主要负责上半部未完成的工作，一般以内核线程的方式运行，特点是延迟执行。

**<mark>89.键盘上敲一个字母是什么中断？</mark>**

硬件中断

**<mark>90.查找一个字符串是否在文件中</mark>**

（1）**grep** string filename

（2）nl filename | **sed** -n '/string/p'

（3） **awk** '/string/ {print NR":", $0}' filename

（4）**less** filename 键入/后跟想要查找的字符串，然后按“Enter”

（5）vi同上

**<mark>91.查找一个本机端口号的状态</mark>**

netstat -anp | grep 端口号：查看当前端口的状态

netstat -anp：查看所有

**<mark>92.几十个G的文件中查找一个字符串是否存在</mark>**

使用dd加grep命令

dd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。默认从标准输入拷贝到标准输出。

 if=文件名：输入文件名，缺省为标准输入。即指定源文件。

skip=blocks：从输入文件开头跳过blocks个块后再开始复制。

ibs=bytes：一次读入bytes个字节，即指定一个块大小为bytes个字节。

 bs=bytes：同时设置读入/输出的块大小为bytes个字节。

 count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。

不设置skip，先把count设为一半文件大小的值，采用二分法查找，如果找到，则限定在了一半的范围内。然后继续查找。

```
dd if=model_20200423155728 bs=1024 skip=3600000 count=1200 | grep '4222019284714124'
```

**<mark>93.如何判断远程服务的端口有没有开启</mark>**

**方式一**：telnet命令

（1）先查看地址能否ping通

```
ping www.baidu.com
```

（2）然后使用telnet查看端口是否开放

```
telnet www.baidu.com 3306
```

如果命令行不显示任何信息说明端口处于开启状态

如果端口处于关闭状态，命令行窗口显示连接失败。

**方式二**：netcat命令

```
nc -vz www.baidu.com 443
```

**方式三**：nmap命令

```
nmap www.baidu.com
```

会显示已打开的端口

**方式四**：执行/dev/tcp检测

```
echo > /dev/tcp/www.baidu.com/443 && echo "Port is open"
```

如果远程服务器端口是开着的，则会打印“Port is open“，如果没有打开会提示”Connection refused“

**<mark>94.平时使用的Linux命令</mark>**

ls、cd、man、chmod、ps、kill、ping、mkdir、rm、mv、cp、gedit。

**<mark>95.介绍一下OSI七层协议，各层协议都有哪些</mark>**

（1）应用层：负责给应用程序提供统一的接口

常见协议有：HTTP、FTP、DNS

（2）表示层：负责把数据转换成能兼容另一个系统的格式

常见协议：LPP 轻量级会话协议

（3）会话层：负责建立、管理和终止表示层实体之间的通信会话

常见协议：LDAP 轻型目录访问协议

（4）传输层：负责端到端的数据传输

常见协议：TCP,UDP

（5）网络层：负责数据的路由、转发、分片

常见协议：IP、ICMP（用于传输出错报告控制信息）

（6）数据链路层：负责数据的封帧和差错检测，以及MAC寻址

常见协议：ARP协议

（7）物理层：负责在物理网络中传输数据帧

常见协议：Ethernet协议

**<mark>96.baidu.com默认使用什么端口</mark>**

80是http协议的默认端口，是在输入网站的时候浏览器就已经帮我们输入端口号了，所以输入www.baidu.com，其实就是访问www.baidu.com:80。

**<mark>97.三次握手</mark>**

同28

**<mark>98.为什么不是俩次</mark>**

同68

**<mark>99.如果网络情况非常好，百分百不会发生拥塞，不会重传SYN，不会有历史连接问题</mark>**

**<mark>可以两次握手吗</mark>**

还是不可以，因为俩次握手无法同步双方的初始序列号

TCP 协议的通信双方，都必须维护一个【序列号】。序列号是可靠传输的一个关键因素，它的作用：

（1）接收方可以去除重复的数据

（2）接收方可以根据数据包的序列号按序接收

（3）可以标识发送出去的数据包中，哪些是已经被对方接收到的（通过ACK报文中的序列号知道）

所以当客户端发送携带【初始序列号】的SYN报文的时候，需要服务端回一个ACK应答报文，表示客户端的SYN报文已被服务端成功接收，那当服务端发送【初始序列号】给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步**

四次握手也能够可靠的同步双方的初始序列号，但由于第二步和第三步可以优化成一步，所以就成了三次握手。

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接受。

**<mark>100.什么时候用TCP什么时候用UDP</mark>**

由于TCP是面向连接的，能保证数据的可靠性交付，因此经常用于：

（1）FTP文件传输

（2）HTTP/HTTPS

由于UDP面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此常用于：

（1）包总量较少的通信，如DNS

（2）视频，音频等多媒体通信

（3）广播通信

**<mark>101.此时的视频面试用的是UDP还是TCP</mark>**

UDP

（1）为什么使用的是UDP

因为UDP是一个无连接的协议，不用保证可靠性，速度快。

（2）如果UDP不保证可靠性，在视频面试的时候如果你回答问题的视频流丢包了，你的回答我就听不见了，那么视频面试的体验将会非常差，怎么办？

需要结合TCP和UDP的特性，让这个协议既可以保证可靠，又可以保证实时性，也就是使用RUDP，常见的RUDP协议主要有**QUIC**。

**<mark>102.UDP丢包会有什么现象</mark>**

（1）传输的数据无法到达接收端，导致接收端获取不到完整的数据包

（2）传输的数据包可能出现乱序，导致接收端无法正确重构数据

（3）传输的数据包可能被重复发送，导致接收端接收到重复的数据

（4）传输的数据包可能出现错误，导致接收端无法正确解码数据

当UDP数据包丢失时，他不会像TCP中那样自动重传，因为UDP没有检测丢失数据包的机制。发送方不会知道数据包丢失，接收方也不会请求重传。

**<mark>103.http和https的区别</mark>**

（1）HTTP协议传输的数据都是未加密的，也就是明文传输，存在安全风险的问题。HTTPS则解决HTTP不安全的缺陷，在TCP和HTTP网络层之间加入了SSL/TLS安全协议，使得报文能够加密传输。

（2）HTTP连接建立相对简单，在TCP三次握手之后就可进行HTTP的报文传输，而HTTPS在三次握手后，还需要进行SSL/TLS握手，才可进行传输

（3）两者默认的端口不一样，HTTP默认端口号是80，HTTPS是443

（4）HTTPS需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的，需要一定费用

**<mark>104.证书绿色是什么意思</mark>**

主流浏览器对没有安装SSL证书的网站提示不安全，安装了SSL证书的网站，浏览器会显示绿色安全标志，表示连接安全

**<mark>105.自己随便编一个证书可以吗，需要去什么地方注册</mark>**

不可以，需要去CA注册。

CA（数字证书认证机构），将服务器公钥放在由CA颁发的数字证书中，只要证书是可信的，公钥就是可信的。

**<mark>106.平常查什么网站？</mark>**

github，StackOverflow，cpp reference

**<mark>107.代码、文献、DEBUG习惯</mark>**

（1）习惯写注释，对于接口、类以及复杂的业务逻辑，添加有意义的注释。

对于接口方法的注释，主要会写详细的传入参数和返回结果说明，以及异常抛出的情况。

对于类主要写类的各个成员变量和成员函数的功能说明。

（2）把一个大的项目拆分成多个小的业务结构来写

（3）封装一些方法的形参以及通用的模板函数，还有复杂的逻辑判断条件

（4）习惯选择合适的日志级别来打印日志信息进行DEBUG。

error：错误日志，指比较严重的错误，对正常业务有影响，需要运维配置监控的；
warn：警告日志，一般的错误，对业务影响不大，但是需要开发关注；
info：信息日志，记录排查问题的关键信息，如调用时间、出参入参等等；
debug：用于开发DEBUG的，关键逻辑里面的运行时数据；
trace：最详细的信息，一般这些信息只记录到日志文件中。
**<mark>108.proactor和reactor模式</mark>**

（1）reactor是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生后，比如可读就绪事件，就需要应用程序主动调用read方法来完成数据的读取，也就是要应用程序主动将socket连接接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。

（2）proactor是异步网络模式，感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址等信息，用来存放结果数据，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全部交给操作系统来做，并不需要像Reactor那样还需要应用进程主动发起read/write来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。

**<mark>109.epoll是同步的还是异步的</mark>**

（1）从I/O层面来看，EPOLL一定是同步的

（2）从消息处理层面来看，EPOLL是异步的

**<mark>110.从数据流的角度描述proactor模式</mark>**

同108

**<mark>111.五种IO模型</mark>**

（1）阻塞IO：调用者调用了某个函数，等待这个函数返回，期间不执行任何操作，必须等这个函数返回才能进行下一步动作

（2）非阻塞IO：每隔一段时间就去检测IO事件是否就绪，没有就绪就做其他事情。非阻塞IO执行系统调用总是立即返回，不管事件是否已经发生，若没有发生，则返回-1，此时可以根据errno区分这俩种情况，对于accept、recv和send，事件未发生时，errno通常被设置为EAGAIN

（3）信号驱动IO：用户进程发送一个sigaction系统调用后，立刻返回，并不会阻塞，当IO事件就绪后，进程收到SIGIO信号，然后执行信号处理函数。

（4）IO复用：linux用select/poll/epoll函数实现IO复用模型。这些函数也会使进程阻塞，但是和阻塞IO不同，这几个函数可以同时阻塞多个IO操作，而且可以同时对多个读操作、写操作的IO函数进行检测。

（5）异步IO：Linux中，可以调用aio_read函数让内核进行IO操作，用户进程继续往下执行，当内核将数据拷贝到缓冲区后，再通知应用程序进行数据处理。

**<mark>112.为什么不用异步来做webserver</mark>**

（1）linux下的异步IO并不成熟，比如：他只支持以指定标识（O_DIRECT）打开的文件，不支持socket句柄。

（2）如果CPU的核心数较多，或线程的调度算法优秀的话，即使单核心性能一般，也有可能与异步操作的模式性能差不多

**<mark>113.如何使用同步IO模拟proactor模式</mark>**

原理：主线程执行数据读写操作，读写完成之后，通知工作线程进行处理。从工作线程的角度来看，他们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

工作流程如下：

（1）主线程往epoll内核事件表中注册socket上的读就绪事件

（2）主线程调用epoll_wait等待socket上的读就绪事件

（3）当sokcet上有数据可读时，主线程从socket上循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列

（4）睡眠在请求队列上的某个工作线程被唤醒，来处理请求，然后往epoll内核事件表中注册socket上的写就绪事件

（5）主线程调用epoll_wait等待socket可写后，循环写入数据

**<mark>114.高并发情况下的性能提升方法</mark>**

（1）语言方面：

可以利用引用和指针，来减少类的构造和析构；

在c++11标准里，引入了右值引用，move语义和forward完美转发的新特性，以及移动构造函数和移动赋值运算符。

**（右值引用补充: 左值和右值有了解过吗？**

- **左值是一个内存实体，可以&，可以存在很久**
- **右值没有内存实体，只是临时的，用一次就不用了。**

**可以用std::move将左值转换为右值**

**说下你是怎么使用右值引用的**

- **实现一个类的时候，会提供移动构造函数和移动赋值函数**
- **怎么使用：如果发现某个对象需要赋值给一个新对象而且之前老对象不会不用了，就用std::move将左值转换为右值）**

可以利用语言提供的原子特性，部分的代替锁来进行互斥。如static在局部变量使用时初次定义就要初始化，且只能初始化一次，重复调用同一函数，第二次调用时不会执行static局部变量初始化的那句话。

（2）IO方面：

使用更优的拥塞控制算法，如谷歌的BBR算法；

修改TCP选项？

（3）减少内存拷贝；

使用条件变量减少频繁的轮询；

尽量减小互斥锁的代码范围，范围越大，竞争条件在时间维度就越激烈

**<mark>115.linux如何切换目录，查看端口绑定情况，查看CPU利用率</mark>**

cd

netstat -tunlp | grep 8089  其中8089为被占用的端口号

vmstat -n 1 一秒刷新一次

**<mark>116.什么是qps和tps，如何计算</mark>**

（1）QPS即每秒查询率，指一台服务器每秒能响应的查询次数，用于衡量特定的查询服务器在规定时间内所处理流量的多少，是主要针对专门用于查询的服务器的性能指标。

QPS = 1s/单个请求耗时 * 服务器核心数（线程数）

（2）TPS是每秒事务数，一个事务是指客户端向服务器发送请求然后服务器做出反应的过程。

TPS = 事务的数量 / 执行总时间

**<mark>117.线程池和任务队列有没有做分离</mark>**

有。线程池分为了线程集合和任务队列俩部分，把线程和任务分离，提升了线程的重用性。

线程池通过run方法从任务队列提取任务，到一个线程中去执行，有任务就提取执行，没有任务则阻塞线程休眠。

**<mark>118.线程池中怎么利用信号量机制</mark>**

线程池中的线程通过run方法从任务队列中提取任务，初始化时，由于信号量值为0，所以线程池中的线程是阻塞的，当主线程读取完数据后，将数据放到缓冲区，然后调用线程池的append方法，append方法将该任务插入任务队列中，并调用post做一次v操作，使信号量+1。此时线程池中的某个线程的wait就不再阻塞，做一次P操作，使得信号量-1，然后从任务队列中取出任务执行

**<mark>119.CPU利用率拉满的时候在线程池中增加线程是否能提高qps</mark>**

不能。应该会导致CPU利用率降低。

不断增加线程数，请求就会变多，随之而来的就是大量的上下文切换、锁征用等，这些串行化的因素会大大增加CPU时间。根据阿姆达尔公式：

加速比 = 1 / （F + 1/n(1 - F)）

其中F是系统的串行化比例，n是线程数。由此可见，为了提高系统的速度，仅增加线程的数量并不一定能起到有效的作用，需要从根本上修改程序的串行行为，提高系统内可并行化的模块比重，在此基础上，合理增加线程数，才能获得最大的加速比。

**<mark>120.如何根据CPU利用率动态设计，优化线程池</mark>**

（1）如果CPU利用率过高是因为线程池中的任务过多或任务处理时间过长，那么增大线程池中的线程数量可以解决问题。但是，如果CPU利用率过高是因为线程池中的某些线程在等待IO操作完成或者其他原因导致了线程挂起，那么增大线程池中的线程数量可能并不会解决问题，甚至会加剧问题。在这种情况下，需要进一步分析问题的根本原因，并采取适当的措施来解决问题。

（2）线程池不仅仅包括线程，还有任务队列，因为任务队列可以缩短任务等待执行的时间。如果线程池中的线程数已经足够，我们可以考虑增加任务队列的大小，以便更多的任务可以等待执行。

**<mark>121.http解析主从状态机</mark>**

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBH2ZO50WrURwTiaNKTH7tCia3AR4WeKu2EEzSgKibXzG4oa4WaPfGutwBqCJtemia3rc5V1wupvOLFjzQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**<mark>122.http状态码</mark>**

同3

**<mark>123.动态链接库静态链接库特点、区别</mark>**

静态链接库：

（1）每一个程序在使用静态库时，都会将静态库文件拷贝一份添加到自身，当有多个源文件时，就会造成大量的内存浪费。

（2）每当库函数代码修改了，需要重新编译链接形成可执行程序。

（3）因为在可执行程序中已经具备了所有执行程序所需要的东西，在执行的时候运行速度快。

动态链接库：

（1）当动态库文件在被使用时，会对所有想使用该动态库的源程序添加一个标记，在程序执行时再链接动态库文件使用

（3）库函数代码修改后，不需要重新编译链接

（3）把链接推迟到了运行时，运行速度慢

**<mark>124.进程线程区别、通信方式</mark>**

区别同32

进程通信同87

线程通信方式：信号、锁、条件变量、信号量

（1）进程间的通信需要借助操作系统

（2）线程间可以直接读写进程数据段（如全局变量）来进行通信

**<mark>125.static修饰局部变量</mark>**

static修饰局部变量改变了它的生命周期，让静态局部变量在出了作用域后仍然存在，到程序结束，生命周期才结束。

**<mark>126.static修饰全局变量</mark>**

一个全局变量被static修饰，则使得这个全局变量只能在本源文件中使用，不能在其他源文件使用

**<mark>127.如何使用类中的static成员函数</mark>**

static修饰的类成员函数，也被所有的类对象所共享，不属于某个具体的实例。没有this指针，不能访问任何非静态成员。

**<mark>128.面向对象的三大特性</mark>**

同41

**<mark>129.虚函数表在什么时候创建、存在什么位置</mark>**

虚函数表在编译期间创建。

位于只读数据段（.rodata），即c++内存模型中的常量区。

**<mark>130.虚函数存在于什么位置</mark>**

虚函数存在于代码段（.text），即c++内存模型中的代码区

**<mark>131.虚函数指针在什么时候创建</mark>**

vptr跟着对象走，所以对象什么时候创建，vptr就什么时候创建出来，所以是在程序运行时创建。

当程序在编译期间，编译器会为构造函数中增加为vptr赋值的代码，当程序在运行时，遇到创建对象的代码，执行对象的构造函数，那么这个构造函数里就有为这个对象的vptr赋值的语句。

**<mark>132.虚函数为什么能实现多态</mark>**

（1）编译器会自动为每个含有虚函数的类生成一份虚表，该表是一个一维数组，虚表里保存了虚函数的入口地址

（2）编译器会在每个对象的前四个字节中保存一个虚表指针，即vptr， 指向对象所属类的虚表。在构造时，根据对象的类型去初始化虚表指针vptr，从而让vptr指向正确的虚表，从而在调用虚函数时，能找到正确的函数

（3）当派生类对基类的虚函数没有重写时，派生类的虚表指针指向的是基类的虚表；当派生类对基类的虚函数重写时，派生类的虚表指针指向的是自身的虚表；当派生类中有自己的虚函数时，在自己的虚表中将此虚函数地址添加在后面

这样当有一个基类指针指向派生类时，就可以根据派生类对虚函数的重写情况动态的进行调用，从而实现多态。

**<mark>133.函数调用过程中堆栈的变化情况</mark>**

（1）首先是把函数的返回地址、参数从右到左依次压入栈中

（2）然后将当前函数的栈帧压入栈中。栈帧包括临时变量、函数的返回值等信息。

（3）之后跳转到函数的入口点开始执行函数代码

（4）函数执行完毕后，将返回值存放在寄存器中，然后将栈帧弹出，恢复返回地址，跳转回调用点。

**<mark>134.什么是内存泄露、如何防止</mark>**

（1）内存泄漏是指由于疏忽或错误造成程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制。

（2）如何防止：同21. 使用智能指针。

**<mark>135.什么是RAII、为什么智能指针可以防止内存泄漏</mark>**

RAII全称是Resource Acquisition is Initialization ，即“资源获取即初始化”，也就是说在构造函数中申请分配资源，在析构函数中释放资源。

智能指针就是一个类，类在超出作用域范围的时候会自动调用类的析构函数，从而实现自动释放资源的功能

**<mark>136.看过智能指针的源码？讲一下shared_ptr的内部结构</mark>**

shared_ptr和weak_ptr都继承于同一个基类_Ptr_base,基类里面有原始指针*_Ptr和计数类指针*_Rep。

计数类_Ref_count_base是一个虚基类，有两个纯虚函数和强弱指针的引用计数。他有一个派生类_Ref_count, 这才是真正的引用计数器对象，有一个数据成员 _Ptr，就是原始指针。

![](C:\Users\win\AppData\Roaming\marktext\images\2023-05-04-16-04-53-image.png)

![](C:\Users\win\AppData\Roaming\marktext\images\2023-05-04-16-05-07-image.png)

shared_ptr是一个智能指针，它包含两个部分：指向内存的指针和引用计数。指向内存的指针指向被共享的对象，引用计数表示目前共享该对象的智能指针数量。

在shared_ptr内部，还包含一个控制块（_Ref_count），控制块包含了引用计数、删除器和其他管理共享资源的信息。每个shared_ptr对象都共享一个控制块，通过操作控制块，可以对所有指向同一个对象的shared_ptr进行引用计数和资源释放的管理。 

一般情况下，shared_ptr的控制块是在堆上分配的，而指向内存的指针是指向堆上分配的对象的。当最后一个shared_ptr指针被销毁时，控制块会负责释放堆上的资源。

**<mark>137.如果传给shared_ptr一个引用，那么引用计数会不会+1</mark>**

不会

**<mark>138.宏定义，有无类型检查，在什么阶段生效</mark>**

没有类型检查，在预处理阶段会展开宏定义

**<mark>139.讲一下ARP协议的原理和作用？</mark>**

在传输一个IP数据包时，确定了源IP地址和目标IP地址后，就会通过主机【路由表】来确定IP数据包的下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道【下一跳】的MAC地址。

由于主机的路由表可以找到下一跳的IP地址，所以可以通过ARP协议，求得下一跳的MAC地址。

**作用**：根据IP地址获取MAC地址

**原理**：ARP是借助**ARP请求与ARP响应**两种类型的包确定MAC地址的。

![ARP 广播](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/34.jpg)

（1）首先主机会通过广播发送ARP请求，这个包中包含了想要知道的MAC地址的主机IP地址

（2）当同个链路中的所有设备收到ARP请求时，会去拆开ARP请求包里的内容，如果ARP请求包中目标IP地址与自己的IP地址一致，那么这个设备就会将自己的MAC地址塞入**ARP响应包**返回给主机。

操作系统通常会把第一次通过ARP获取的MAC地址缓存起来，以便下次直接从缓存中找到对应IP地址的MAC地址。

不过，MAC地址的缓存是有一定期限的，超过这个期限，缓存的内容就会被清除

**<mark>140.在哪里会用到ARP协议？</mark>**

比如有多台设备连接在同一个交换机上，此时设备1想要和设备3通信，但是设备1只知道设备3的IP地址，不知道对方的MAC地址。

此时设备1就会将自己的IP地址、MAC地址、以及对端的IP地址等信息封装成一个帧。

当交换机收到该帧时，就会在自己的转发表里查看是否存在于该IP对应的MAC地址，这时会有俩种情况：

（1）如果存在，就通过对应的端口发给目标设备，目标设备收到后也组装成一个帧，通过单播的形式传给设备1；

（2）如果不存在，交换机会把帧向所有端口广播（除了该帧进入的端口），也就是ARP协议，目标设备一定能够收得到，后续步骤如上

**<mark>141.如果获取不到MAC地址会发生什么</mark>**

会再次发送ARP请求，请求的重发次数是由操作系统决定的，通常是3到5次。如果多次发送没有获取到MAC地址，就会返回一个ICMP包用来通知出错原因。

**<mark>142.TCP和UDP区别</mark>**

（1）TCP是面向连接的，UDP是无连接的

（2）TCP提供可靠的服务，UDP则是尽最大努力交付，但不保证可靠

（3）TCP是面向字节流的，UDP是面向报文的

（4）UDP没有拥塞控制，因此网络出现拥塞时不会使源主机的发送速率降低（对实时应用很有用，如视频会议等）

（5）每一条TCP连接只能是点到点的；而UDP支持一对一，一对多，多对一和多对多的交互通信

（6）TCP首部开销较大，需要20个字节；UDP只需要8字节

**<mark>143.对socket的了解</mark>**

socket主要用来实现跨网络与不同主机上的进程之间通信。

socket是在应用层和传输层之间的一个抽象层，他把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。

在linux中，可以通过socket函数来打开一个网络文件，返回值就是文件描述符，然后就可以使用普通的文件操作函数来传输数据

**<mark>144.宏定义</mark>**

宏定义是一种预处理指令，有俩种用法，含参或不含参，含参类似于函数，不含参数则主要用于将某个符号或字符串定义为一个宏，以便在程序中使用。用#define来定义。

优点：能简化代码的编写和修改，加快运行的效率

缺点：容易出现未知的错误，因为宏定义没有类型检查和作用域限制。

**<mark>145.宏定义和const的区别</mark>**

（1）编译阶段不同：define是在编译的预处理阶段起作用，const这是在编译和运行的时候起作用

（2）define只做替换，不做类型检查和计算，也不求解，容易产生错误；

const常量有数据类型，编译器可以对其进行类型安全检查

（3）define只是将宏名称进行替换，在内存中会产生多份相同的备份，const在程序运行中只有一份备份

（4）宏定义的数据没有分配内存空间，只是插入替换掉；const定义的变量只是值不能改变，但要分配内存空间

**<mark>146.typedef的作用</mark>**

（1）定义一种类型易于记忆的别名，而不只是简单的宏替换，可以用来声明多个指针对象。

```
char* pa, pb;//只有pa定义为了char指针类型，pb为char类型

typedef char* PCHAR;
PCHAR pa, pb;  //两个都为char指针类型
```

（2）以前的代码，在声明struct新对象时，必须带上struct，使用typedef可以在定义结构体的时候定义一个别名，声明新对象时就不需要再带上struct

```
typedef struct tagPOINT{  
    int x;  
    int y;  
}POINT;  
POINT p1; // 这样就比原来的方式少写了一个struct，比较省事，尤其在大量使用的时候  
```

（3）用来定义与平台无关的类型

```
typedef long double REAL; //在一目标平台上，让它表示最高精度的类型为：
typedef double REAL;      //在不支持 long double 的平台二上，改为：
typedef float REAL;       //在连 double 都不支持的平台三上，改为：
```

（4）可以为复杂的声明定义一个新的简单的别名

```
//原声明：int *(*a[5])(int, char*);
//变量名为a，直接用一个新别名pFun替换a就可以了：
typedef int *(*pFun)(int, char*); 
//原声明的最简化版：
pFun a[5];
```

**<mark>147.在c++中最常用的数据结构</mark>**

vector

**<mark>148.vector的缺点</mark>**

（1）插入删除效率低，在头部进行插入删除时需要移动整个数组

（2）当动态添加的数据超过vector默认分配的大小时，要进行整体的重新分配、拷贝与释放

（3）访问元素时没有边界检查

（4）不支持多维数组，需要通过嵌套vector来表示

**<mark>149.sort排序的底层实现</mark>**

快排时间复杂度为O(nlogn)

底层是根据传入数组的大小来判断使用的排序方式。

（1）如果长度小于40，直接使用插入排序，否则进入快排

（2）但如果快排的递归层数过多可能会导致栈溢出，因此sort限制递归层数为1.5logN，如果超过了层数限制就使用堆排序

（3）sort快排还对基准值进行了优化，它将每一段排序的数组分成了8段，9个位置，每三个位置进行一次冒泡排序，再对这三组的中间值进行一次冒泡，最后得到一个中间值作为基准值

**为什么sort选择快排？**

因为默认需要排序的数组的分布是比较随机的那种分布，然后快排在比较随机的分布上，表现的比较好，速度比较快

**<mark>150.野指针</mark>**

```
int main(void) { 

    int* p;     // 未初始化
    std::cout<< *p << std::endl; // 未初始化就被使用

    return 0;
}
```

指的是没有被初始化过的指针。

为了防止出错，对于指针初始化应该要赋值为NULL

**<mark>151.悬空指针</mark>**

```
int main(void) { 
  int * p = nullptr;
  int* p2 = new int;

  p = p2;

  delete p2;
}
```

指针最初指向的内存已经被释放了的一种指针

**<mark>152.如果使用已经被释放的内存是否会出现错误？可能会出现什么错误？</mark>**

会，应该在释放完内存之后将指针设置为NULL，以避免使用已经被释放的内存。

可能出现的错误：

（1）程序崩溃：如果使用已经释放的内存，还进行写操作，会导致程序崩溃

（2）数据损坏：可能会覆盖其他重要内存

（3）安全漏洞

**<mark>153.为什么用reactor</mark>**

（1）高性能：reactor使用了事件驱动，异步非阻塞的特性，可以高效的处理大量的客户端请求，提高系统的并发能力

（2）可扩展性：reactor可以灵活的通过增加reactor实例的个数来充分利用CPU资源

（3）灵活性：可以根据应用需求来配置线程数量，可以适应不同的负载，并保证高性能

（4）可维护性：使用reactor模式可以将业务逻辑与IO操作分离，这样有利于对系统进行维护和升级

（5）数据处理简单：数据处理基于事件的方式完成，可以处理大量的数据，避免了阻塞和死锁的问题

**<mark>154.reactor解决了什么实际问题</mark>**

reactor模式的核心是解决了多请求问题，如果有特别多的请求同时发生，reactor模式不会因为线程池被短时间占满而拒绝服务。一般实现多请求的模块，会使用线程池的实现方案，但如果瞬间有大量并发，则会一下子消耗所有线程，整个服务就陷入阻塞，后续请求将无法接入。

reactor模式则会有一个分发者对象先接收事件，然后再快速的分发给对应连接的处理对象进行处理，这样就不会阻塞请求的接收

**<mark>155.假设线程池有100个线程，但有1000个用户同时使用，reactor的具体表现</mark>**

reactor的核心思想就是使用少量的线程来处理大量的并发请求，通过事件循环（event loop）和非阻塞 I/O 操作来实现高效的处理。

在这种情况下， Reactor 模式使用单个线程作为事件循环线程（Event Loop Thread），该线程负责处理所有的事件调度和 I/O 操作。这个线程负责监听所有的输入事件，并调用相应的处理函数进行处理。

当有新的事件到达时，事件循环线程会将事件分发给线程池中的空闲线程进行处理。每个线程负责处理自己分配到的事件。处理完成后，将结果返回给事件循环线程，由事件循环线程进行后续的回调处理或响应给用户。

通过这种方式，使用较少的线程来处理大量的并发请求，能够充分利用系统资源，提高系统的吞吐量和响应性能。同时，采用非阻塞的 I/O 操作可以避免线程在等待 I/O 完成时的阻塞，进一步提高系统的并发能力和资源利用率。

**<mark>156.IO多路复用的流程和原理</mark>**

流程：

（1）创建socket文件描述符，并将需要监听的IO事件添加到事件集合中（如select集合）

（2）调用IO多路复用函数，将所有待处理事件的集合传递给函数

（3）IO多路复用函数会等待并监听所有传递的事件集合中的IO事件，并自动挂起当前进程，直到有事件发生或超时

（4）当某个IO事件触发时，IO多路复用函数会返回该事件的文件描述符，并从事件集合中删除该事件

（5）处理完该事件后，将该事件重新加入到事件集合中

（6）循环上面的2到5步，直到IO操作都完成

原理：

利用操作系统提供的事件通知机制，将多个IO事件添加到一个事件集合中进行监听。当事件发生时，操作系统会通知正在等待的进程，进程就可以及时处理该事件。

**<mark>157.有没有考虑程序崩溃场景，项目程序崩溃了怎么办</mark>**

（1）加入了异常捕获机制，以防止出现程序崩溃的情况

（2）加入日志系统，来监控系统运行情况，以便于追踪问题的根源

（3）开发完成后，使用webbench进行了测试和验证，以确保程序的稳定性和安全性

**<mark>158.项目具体应用场景，为什么做这个项目</mark>**

**应用场景**：

（1）目前实现的主要是提供web服务，将静态的页面通过http协议呈现给用户，可以同时处理上万个客户端的请求

（2）后续完善可以实现文件的传输和下载，以及在线视频和音频等内容的传播。

**为什么做这个项目**：

实验室的项目偏向于机器视觉，感觉自身对于后台开发的知识有点薄弱，而Webserver项目涉及到很多基础的网络知识和编程技术，通过做这个项目能够提高自己的技术和理论水平。并且可以通过实践搭建Web服务器，能够深入了解Web服务器的工作原理和机制。

**<mark>159.为什么裸写socket编程而不是使用一些成熟的协议</mark>**

成熟协议：ISAPI, CGI，WinInet，Winsock

（1）主要是因为裸写socket编程可以更好地理解和掌握网络通信原理，从而更好的应对一些特殊的需求或问题。

（2）利用成熟的协议可以简化开发和部署的工作量，并且减少出现问题的可能性，但是有些时候我们会需要更加细节的控制，例如需要进行网络延迟测试，此时裸写socket编程就可以实现更好的优化。

补充：裸写socket可以实现网络延迟测试是因为它可以直接控制底层的网络数据传输过程，包括对数据包的发送时间、延迟、丢失等进行细粒度的控制。而成熟的协议涉及到许多层次的网络协议，其控制的粒度更为宏观，无法对底层数据进行如此细节的控制

<mark>**160.项目中遇到的印象深刻的问题**</mark>

（1）使用优先级队列来优化定时器的时候，最先想到的就是直接使用STL库自带的priority_queue来实现就可以了。但写到调整定时器adjust_timer操作的时候，发现需要修改priority_queue中保存的定时器指针内部的expire_time的值。然后当时就有个疑问，想到直接修改priority_queue内部的值后，是否会进行自动排序。后来写了个测试程序试了一下，发现修改后并不会重新排序，所以不能直接对其保存的指针内部的值进行修改。后来参考了别人的写法，发现是要自己用vector数组来重新实现一个小顶堆，通过unordered_map来保存定时器的下标。当需要调整指定的定时器的时候，先通过哈希表找到定时器在vector中的位置，然后修改内部的值后，再通过下沉的操作把它移动到合适的位置。

（2）线程池初始化时，通过pthread_create生成线程的时候，工作线程运行的函数一定要声明为static。因为pthread_create函数的第三个参数为函数指针，指向工作线程运行的函数，他要求线程处理函数的参数类型为void*，如果线程函数为类成员函数，那么this指针会作为默认的参数传进函数中，this指针的类型为线程池类的类型，从而和void*不匹配，不能通过编译。改成static成员函数，就不会有this指针

**<mark>161.TCP如何保证可靠传输</mark>**

（1）确认和重传：接收方收到报文就会进行确认，并返回一个确定应答消息，发送方发送一段时间后没有收到确认应答消息就会进行重传

（2）数据校验：TCP报文头有校验和，用于校验报文是否损坏

（3）数据合理分片和排序：TCP会按最大传输单元（MTU）合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层

（4）流量控制：当接收方来不及处理发送方的数据时，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失

（5）拥塞控制：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失

**<mark>162.使用TCP编程时，如果服务端程序崩溃了，那么客户端会出现什么情况</mark>**

（1）如果是服务端的进程崩溃了，那么内核会发送FIN报文，与客户端进行四次挥手断开连接

（2）如果服务端主机宕机，那么就不会发生四次挥手：

    （a）如果客户端会发送数据：

由于服务端已经不存在了，所以客户端会进行超时重传，超过一定时间后，会断开TCP连接；

   （b）如果客户端一直不会发送数据：

如果开启了TCP Keepalive机制，则在一段时间没有进行数据交互后，客户端会发送探测报文，达到一定次数没收到响应后，就会断开连接；

如果没有开启，则TCP连接会一直存在

<mark>**163.服务器关机时，一定要等到客户端触发TCP的keepalive后客户端才会关闭吗，有什**么</mark>**<mark>优化方法吗</mark>**

可以在客户端实现心跳机制，自己设定一个时间来发送心跳包，当服务器关机后，心跳包无法收到响应，就可以选择关闭连接

**<mark>164.线程之间共享全局变量如何协调</mark>**

（1）锁机制：通过互斥锁、信号量等线程同步机制来保证共享变量在同一时间只能被一个线程访问，避免多个线程同时读写同一块内存

（2）原子操作：使用atomic关键字，让多个线程对共享变量的读写操作都是原子性的

（3）使用条件变量，让线程在一定条件下等待或唤醒，从而实现线程之间的同步

**<mark>165.为什么使用条件变量时总会使用互斥锁</mark>**

为了保证wait操作的原子性。如果一个线程调用了pthread_cond_wait()函数，但此时还没进入wait状态，另一个线程就调用了pthread_cond_singal()，就会导致此次唤醒丢失。而加了锁的情况下，第二个线程必须等到第一个线程的pthread_cond_wait()释放锁进入wait状态后，才能调用pthread_cond_singal()

**<mark>166.对于大一点的项目如何快速找出C++内存泄漏的代码</mark>**

（1）可以利用valgrind的memcheck工具，来检测程序运行短时间内出现的内存泄漏

（2）利用valgrind的massif工具，来检测程序运行长时间内的内存泄漏

（3）用cppcheck来检测一些我们可能忽略的代码错误

**<mark>167.c++和python有什么区别</mark>**

（1）c++是一种编译型语言，需要将代码编译成可执行文件才能运行；

python是一种解释型语言，可以直接运行脚本

（2）c++是一种静态类型语言，需要在编译时指定变量的数据类型；

python是一种动态类型的语言，可以在运行时解析变量类型

（3）c++可以直接操作内存，效率高；python具有很高的开发效率，但性能较低

**<mark>168.调用new之后底层会做什么</mark>**

new会调用自定义类型的构造函数来初始化对象，并调用一个全局函数operator new。

operator new是对malloc的封装，实际还是通过malloc来申请空间，申请成功则直接返回，失败则会执行用户设置的应对措施，如果没有设置则抛出异常

**<mark>169.操作系统如何分配内存，在哪里分配内存</mark>**

（1）当一个进程启动时，操作系统会为该进程分配一部分内存。这部分内存被分为更小的单元，称为页面

（2）操作系统会在页表中维护所有的可用页面

（3）当进程请求内存时，操作系统会检查页表以查看是否有可用的页面：

如果有，就把该页面分配给进程；如果没有，就使用页面置换算法来淘汰某页面腾出空间

在哪里分配内存：操作系统从RAM或虚拟内存中分配内存，当物理RAM不足以容纳所有正在运行的程序和数据时，则通过虚拟内存来模拟额外的内存

**<mark>170.归还内存时操作系统会做什么</mark>**

操作系统会将该内存区域的页面标记为空闲，移入空闲页面列表，以便其他程序可以使用这些页面

**<mark>171.内存碎片怎么处理</mark>**

内存碎片分为：

（1）内部碎片：就是已经分配出去，却不能被利用的内存空间

（2）外部碎片：指的是还没有被分配出去，但由于太小了无法分配给申请内存空间的新进程的内存空闲区域

采用分段式分配内存，按需分配可以避免内部碎片

对于外部碎片通过紧凑技术消除，也就是内存交换

比如有1G的物理内存，用户执行了多个程序，分别占用512MB，128MB, 256MB，这时候如果关闭128MB的程序，则此时空闲内存还有256MB，如果这个256MB不是连续的，被分成了俩段128MB内存，就会导致没有空间再打开一个200MB的程序。

可以把256MB程序占用的内存写到硬盘上，然后再从硬盘上读回来到内存里。不过在读回来的时候，我们不能装载回原来的位置，而是要紧跟再那已经被占用的512MB内存后面，这样就能空出连续的256MB内存。

也就是在回收内存的时候要尽可能地将相邻的空间合并

**<mark>172.c++有什么情况会导致宕机</mark>**

（1）内存泄漏：如果程序分配了内存但没有正确释放，重复执行这种操作可能导致内存泄漏。当内存资源耗尽时，程序可能会崩溃。

（2）数组越界访问：当访问数组时，如果访问了超出数组边界的元素，即访问了未分配给数组的内存，可能会导致程序崩溃。数组越界是一种常见的编程错误，需要小心处理。

（3）野指针：使用未初始化的指针（野指针）进行访问操作会导致不可预测的行为，可能导致程序崩溃。

（4）空指针访问：当使用空指针（未初始化或已释放的指针）进行访问操作（如解引用、访问成员变量或调用成员函数）时，会导致程序崩溃。空指针访问是一种常见的编程错误，需要避免。

（5）栈溢出：无限递归

（6）未处理异常：当异常被抛出但未被捕获和处理时，程序会终止并抛出异常信息。如果异常没有被适当地处理，程序可能会崩溃。

（6）返回指向临时变量的指针、内存分配释放不配对

**<mark>173.数组越界为什么会导致宕机</mark>**

因为数组在内存中是连续存储的，当访问一个数组元素时，会根据数组的起始地址和下标计算出该元素的内存地址，如果下标越界了，就会访问无效的内存地址，破坏了内存的安全性

**<mark>174.迷宫寻路算法，如果迷宫有环怎么办</mark>**

BFS,DFS, Dijkstra，A*

如果有环：不能只是简单地将走过的路径标记为2，然后通过判断当前点是不是2来决定能不能落脚，可以将入口点标记为2，每走一步加一，然后通过上一个点pre和当前点cur的值来判断能不能落脚

[(157条消息) 数据结构---复杂迷宫求解（多路径带环）_数据结构图求多个路径的方法_y6_xiamo的博客-CSDN博客](https://blog.csdn.net/y6_xiamo/article/details/80102163)

**<mark>175.客户端输入名字的前部分，如有玩家ABC，当客户端输入A时，会有下拉框提示ABC</mark>**，**<mark>问数据结构和算法设计</mark>**

数据结构：字典树

算法设计：

（**1**）初始化：一棵空的字典树仅包含一个根节点，该节点的字符指针为空

（**2**）插入：当需要插入一个字符串S时，首先让一个指针P指向根节点，然后依次扫描字符串S中的每个字符c：

（a）如果P的子节点中没有c这个节点，则创建一个c节点，然后将P移动到节点c

（b）如果有c这个节点，则直接让P节点移动到c

重复上述操作，直到字符串S扫描完毕，在当前节点P上标记一下字符串末尾

（**3**）检索：检索和插入类似，假设我们需要检索一个字符串s，首先让一个指针P指向根节点，然后依次扫描S中的每个字符c：

（a）如果P的子节点中没有c这个节点，则字符串不存在，结束检索

（b）如果有c这个节点，则直接让P节点移动到c，继续检索

重复上述操作，当S中的字符扫描完毕时，若当前p有被标记为字符串末尾，则说明S存在，否则不存在

**<mark>176.文件读写流程（问磁盘到内存的那些步骤）</mark>**

**读文件**：

（1）进程调用库函数向内核发起读文件请求

（2）内核通过检查进程的文件描述符定位到虚拟文件系统的已打开文件列表表项

（3）调用系统调用函数read（）

（4）read()函数通过文件表项链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的inode

（5）在inode模块中，通过文件内容偏移量计算出要读取的页，并可以找到文件对应的address_space

（6）在 address_space中访问该文件的页缓存树，查找对应的页缓存节点：

如果页缓存命中，那么直接返回文件内容；

如果页缓存缺失，那么产生一个缺页异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页，然后重新查找页缓存，返回文件内容

**写文件**：

前5步和读文件一致

（6）如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去

（7）如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过 inode找到文件该页的磁盘地址，读取相应的页填充该缓存页，此时缓存页命中，执行第6步

（8）一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块，有两种方式可以把脏页写回磁盘：

（a）手动调用sync() 或fsync()系统调用把脏页写回

（b）pdflush进程会定时把脏页写回到磁盘

同时需要注意的是，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放

![](https://i0.hdslb.com/bfs/article/f3b8ae4ba0e53ea8f08ce792909120ac632c8fe1.jpg@903w_735h_progressive.webp)

https://www.bilibili.com/read/cv15988841/

**<mark>177.七层，五层，四层网络结构</mark>**

七层：OSI网络模型

应用层；表示层；会话层；传输层；网络层；数据链路层；物理层

五层：TCP/IP模型

应用层；传输层；网络层；数据链路层；物理层

四层：TCP/IP模型

应用层；传输层；网络层；网络接口层

**<mark>178.内存分配方式，如何让类中数据只保存在栈（堆）中</mark>**

**内存分配方式**：

（1） 从静态/全局存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。

（2） 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

（3） 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意大小的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

**如何让类中数据只保存在栈（堆）中**：等同于---->如何限制一个类对象只在堆（栈）上分配空间。

（1）如何限制一个类只在堆上分配空间：

将析构函数设置为私有，写一个公有的destroy函数释放内存。

如果这个类要作为基类使用，可以将析构函数设置为protected。

限制一个类对象只在堆上分配空间，即这个对象只可以new出来，却不可以直接声明出来。我们都知道在new的时候其实执行是分两个步骤，首先是调用operator new()函数，在堆中申请类大小的内存，其次就是调用类的构造函数。如果我们简单粗暴地将构造函数设置为私有成员，我们在无法直接声明对象的同时也无法通过new来创建对象，故这种方法不可以。

当对象建立在栈上面，是由编译器分配内存空间，调用类的构造函数的，当对象“生命”结束的时候，也是由编译器来进行资源回收，调用类的析构函数。也就是说这个对象的整个生命周期都是编译器掌握的。那么如果编译器无法调用析构函数会发生什么情况呢？我们创建一个类，并将类析构函数权限设置为私有，在程序中直接声明一个对象看看结果如何。

```
class A
{
private:
    ~A(){}
};
int main()
{
    A a;//无法通过编译
    return 0;
}
```

如上面代码所示，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性，其实不光是析构函数，只要是非静态的函数，编译器都会进行检查。如果类的析构函数是私有的，则编译器不会在栈空间上为类对象分配内存。因此，将析构函数设为私有，类对象就无法建立在栈上了。
由于我们的析构函数被我们设置成了私有，当我们需要销毁我们new出来的对象的时候，就无法直接使用delete。故我们需要在类中完成一个公有的destory方法，让我们在new之后可以调用destory函数释放内存，避免造成内存泄漏

```
class A
{
public:
    destory()
    {
        delete this;
    }
private:
    ~A(){}
};
```

（2）只在栈上分配空间：

在类中写出new和delete的重载函数，并将其设置为私有即可

```
class A()
{
public:
    A(){}
    ~A(){}
private:
    void* operator new(size_t t){}
    void  operator delete(void* ptr){}
};
```

**<mark>179.线程间通信方式</mark>**

信号：类似进程间的信号处理

锁机制：互斥锁、读写锁和自旋锁

条件变量：使用通知的方式解锁，与互斥锁配合使用

信号量：包括无名线程信号量和命名线程信号量

**<mark>180.粘包的解决方法</mark>**

粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种解决粘包的方式：

- **固定长度的消息**：这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
  
  但是这种方式灵活性不高，实际中很少用。

- **特殊字符作为边界**：我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就认为已经读完一个完整的消息。
  
  HTTP 是一个非常好的例子。HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
  
  但有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。

- **自定义消息结构**：我们可以自定义一个消息结构，由包头和数据组成，其中包头是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整的用户消息来处理了。

**<mark>181.TCP，UDP分别在微信的哪个功能上使用比较多</mark>**

TCP协议更多应用于微信聊天、文件传输等功能，UDP协议更多用于语音、视频通话等实时通讯功能

**<mark>182.TIME_WAIT的作用（两个）</mark>**

（1）防止历史连接中的数据，被后面相同四元组的连接错误的接收：

因为序列号和初始序列号都不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据。

因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的**

（2）保证「被动关闭连接」的一方，能被正确的关闭

如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。

假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。

服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。

为了防止这种情况出现，客户端必须等待足够长的时间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间

客户端在收到服务端重传的 FIN 报文时，TIME_WAIT 状态的等待时间，会重置回 2MSL。

**<mark>183.拥塞控制算法</mark>**

拥塞控制的目的是为了**避免发送方的数据填满整个网络**。

为了在发送方调节所要发送数据的量，定义了一个叫做拥塞窗口的概念。

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化**

四大算法：

（1）**慢启动**：TCP连接刚建立时，一点一点进行提速，试探网络的承受能力。

（a）连接建立好的开始先初始化拥塞窗口大小为1，表示可以传一个MSS大小的数据

（b）每当收到一个ACK，拥塞窗口大小就会加一

（c）每当过了一个往返延迟时间RTT，拥塞窗口大小就会翻倍，呈指数上升

（d）慢启动算法受到慢启动门限的限制，有一个上限，小于这个上限时，使用慢启动算法，大于等于这个上限时，就会使用拥塞避免算法

（2）**拥塞避免算法**：

（a）每收到一个ACK，拥塞窗口大小 += 1 / 拥塞窗口大小

（b）每当过一个往返时间，拥塞窗口大小加一

过了慢启动阈值后，拥塞避免算法可以避免窗口增长过快导致窗口拥塞，此时还是增长阶段，一直增长，网络就会进入拥塞的状况了，会出现丢包现象，此时就需要对数据包进行重传，当触发重传机制后，就进入了拥塞发生算法

（3）**拥塞发生算法**：

重传机制主要有两种：**超时重传和快速重传**

发生超时重传时，就会使用拥塞发生算法。TCP认为这种情况比较糟糕，反应也比较强烈：

（a）它将慢启动阈值设置为当前拥塞窗口大小的一半

（b）将拥塞窗口直接重置为1，然后重新进入慢启动过程

但这种方式太激进了，会造成网络卡顿。

因此当收到三个重复确认ACK时，TCP就开启快速重传算法，TCP认为这种情况不严重，只丢失一小部分的数据，此时：

（a）拥塞窗口大小变为原来的一半

（b）将慢启动阈值置为当前改变后的拥塞窗口大小

（c）然后就进入快速恢复算法

（4）**快速恢复算法**：

在进入快速恢复算法之前，拥塞窗口和慢启动阈值已经被更新了

（a）然后将拥塞窗口大小设置为慢启动阈值 + 3，因为收到3个重复的ACK

（b）重传丢失的数据包

（c）如果再收到重复ACK，那么拥塞窗口  + 1

（d）如果收到新数据ACK后，表明重传的包成功了，那么退出快速恢复算法，将拥塞窗口大小设置为慢启动阈值，然后进入拥塞避免算法

![快速重传和快速恢复](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

**<mark>184.相比于其他语言，你觉得C++的特点有什么</mark>**

（1）引入了模板的概念，可复用性高

（2）运行效率高

（3）三大特性：封装、继承、多态

**<mark>185.项目中如何组织代码结构，用了什么版本管理工具</mark>**

（1）将代码按照不同的功能模块进行组织，每个模块放在一个文件夹下。主要有lock模块用于控制互斥锁和信号量，http模块负责解析报文，定时器模块，线程池模块等等

（2）将代码按照不同的功能分层组织：主线程作为异步线程只负责消息的收发，线程池中的工作线程负责解析具体的消息

（3）Git

**<mark>186.C++的虚函数有什么优势和劣势</mark>**

优势：实现了多态，可以使相同的函数实现不同的功能，提高代码的复用性和接口的规范化，更加符合面向对象的设计理念

劣势：

（1）运行时开销：由于虚函数的动态绑定需要在运行时进行额外的查找和解析，因此相对于非虚函数，虚函数会引入一定的运行时开销，可能导致性能稍微降低

（2）内存开销：：每个包含虚函数的类都会引入一个虚函数表（vtable）指针，以及额外的虚函数表。这增加了对象的内存开销，尤其是在大规模继承层次结构中。

（3）增加了设计的复杂性

**<mark>187.虚函数可以inline吗</mark>**

可以，但它的行为并不符合我们通常对inline函数的预期。

在C++中，使用`inline`关键字可以告诉编译器尝试将函数的定义内联展开，以减少函数调用的开销。

然而，对于虚函数，`inline`关键字的使用并不会实现我们期望的内联行为。虚函数的调用是通过虚函数表（vtable）进行的，这个调用过程涉及动态绑定和运行时查找。由于内联函数需要在编译时展开，而虚函数的调用在运行时才能确定，因此无法将虚函数的定义内联展开。

因此，虽然虚函数可以使用`inline`关键字进行声明，但编译器通常会忽略该关键字，并将其视为一个普通的虚函数。对于需要使用虚函数的情况，不建议使用`inline`关键字，而是依赖编译器自身的优化来决定是否将其内联展开。

**<mark>188.虚函数对性能上除了虚函数表查询的开销以外还有什么缺陷？</mark>**

（面试官提示：从现代编译器角度看。提示之后还是想不到，面试官回答要考虑，是否在一个CPUcache里面，有了虚函数以后，编译器不会做一些很强大的优化）

（1）缺少内联以及其他的优化机会：编译器在编译阶段无法确定实际调用的函数版本，从而无法进行函数内联优化。还会限制编译器其他方面的优化能力，例如可能无法进行循环优化

（2）缓存不友好：虚函数的调用涉及到动态绑定，而动态绑定需要在运行时根据对象的实际类型进行函数调用。这种动态绑定导致了缓存不友好的情况。由于虚函数表中存储了不同函数的地址，而不同的对象可能具有不同的虚函数表指针，这会导致虚函数调用所涉及的代码和数据分散在不同的内存位置上，可能导致缓存失效和不连续的内存访问，从而降低了缓存的命中率。

**<mark>189.在linux下查看进程所耗资源命令</mark>**

（1）top命令：用于实时监视系统中运行的进程。可以使用top命令查看各进程所占用的 CPU、内存、虚拟内存、磁盘 I/O 等资源占用情况。

（2）ps命令：用于列出当前系统中运行的进程。可以使用ps命令查看各进程的 PID、CPU 占用、内存占用、状态等信息。

（3）htop命令：是top命令的升级版，提供了更丰富的功能和界面。可以使用htop命令查看进程的 CPU 占用、内存占用、线程数量、进程状态等信息。

（4）pidstat命令：用于显示进程的资源使用情况。可以使用pidstat命令查看各进程的 CPU 使用情况、内存使用情况、I/O 操作情况等。

（5）iostat命令：用于监视系统的磁盘 I/O 性能。可以使用iostat命令查看各进程的磁盘 I/O 操作情况，包括每个进程的读写速度、请求队列长度、磁盘利用率等。

**<mark>190.查看网络连接数有多少条的命令</mark>**

```
netstat -an | grep ESTABLISHED | wc -l
```

wc（word count）命令用于统计文件字节、字符、单词与行的数量。

-l, --lines
 仅显示行数

**<mark>191.netstat能查看什么连接协议</mark>**

（1）TCP

（2）UDP

（3）Unix 域套接字：本地进程间socket通信

（4）RAW协议：RAW 协议是一种基本的传输层协议，提供对 IP 层的直接访问

（5）ICMP：ICMP 是一种网络层协议，用于发送控制和错误消息

**<mark>192.tcp/ip握手和挥手的区别</mark>**

- 握手是建立 TCP 连接时进行的，而挥手是终止 TCP 连接时进行的。
- 握手是为了协商连接参数和初始序列号，挥手是为了协商连接终止请求。
- 握手过程中，客户端和服务器交换多个报文段以建立连接；而挥手过程中，双方交换多个报文段以完成数据传输并关闭连接。

**<mark>193.挥手的状态timewait状态和closewait状态发生在什么地方什么时候</mark>**

（1）time_wait状态发生在**主送关闭方**接收到第三次挥手的SYN报文后，回一个ACK报文，进入time_wait状态，然后等待2MSL时间，如果没有新的数据到来，就关闭连接.

Timewait 状态的主要目的是确保在连接终止后的一段时间内，处于 Timewait 状态的一方能够接收到可能延迟到达的报文段，并防止早期建立的连接的重复报文段干扰后续连接。

（2）close_wait状态发生在被动关闭方收到第一次挥手的SYN报文后，发送ACK报文，然后进入close_wait状态

Closewait 状态表示被动关闭的一方已经完成数据传输并等待主动关闭的一方发送最后的关闭请求

一旦进入 Closewait 状态，被动关闭的一方可以继续发送可能积压的数据，但不会再接收数据。

**<mark>194.timewait数量很多是什么原因造成的</mark>**

TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接

有三个场景服务器会主动断开连接：

- 第一个场景：HTTP 没有使用长连接
- 第二个场景：HTTP 长连接超时
- 第三个场景：HTTP 长连接的请求数量达到上限

（1）**当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive**，因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。

针对这个场景下，解决的方式也很简单，让客户端和服务端都开启 HTTP Keep-Alive 机制。

（2）**如果客户端在发送完一个 HTTP 请求后，在一段时间内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接**。

当服务端出现大量 TIME_WAIT 状态的连接时，如果现象是有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么大概率就是因为 HTTP 长连接超时，导致服务端主动关闭连接，产生大量处于 TIME_WAIT 状态的连接。

（3）Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。

**对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果最大请求数量参数值是 100，这时候就服务端就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态**。

**<mark>195.http协议消息报文</mark>**

（1）请求报文

由三部分组成：请求行，请求头，请求体

请求行：主要由请求方法（一般是GET和POST），请求URL和HTTP协议及版本组成

请求头：包含若干个属性，格式为属性名：属性值，包含Connection、Content-Length 等信息

请求体：主要包含POST方法的请求数据

（2）响应报文

也由三部分组成：响应行、响应头、响应体

响应行：包含报文协议及版本，还有状态码和状态描述

响应头：也由多个属性组成

响应体：包含服务器返回给客户端的数据

**<mark>196.POST和GET的区别</mark>**

（1）get是获取数据，post是修改数据

（2）get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内，相对较为安全

（3）get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。

（4）GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200 OK(返回数据); POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue表示继续发送，浏览器再发送data，服务器响应200 ok(返回数据)。

（5）GET请求会被浏览器主动缓存，而POST不会，除非手动设置。

（6）GET是幂等的，而POST不是幂等的

- 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

**<mark>197.http是无状态的，开发web的时候怎么知道当前的用户态信息</mark>**

客户端在第一次访问服务器的时候，服务器端会针对这次请求创建一个会话，并生成一个唯一的session ID来标注这个会话，然后服务端会把这个session ID写入到客户端浏览器的cookie里面，用来实现客户端状态的保存，那么在后续的请求里，客户端每一次请求都会携带session ID ，服务器端就可以根据session ID来识别当前会话的状态。

**cookie是客户端的存储机制，而session是服务端的存储机制**

**<mark>198.cookie怎么找到服务器端的信息</mark>**

在首次登陆某个网站的时候，没有任何cookie，服务器会返回一个自生成的session id。这个id作为cookie值写入浏览器。当再次登陆的时候，请求会携带这个cookie值传入后台服务器，服务器拿到 session  id 之后，在内存找到与之对应的 session 就可以继续操作了。
**<mark>199.http请求怎么知道成功还是失败？状态码</mark>**

通过HTTP响应的状态码

同3

**<mark>200.LT和ET的区别</mark>**

ET：边缘触发，使用边缘触发模式时，当被监控的socket描述符上有可读事件发生时，**服务器端只会从epoll_wait中苏醒一次**，即使进程没有调用read函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完

LT：水平触发，使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，目的是告诉我们有数据需要读取；

**<mark>201.线程池怎么保证线程安全</mark>**

（1）使用了互斥锁，通过对共享资源的加锁和解锁来保证并发访问的安全

（2）使用信号量，信号量是一种计数器，可以用来实现多个线程的同步和互斥。

（3）还可以使用读写锁，条件变量和原子操作来保证线程安全

**<mark>202.互斥锁可以重入吗</mark>**

C++标准库中用 mutex 表示不可重入的互斥锁，用 recursive_mutex 表示可重入的互斥锁。

在同一个线程中连续lock两次mutex会产生死锁。一般情况下，如果同一个线程先后两次调用 lock，在第二次调用时，由于锁已经被占用，该线程会挂起等待占用锁的线程释放锁，然而锁正是被自己占用着的，该线程又被挂起而没有机会释放锁，因此 就永远处于挂起等待状态了，于是就形成了死锁。

此时就需要使用递归式互斥量 recursive_mutex 来避免这个问题。recursive_mutex 不会产生上述的死锁问题，只是会增加锁的计数，但必须确保 unlock 和 lock 的次数相同，其他线程才可能获取到这个锁

**<mark>203.线程会有自己独立的栈区吗？会有独立的堆区吗？</mark>**

C++中的线程会有自己独立的栈区，用于保存线程的局部变量和调用栈信息。

至于堆区，线程通常会共享同一个堆区，即使用malloc、new等内存分配方法所分配出的内存块可以在多个线程之间共享。当然，也可以通过手动编写线程安全的内存分配方法，为每个线程分配独立的堆区。

**<mark>204.你了解 Linux 虚拟内存空间吗？</mark>**

（1）从程序局部性原理中我们可以得到这样一个结论：进程在运行时，不会一下子就要访问所有的内存，相反进程对于内存的访问会表现出明显的倾向性。进程更倾向于访问最近访问过的数据，以及热点数据附近的数据。

（2）所以无论一个进程实际可以占用的内存资源有多大，根据程序局部性原理，在某一段时间内，进程真正需要的资源只是很少的一部分，我们只需要为每个进程分配很少的内存就可以保证进程的正常运行

（3）而虚拟内存的引入正是为了解决这个问题，虚拟内存引入后，进程的视角就会变得非常开阔，每个进程都拥有属于自己的虚拟地址空间，进程与进程之间的虚拟地址空间是相互隔离，互不干扰的。

（4）每个进程都认为自己独占所有的内存空间，所有内存资源都属于自己，但其实任何一个虚拟内存里存储的数据，本质上还是保存在物理内存里的，只不过内核帮我们做了虚拟内存到物理内存这一层的映射，将不同进程的虚拟地址和不同内存的物理地址映射起来。

（5）当CPU访问进程的虚拟地址时，将虚拟地址转换成不同的物理地址，这样不同的进程运行时，虽然操作的是同一虚拟地址，真正写入的却是不同的物理地址，就不会造成冲突了。

（6）通过将多进程之间协同的相关复杂细节全部交给内核中的内存管理模块来处理，极大降低了编程的复杂性，这一切都是因为虚拟内存能够提供内存地址空间的隔离，极大的扩展了可用空间。

**<mark>205.虚拟内存有什么好处？</mark>**

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。

这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

**<mark>206.两个进程 malloc 可能会返回一个值吗？会映射到一个物理地址吗？</mark>**

可以，不会

**<mark>207.影响 C++ class 类的大小的因素有哪些？</mark>**

（1）class对象数据成员占用内存大小，会影响类对象大小。

（2）class对象采用的内存对齐策略，会影响类对象大小

（3）class对象中普通成员函数不会影响对象大小，但class中virtual函数会影响类对象的大小。因为虚函数导致对象增加4字节空间, 这是 vptr的缘故。

（4）虚承继的情况：由于涉及到虚函数表和虚基表，会同时增加一个（多重虚继承下对应多个）vptr指针指向虚函数表vTable和一个vptr指针指向虚基表vbTable，这两者所占的空间大小为：8（或8乘以多继承时父类的个数）；

**<mark>208.死锁产生的条件是什么？Cpp 中如何避免死锁？</mark>**

死锁概念：两个或者多个并发的进程，如果每个进程持有某个资源的同时又在等待其他的进程释放资源导致程序无法向前推进，称这一组进程产生了[死锁]。通俗的来说就是两个或者多个进程无限期的阻塞，互相等待的状态。

死锁产生的四个条件：

（1）互斥：一个资源每次只能被一个进程使用

（2）不可抢占：进程已获得的资源，在未使用完之前，不能强行剥夺

（3）占有并等待：一个进程因请求资源而阻塞时，对已获得的资源保持不放  
（4）循环等待：若干进程之间形成一种首尾相接的循环等待资源关系。

这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。

Cpp 中可以通过以下方法避免死锁：

（1）破坏互斥条件：修改代码使得资源可以被多个进程并发使用，如使用共享内存；

（2）破坏占有并等待条件：进程在请求资源时，先释放已经占有的资源，再去请求新的资源；

（3）破坏不可抢占条件：在一些情况下，允许系统强制剥夺进程所占有的资源；

（4）破坏循环等待条件：按照某一规则对资源进行排序，要求每个进程按照相同的顺序请求资源，可避免进程循环等待的发生。

**<mark>209.哈希表怎么处理碰撞问题？最差能退化到什么复杂度？</mark>**

碰撞（Collision）指的是哈希函数将不同的键映射到了同一个哈希桶（或槽位）的情况。在哈希表中，处理碰撞问题是关键之一，常用的解决碰撞的方法有以下两种：

（1）链接法（Chaining）：每个哈希桶维护一个链表（或其他数据结构），所有映射到该桶的键值对都存储在链表中。当发生碰撞时，新的键值对可以直接添加到链表的末尾。这样，不同的键可以共享同一个哈希桶，通过链表进行存储和查找。链表长度的增加会导致查找效率降低，但通常情况下链表长度较短，对性能影响较小。

（2）开放地址法（Open Addressing）：所有键值对都存储在哈希表的桶中，发生碰撞时会尝试寻找下一个可用的空桶。常见的开放地址法有线性探测（Linear Probing）、二次探测（Quadratic Probing）和双重散列（Double Hashing）等。这些方法在发生碰撞时会通过一定的规则寻找下一个可用的桶，直到找到空桶或达到一定的探测次数。开放地址法相比链接法占用更少的内存，但对于哈希表的装载因子（Load Factor）有一定的限制。

***哈希表装载因子是指哈希表中已经存储的元素数量与哈希表大小的比值***

最差情况下，哈希表的性能可能退化为 O(N)，其中 N 是哈希表中存储的键值对数量。这种情况通常发生在哈希函数设计不合理、哈希表装载因子过高或发生大量的碰撞时。在最坏的情况下，哈希表中的所有键值对都映射到同一个桶，导致链表或探测序列非常长，从而降低了查找、插入和删除操作的效率。因此，在设计和使用哈希表时，需要选择合适的哈希函数、调整装载因子，并根据实际情况进行性能分析和优化，以避免最差情况的发生。

**STL库中的unordered_set设置为如果元素个数 >= 篮子个数，篮子就要扩充为原来的2倍左右，然后将元素重新打散，挂在不同的篮子上**

**<mark>210.一个类空指针可以调用虚函数吗？可以调用普通函数吗？</mark>**

- （1）空指针调用非虚成员函数，若函数中没有需要解引用this的地方，函数运行不会出错，但是若用到this，因为this=nullptr，运行出错。
- （2）空指针调用虚函数运行时会出错。
- （3）这两种情况在编译时都能通过。

```
class A {
private:
    int data;
public:
    void fun0() { }
    virtual void fun1(){ }
};

int main() {
    A *p = nullptr;
    p->fun0();
    p->fun1();
}
```

（a）**空指针为什么能调用非虚成员函数？**
        首先，调用非虚函数，采用的是静态联编的方式，在编译期间，编译器会根据对象的静态类型来确定调用哪个函数。
       不管p指向什么，都不会影响p的静态类型，只要p的静态类型确定了，编译器就会根据这个静态类型找到对应的函数地址，就算p指向了NULL，也能找到A::fun0()地址，自然能成功调用了。
（b）**空指针调用的非虚成员函数中，引用了数据成员，为什么运行时会报错？**
        p->fun0();这种成员函数调用，在编译器里面会转变成A::fun0(this);，this指针会当作一个参数传给函数的。也就是说类对象被当作一个参数传给了成员函数，除了多了个this参数之外，成员函数和一般的函数并没有区别。只要函数内部不对这个this指针做取址操作，就不会报错。
       如果现在在函数内部要访问数据成员data，即使你写的是data，实际上也是通过this->data去访问这个数据成员的，现在this是空指针，你对空指针进行->操作，当然是非法的。
（c） **空指针为什么无法调用虚函数？**

虚表指针保存在实例化对象的前四个字节中，而空指针无法找到对应的对象的地址，因此就找不到虚表指针，也就无法找到虚表来调用虚函数

**<mark>211.手写生产者消费者模型</mark>**

```
#include <pthread.h>
#include <iostream>
#include <queue>
#include <unistd.h>
using namespace std;

template<typename T>
class BlockQueue {
private:
    bool isFull() {
        return que.size() == _capacity;
    }

    bool isEmpty() {
        return que.empty();
    }

public:
    BlockQueue(int cap = 5):_capacity(cap) {
        pthread_init_mutex(&_mutex, NULL);
        pthread_init_cond(&_full, NULL);
        pthread_init_cond(&_empty, NULL);
    }
    ~BlockQueue() {
        pthread_mutex_destory(&_mutex);
        pthread_cond_destory(&_full);
        pthread_cond_destory(&_empty);
    }

public:
    void push(const T& data) {
        pthread_mutex_lock(&_mutex);

        //判断是否满足生产消费条件时不能用if，而应该用while：
        //pthread_cond_wait函数是让当前执行流进行等待的函数，
        //是函数就意味着有可能调用失败，调用失败后该执行流就会继续往后执行,
        //就会出现错误(没有数据还拿，没有空间还放)。
        //在多消费者的情况下，
        //当生产者生产了一个数据后如果使用pthread_cond_broadcast函数唤醒消费者，
        //就会一次性唤醒多个消费者，但待消费的数据只有一个，此时其他消费者就被伪唤醒了。
        //为了避免出现上述情况，我们就要让线程被唤醒后再次进行判断，
        //确认是否真的满足生产消费条件，因此这里必须要用while进行判断。
        while (isFull()) {
            pthread_cond_wait(&_full, &_mutex);
        }
        que.push(data);
        pthread_cond_signal(&_empty);
        pthread_mutex_unlock(&_mutex);
    }

    void pop(T& data) {
        pthread_mutex_lock(&_mutex);
        while (isEmpty()) {
            pthread_cond_wait(&_empty, &_mutex);
        }
        data = que.front();
        que.pop();
        pthread_cond_signal(&_full);
        pthread_mutex_unlock(&_mutex);
    }


private:
    queue<T> que;
    int _capacity;
    pthread_mutex_t _mutex;
    pthread_cond_t _full;
    pthread_cond_t _empty;

};
```

**<mark>212.存字符串用`unordered_map`还是用`map`好？为什么？要怎么优化？</mark>**

如果不要求字符串的有序性，用unorder_map好。因为unorder_map底层是哈希表实现的，而map是红黑树，所以相较于map，unorder_map的效率更高

优化：

（1）reserve预分配足够的内存

（2）尽量使用字符串的引用或指针来操作元素

（3）可以自定义特定的哈希函数

（4）使用移动语义来避免不必要的复制

**<mark>213.有一个请求队列,有读者线程和写者线程 在同时操作这个共享的请求队列,属于什么</mark>**

**<mark>样的读写模型 ？</mark>**

应该是公平读写模型

因为读者线程和写者线程都可以同时操作共享的请求队列，没有明确的读者或写者优先级。这意味着读者和写者之间没有特定的顺序限制，可以并发地访问请求队列。

**<mark>214.一写多读模型的情况下怎么解决读写冲突的问题？加锁是一种方案,但是会影</mark>**

**<mark>响性能,有没有更好的办法？</mark>**

可以使用双BUFFER及shared_ptr的机制来实现对同一变量的高效访问，同时又能保证不会出现竞争条件

（1）双buffer就是指对于通常要被多个线程访问的变量，再额外定义一个备份变量，由于是一写多读，写线程只向备份变量中写入，而所有线程只需要访问主变量本身即可，当写线程对备份变量的写操作完成后，会触发主变量指针和备份变量指针的互换操作，将原变量和备份变量进行交换，从而更新数据

（2）共享指针shared_ptr记录了对变量的引用次数，可以避免指针切换时的**访问丢失**问题

**在指针的切换过程中，会出现如下两个问题：**

假设使用map作为缓冲buffer

（1）由于对主map 的读是多线程的读，会出现多线程同时使用主map 共享指针ptr 的情形，而互换指针时，需要对主map 的指针进行写操作，为了避免对 ptr 的读写出现竞争条件，可以使用自旋锁来对ptr 的读写进行同步。使用自旋锁的原因有两个：

（a）只在指针切换时使用锁，而不是在读写两个map 时使用锁，因而锁的使用频率会非常的低，由此导致的上下文切换的代价是可接受的。
（b）由于指针切换时 ptr 处于的情形是一写多读，指针互换准备对 ptr 进行写操作时，要获取锁的等待时间并不长，并不会有长时间的锁等待出现，因而可以使用代价更小的自旋锁，而不是使用代价更高的读写锁。

（2）在准备互换ptr 和 bak_ptr 指向的内容时，如果某个读线程正在使用 ptr 访问主map，直接互换就可能出现读线程再通过ptr获取数据时访问失效的问题，严重的情况下会访问到无效内存导致程序崩溃。为了避免出现读线程会读取到无效数据，可以利用共享指针的引用计数来实现指针的延迟互换。

**<mark>215.epoll中可以无限承载socket的连接吗？创建socket时的返回值是什么？</mark>**

（1）epoll本身没有连接数的限制，但内存是有限的，1G的内存上能监听约10W个端口

（2）如果socket创建成功，返回的是一个整数文件描述符，用于后续的socket操作。如果创建失败，返回-1，并且可以使用errno变量来获取具体的错误信息

**<mark>216.fd在系统中有限制吗？可以无限申请吗？</mark>**

有限。

（1）单个进程中默认是1024，可以通过

```
ulimit -n   #查看当前进程的fd数量限制
ulimit -n num  #修改当前进程的fd数量限制
```

程序中可以用系统函数修改

```
#include <sys/resource.h>

struct rlimit {
    rlim_t rlim_cur; // soft limit
    rlim_t rlim_max; // hard limit    
};

// get resource limit
int getrlimit(int resource, struct rlimit *rlim);

// set resource limit
int setrlimit(int resource, const struct rlimit *rlim);
```

（2）操作系统对文件描述符也有限制，进程分配的文件描述符数量不能超过操作系统的限制，可以通过修改内核参数来调整阈值

```
sysctl fs.file-max=655360
```

文件描述符的数量总是有限的，取决于系统的配置和硬件资源

**<mark>217.一个服务端进程最多可以和多少个客户端进行连接？和fd的数量有关吗？</mark>**

最多可以同时连接的客户端数量取决于多个因素，包括操作系统的设置、硬件资源和应用程序的设计。

文件描述符的数量与同时连接的客户端数量有关，因为每个客户端连接都需要一个文件描述符。但是，需要注意的是，文件描述符的数量并不是唯一影响同时连接的客户端数量的因素。

其他因素包括：

（1）内存：每个连接都会消耗一定的内存，因此可用内存的大小限制了同时连接的客户端数量。

（2）网络带宽：每个连接的数据传输需要使用网络带宽，如果带宽有限，可能会限制同时连接的客户端数量。

（3）处理器性能：处理客户端请求需要消耗处理器资源，处理器的性能限制了同时处理请求的数量。

因此，尽管文件描述符的数量可能很大，但同时连接的客户端数量仍然受到其他因素的限制。实际可支持的连接数取决于这些因素之间的平衡和限制。

**<mark>218.假设这样一个场景，客户端在和服务端进行TCP的三次握手的过程中，突然间</mark>**

**<mark>客户端宕机了，那么这个socket怎么处理？可以删除吗？是怎么删除的？</mark>**

服务端会进行超时重传，重传超过一定的次数后，就会断开连接。

超过超时时间后，服务端会自动关闭相应的socket，并释放相应的资源。这个过程由操作系统自动处理，应用程序无需显式进行操作。

**<mark>219.在服务端调用`accept()`之后,socket就是一直可读的吗？就是调用read()函数</mark>**

**<mark>就一直可以读吗？会阻塞吗？</mark>**

在服务端调用`accept()`函数之后，返回的新socket描述符可以用于后续的数据读取操作，例如调用`read()`函数。

当调用`read()`函数时，它会尝试从socket中读取数据。根据socket的状态和接收缓冲区中是否有数据可用，`read()`函数的行为可能会有所不同。

（1）阻塞模式：如果socket处于阻塞模式，并且接收缓冲区中没有数据可用，`read()`函数会阻塞当前线程，直到有数据到达为止。它会一直等待，直到有数据可读或发生错误。

（2）非阻塞模式：如果socket处于非阻塞模式，并且接收缓冲区中没有数据可用，`read()`函数会立即返回，并返回一个特定的错误码或值（如EWOULDBLOCK、EAGAIN等），表示当前没有数据可读。

在非阻塞模式下，通过轮询或使用事件驱动的方式，可以不断调用`read()`函数，以检查是否有数据可读。当有数据到达时，`read()`函数会返回读取的数据量；如果没有数据可读，它可能会返回一个指示暂时无数据可读的错误码或值。

**<mark>220.如果服务端read()函数发生了阻塞,对方客户端异常关闭了,一直没有发数据过来</mark>**

**<mark>服务端会一直阻塞吗？会导致服务端卡死吗？</mark>**

（1）如果客户端进程崩溃，内核会发送FIN报文通知服务端关闭连接，服务端read函数就会返回一个表示连接已关闭的值，通常是0，并结束阻塞状态

（2）如果客户端宕机：

（a）如果服务端设置了接收超时时间，在超过一定时间后，就会结束阻塞状态

（b）如果没有设置超时时间：

如果开启了TCP Keepalive保活机制，那么一定时间后服务端内核就会向应用程序发送错误通知，通常read返回0，结束阻塞；

如果没有开启保活机制，那么服务端就会一直阻塞

**<mark>221.epoll可以解决上面这个问题吗？如果要识别这个问题，怎么识别？</mark>**

（1）读取返回值：当服务端通过 `epoll` 进行非阻塞读取时，如果连接已关闭或出现异常，`read()` 函数会返回一个特定的值，通常为 一个负数。这表明连接已断开或发生错误，服务端可以根据返回值判断连接状态。

（2）事件通知：使用 `epoll` 监听的套接字在连接断开时会触发相应的事件通知。当客户端连接异常断开时，服务端可以通过检查 `epoll` 返回的事件列表来判断是否存在连接断开的事件，如 `EPOLLRDHUP` 事件。

（3）超时机制：服务端可以在 `epoll_wait()` 函数中设置超时时间，当超过指定的时间后仍未收到任何事件，可以认为连接出现异常。服务端可以根据超时事件来判断连接状态是否正常。

**<mark>222.linux进程创建线程的流程是怎么样的？</mark>**

（1）用户程序调用pthread_create库函数

（2）尝试从栈缓存里获取是否有合适大小的内存，如果有，设置为线程栈，如果没有则从堆中申请指定大小的空间作为线程栈

（3）线程控制块的地址放在栈底，其中存放当前线程的数据

（4）然后调用create_thread()函数, create_thread()函数中调用clone()函数

（5）**将主线程的寄存器信息保存在主线程内核栈中**，然后调用sys_clone()

（6）紧接着调用do_fork()，do_fork函数的第一个参数可以用来控制父子进程共享或拷贝哪些进程资源，就可以设置线程共享进程的task_struct，类似于浅拷贝

（7）然后将该线程的task_struct加入链表队列中，返回用户空间

（8）接着调用start_thread函数，指向线程函数

（9）线程结束后，释放线程栈

**<mark>223.线程共享进程的资源在linux中是怎么实现的？</mark>**

do_fork函数中，会调用copy_process()函数，负责进程复制或克隆的核心实现

（1）创建新进程结构：`copy_process()`函数首先会为新的线程分配一个新的`task_struct`，用于跟踪进程的状态和资源。

（2）复制进程资源：接下来，`copy_process()`函数会复制父进程的资源到新进程结构中，包括内存映像、文件描述符表、信号处理器等。这样，新的线程就与父进程共享相同的资源。其中通过复制父进程的内存映像（页表），就可以确保线程与父进程共享相同的虚拟地址空间。这样，线程可以直接访问进程的全局变量、静态变量和堆上的动态分配内存。

（4）设置线程特定的资源：在创建线程时，内核会为新线程设置线程特定的资源，例如线程 ID（tid）、线程局部存储（TLS）等。这些资源是线程独有的，与其他线程不共享。

需要注意的是，线程共享进程资源是通过复制父进程的资源来实现的，因此线程之间共享的资源是相同的。但是，线程也可以通过使用同步机制（如互斥锁、条件变量）来保护共享数据，以避免并发访问问题。

**<mark>224.线程有自己私有的栈，那么这个栈的内存是被分配到哪里的？是放在进程所属</mark>**

**<mark>的内存里面，还是说放在独立于进程外部的内存中？</mark>**

线程的栈内存是分配在进程的内存空间中，而不是独立于进程外部的内存。所以线程可以共享进程的其他资源，如代码段、全局变量和堆内存等。同时，线程之间的通信和同步也更加方便，因为它们可以直接访问相同的地址空间。

**<mark>225.什么是协程？协程有什么用？</mark>**

协程就是用户态的线程

（1）协程是由用户代码控制的，而不是由操作系统内核调度。它不依赖于操作系统提供的线程管理机制，因此可以在用户空间实现，并避免了线程切换的开销。

（2）协程可以在一个线程内同时执行多个协程，并且可以通过协程之间的切换来实现多任务并发。这种切换是协作式的，也就是说一个协程在执行过程中可以主动让出执行权给其他协程。

```
void A() {
   cout << 1 << " ";
   cout << 2 << " ";
   co_yield_ct();  // 切出到主协程
   cout << 3 << " ";
}

void B() {
   cout << "x" << " ";
   co_yield_ct();  // 切出到主协程
   cout << "y" << " ";
   cout << "z" << " ";
}

int main(void) {
  ...  // 主协程
  co_resume(A);  // 启动协程 A
  co_resume(B);  // 启动协程 B
  co_resume(A);  // 从协程 A 切出处继续执行
  co_resume(B);  // 从协程 B 切出处继续执行
}
```

```
输出：1 2 x 3 y z
```

作用：

（1）异步编程：协程提供了一种更直观、简洁的方式来编写异步代码。使用协程可以避免回调复杂的状态管理，使异步代码更易于理解和编写。协程能够简化异步任务的调度和等待，使程序员能够以顺序、同步的方式编写异步代码。

（2）状态机：协程可以用于编写状态机，使状态的转换和控制流更加清晰和可读。协程能够暂停和恢复执行，保留函数的上下文状态，从而能够编写具有复杂状态转换逻辑的代码，而无需显式地编写状态机的逻辑。

（3）生成器：协程可以作为生成器（Generator）使用，用于生成序列化的数据流或惰性计算。生成器可以逐步生成数据，而不是一次性生成全部数据，这在处理大量数据或需要按需计算的情况下非常有用。

（4）轻量级线程：协程可以用作一种轻量级的线程模型，可以在一个线程内并发执行多个协程。由于协程的切换是由用户控制的，因此可以避免线程切换的开销，提高程序的性能和效率。协程可以用于并发任务的调度和执行，以及避免共享状态和线程安全性等并发编程问题。

**<mark>226.一致性哈希，场景、解决问题</mark>**

[9.4 什么是一致性哈希？ | 小林coding](https://www.xiaolincoding.com/os/8_network_system/hash.html#%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E8%AF%B7%E6%B1%82)

哈希算法在面对节点数量变化时，**最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(N)**，这样数据的迁移成本太高了。

一致性哈希算法就很好解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。

一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而**一致哈希算法是对 2^32 进行取模运算，是一个固定的值**。

我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为**哈希环**，如下图：

![](https://cdn.xiaolincoding.com//mysql/other/0ea3960fef48d4cbaeb4bec4345301e7.png)

一致性哈希要进行两步哈希：

- 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；
- 第二步：当对数据进行存储或访问时，对数据进行哈希映射；

所以，**一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上**。

对「数据」进行哈希映射的结果值，往**顺时针的方向的找到第一个节点**，就是存储该数据的节点。

**在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响**。

但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。

为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。

引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景

**<mark>227.对new和malloc的理解</mark>**

new和malloc都是动态内存分配函数。其中，new是C++中的操作符，malloc是C语言中的函数。new会调用对象的构造函数，而malloc不会。使用new可以简化代码，并且更加类型安全。

**补充：**

new和malloc区别：

(1)  **分配内存的位置**：malloc是从堆上动态分配内存，new是从自由存储区为对象动态分配内存。自由存储区的位置取决于operator new的实现。自由存储区不仅可以为堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。

(基本上，所有的C++编译器默认使用堆来实现自由存储，也即是缺省的全局运算符new和delete也许会按照malloc和free的方式来被实现，这时藉由new运算符分配的对象，说它在堆上也对，说它在自由存储区上也正确。但程序员也可以通过重载操作符，改用其他内存来实现自由存储)

(2)  **返回类型安全性**：malloc内存分配成功后返回void*，然后再强制类型转换为需要的类型；new操作符分配内存成功后返回与对象类型相匹配的指针类型；因此new是符合类型安全的操作符。

(3)  **内存分配失败返回值**：malloc内存分配失败后返回NULL。new分配内存失败则会抛异常（bac_alloc）。

(4)  **分配内存的大小的计算**：使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而malloc则需要显式地指出所需内存的尺寸。

(5)  **是否可以被重载**：opeartor new /operator delete可以被重载。而malloc/free则不能重载

**<mark>228.new是在内存上哪一块去分配的内存</mark>**

new是从自由存储区为对象动态分配内存。自由存储区的位置取决于operator new的实现。自由存储区不仅可以为堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。基本上，所有的C++编译器默认使用堆来实现自由存储

**<mark>229.如果new内存失败了会是怎么样？</mark>**

会抛出std::bad_alloc异常。

如果加上std::nothrow关键字，

```
A* p = new (std::nothrow) A;
```

new 就不会抛出异常而是会返回空指针

**<mark>230.右值引用有什么作用</mark>**

右值引用是C++11引入的特性，它是指对右值进行引用的一种方式。右值引用的作用主要有两个：

（1）可以通过右值引用来实现移动语义。移动语义可以在不进行深拷贝的情况下，将对象的资源所有权从一个对象转移到另一个对象，从而提高代码的效率。

（2）右值引用还可以用于完美转发。在函数模板中，通过使用右值引用类型的形参来接收参数，可以实现完美转发，即保持原参数的值类别（左值还是右值），将参数传递给另一个函数。

**<mark>231.在哪些场景下会应用智能指针</mark>**

我自己是在在动态内存管理中，使用智能指针可以避免手动管理内存的麻烦和出错风险。

**<mark>232.如果遇到内存泄漏这种问题，你一般是怎么去解决</mark>**

（1）在程序中加入必要的错误处理代码，避免程序因为异常情况而导致内存泄漏。

（2）使用智能指针等RAII机制，自动管理内存，避免手动管理内存的麻烦和出错风险。

（3）使用内存分析工具，检测程序中的内存泄漏，并进行相应的修复。

**<mark>233.class中缺省的函数</mark>**

在C++中，如果一个类没有显式地定义「构造函数、析构函数、拷贝构造函数、赋值运算符重载函数」，那么编译器会自动生成这些函数，这些函数被称为缺省函数。

**<mark>234.多线程锁是什么</mark>**

多线程锁是一种用来保护共享资源的机制。在多线程编程中，如果多个线程同时访问同一个共享资源，可能会发生竞态条件（Race Condition），导致程序的行为出现未定义的情况。为了避免这种情况的发生，可以使用多线程锁来保护共享资源。

多线程锁的基本思想是，在访问共享资源之前先获取锁，访问完成之后再释放锁。这样可以保证同一时刻只有一个线程可以访问共享资源，从而避免竞态条件的发生。

常见的多线程锁包括互斥锁、读写锁、条件变量等。其中，互斥锁用于保护共享资源的访问，读写锁用于在读多写少的情况下提高并发性能，条件变量用于线程之间的同步和通信。

**<mark>235.mysql的事务是什么</mark>**

在数据库中，事务（Transaction）是一组操作单元，这些操作单元要么全部执行成功，要么全部执行失败。事务是保证数据库一致性的重要机制之一，它可以将一系列的操作看作一个整体，从而保证数据库的完整性和正确性。

事务具有四个特性：

- 原子性（Atomicity）：事务中的所有操作要么全部执行成功，要么全部执行失败，不会出现部分执行的情况。

- 一致性（Consistency）：事务执行前后数据库的状态是一致的，即数据库中的约束和规则都得到了保持。

- 隔离性（Isolation）：多个事务并发执行时，相互之间不会影响彼此的执行结果。

- 持久性（Durability）：事务执行完成后，对数据库所作的修改将被永久保存到数据库中。

MySQL是一种常见的关系型数据库，支持事务的机制。在MySQL中，事务可以

通过使用事务控制语句（Transaction Control Statements）来进行管理，包括以下三个语句：

- START TRANSACTION：开始一个事务。

- COMMIT：提交一个事务，使之生效。

- ROLLBACK：回滚一个事务，使之失效。

在MySQL中，事务默认是关闭的，需要通过设置autocommit参数为0来启用事务。启用事务后，可以通过执行SQL语句来进行事务操作

**<mark>236.TCP连接中间会有什么操作</mark>**

在TCP连接中，客户端和服务器之间会进行以下操作：

- 握手阶段：客户端向服务器发送SYN包（同步包），请求建立连接。服务器收到SYN包后，向客户端发送SYN+ACK包（同步确认包），表示可以建立连接。客户端收到SYN+ACK包后，再向服务器发送ACK包（确认包），表示连接建立成功。

- 数据传输阶段：连接建立成功后，客户端和服务器之间可以进行数据的传输。客户端向服务器发送数据包，服务器接收数据包并进行处理，然后向客户端发送响应包。客户端收到响应包后，可以再次向服务器发送数据包，以此类推。

- 断开连接阶段：当客户端或服务器不再需要连接时，可以发送FIN包（结束包）来请求断开连接。对方收到FIN包后，也发送FIN包进行响应，表示同意断开连接。当两端都收到对方的FIN包后，连接才真正关闭。

需要注意的是，在TCP连接中可能会出现丢包、拥塞等情况，需要进行相应的处理，例如重传丢失的数据包、调整发送窗口大小等。

**<mark>237.谈一下对面向对象的看法</mark>**

"面向对象"是一种以事物为中心的编程思想，它是一种编程范式，满足面向对象编程的语言，一般会提供类、封装、继承等语法和概念来辅助我们进行面向对象编程。

所谓的面向对象就是将我们的程序模块化，对象化。它具有许多优点：

（1）**封装性（Encapsulation）**：面向对象的一个关键概念是封装，它允许将数据和对数据的操作封装在对象内部。这种封装性可以隐藏实现细节，使得对象的使用者只需关注对象的接口而不需要了解内部实现细节。这有助于提高代码的可维护性和可复用性。

（2）**继承性（Inheritance）**：继承是面向对象的另一个重要特性，它允许一个类继承另一个类的属性和方法。通过继承，可以实现代码的重用，并且可以建立类之间的层次关系，提供了一种更为灵活的代码组织方式。

（3）**多态性（Polymorphism）**：多态性是面向对象的重要特征之一。它允许使用统一的接口来处理不同的对象类型，而不需要关心对象的具体类型。多态性可以提高代码的灵活性和可扩展性，使得代码更加通用和易于理解。

（4）**模块化（Modularity）**：面向对象的设计方法鼓励将程序划分为相互独立的模块或对象，每个模块负责特定的功能。这种模块化的设计使得程序更易于理解、调试和维护。同时，模块化也促进了团队协作，不同成员可以独立开发和测试各自负责的模块。

（5）**可扩展性和可维护性（Scalability and Maintainability）**：面向对象的编程方法对于构建大型和复杂的软件系统非常有利。通过将系统分解为独立的对象和模块，可以更容易地添加新功能、修改现有功能，而不会对整个系统造成过大的影响。这种可扩展性和可维护性使得面向对象的程序更具有长期的生命周期，更易于适应变化的需求。

**<mark>238.c++有几种继承</mark>**

在C++中，有以下几种类型的继承：

（1）**公有继承（Public Inheritance）**：公有继承是最常见的继承方式。在公有继承中，基类的公有成员和保护成员都会成为派生类的公有成员和保护成员，私有成员不会被继承。公有继承表示派生类是基类的一种类型，可以访问基类的公有成员。

（2）**私有继承（Private Inheritance）**：私有继承意味着派生类继承了基类的所有成员，但它们都变成了私有成员。在私有继承中，基类的公有成员和保护成员都变成了派生类的私有成员，无法直接访问。私有继承常用于实现继承的代码重用，而不是通过派生类对象访问基类的成员。

（3）**受保护继承（Protected Inheritance）**：受保护继承是介于公有继承和私有继承之间的一种继承方式。在受保护继承中，基类的公有成员和保护成员都变成了派生类的受保护成员，无法通过派生类对象访问。受保护继承较少使用，但在某些特定的设计情况下可能会有用。

此外，C++还提供了一种特殊的继承方式：

（4）**虚继承（Virtual Inheritance）**：虚拟继承用于解决多继承中的菱形继承问题。当一个派生类从两个或多个基类派生，并且这些基类又有一个共同的基类时，如果不使用虚拟继承，会导致共同基类的多份实例。虚拟继承通过使共同基类在继承链中只有一份实例，解决了菱形继承的问题。

**<mark>239.子类已经重写，如何调用父类的函数</mark>**

通过使用作用域解析运算符

```
#include <iostream>

class Base {
public:
    void display() {
        std::cout << "Base class display() function" << std::endl;
    }
};

class Derived : public Base {
public:
    void display() {
        std::cout << "Derived class display() function" << std::endl;
    }

    void callBaseDisplay() {
        Base::display();  // 调用父类的display()函数
    }
};

int main() {
    Derived derivedObj;
    derivedObj.display();  // 调用子类的display()函数
    derivedObj.callBaseDisplay();  // 调用父类的display()函数

    return 0;
}
```

**<mark>240.有向图和无向图是什么，都作用在什么方向</mark>**

有向图（Directed Graph）是一种图形结构，其中图中的边具有方向。每条边连接两个顶点，并且从一个顶点指向另一个顶点。换句话说，有向图中的边具有起点和终点，且有指定的方向。

无向图的边则没有方向，可以在两个顶点之间进行双向移动。

有向图可用于表示网页链接、软件模块之间的依赖关系、任务调度和流程图等。在算法和数据结构中，有向图应用在拓扑排序、最短路径算法和网络流算法等

无向图可用于表示社交网络中的用户关系、道路或交通网络中的路径等。在图论中，无向图应用在最小生成树、连通分量等算法中。

**<mark>241.了解完全二叉树吗</mark>**

完全二叉树（Complete Binary Tree）是一种特殊的二叉树结构，其中除了最后一层外，其他层的节点都是满的，并且最后一层的节点从左到右连续排列。换句话说，完全二叉树是按照从上到下、从左到右的顺序依次填充节点的二叉树。

特点：

（1）在完全二叉树中，每个节点都与其在二叉树中的位置相对应，可以使用数组或链表等数据结构来存储完全二叉树。

（2）如果用数组表示完全二叉树，假设节点的索引从 1 开始，那么对于任意一个节点的索引 i，它的左子节点的索引为 2i，右子节点的索引为 2i+1。

（3）完全二叉树通常是通过层次遍历（Level Order Traversal）来构建和访问的，因为层次遍历可以按照从左到右的顺序访问节点。

完全二叉树的特性使得它在某些应用中具有优势，例如堆数据结构和优先级队列等。

顺序结构存储就是使用数组来存储，一般只适合表示完全二叉树，因为如果不是完全二叉树，存储时会有空间的浪费

![在这里插入图片描述](https://img-blog.csdnimg.cn/2021050811100827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81MTk4MzYwNA==,size_16,color_FFFFFF,t_70#pic_center)

由图中可以看出，左侧一棵完全二叉树存储进一个数组时不存在空间浪费；而右侧非完全二叉树在存储时下标为3、6、7、8的位置没有数据，造成了空间的浪费。

**<mark>242.vim如何删除一行</mark>**

将光标移动到需要删除的行
按一下ESC键，确保退出编辑模式
按两次键盘上面的d键，即 dd ，就可以删除了。
